{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  169\n",
      "Number of Linear Gaps filled: 5\n",
      "Single gaps filled\n",
      "139\n",
      "Number of gaps with backup water level: 139\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "139\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "adjustment() missing 1 required positional argument: 'index_locations'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[158], line 480\u001b[0m\n\u001b[0;32m    472\u001b[0m         adj_values \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n\u001b[1;32m--> 480\u001b[0m filled_df, wl_dataset, all_gaps, dataset_LF, poly_wl, filled_gap_list, adj_values \u001b[38;5;241m=\u001b[39m cbi_gapfill(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mmrpro\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDocuments\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCode\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCBI\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mGap_Filling\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mP21_2016_gaps.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[158], line 419\u001b[0m, in \u001b[0;36mcbi_gapfill\u001b[1;34m(filepath)\u001b[0m\n\u001b[0;32m    415\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(poly_wl_list) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m :\n\u001b[0;32m    417\u001b[0m     filled_df \u001b[38;5;241m=\u001b[39m fill_gaps(poly_wl_list,gap_list,dataset_LF)\n\u001b[1;32m--> 419\u001b[0m     adj_values \u001b[38;5;241m=\u001b[39m adjustment(filled_df, adjustment_list)\n\u001b[0;32m    421\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGaps filled\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mlen\u001b[39m(poly_wl_list))\n\u001b[0;32m    423\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
      "\u001b[1;31mTypeError\u001b[0m: adjustment() missing 1 required positional argument: 'index_locations'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def read_wl_csv(file_path):\n",
    "    wl_df = pd.read_csv(file_path)\n",
    "\n",
    "    ##### if the csv is from lighthouse then this drop function is always true\n",
    "    ##### if the csv is not from lighthouse then you will need to modify the function\n",
    "\n",
    "    wl_df.drop(labels=range(len(wl_df)-6,len(wl_df)), axis=0, inplace=True)\n",
    "\n",
    "    keys = wl_df.keys().to_list()\n",
    "    \n",
    "    wl_df['date'] = pd.to_datetime(wl_df[keys[0]])\n",
    "    wl_df[keys[1]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[2]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[3]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df['pwl'] = pd.to_numeric(wl_df[keys[1]],errors= 'coerce')\n",
    "    wl_df['bwl'] = pd.to_numeric(wl_df[keys[2]],errors= 'coerce')\n",
    "    wl_df['harmwl'] = pd.to_numeric(wl_df[keys[3]],errors= 'coerce')\n",
    "    wl_df['pwl surge'] = wl_df['pwl'] - wl_df['harmwl']\n",
    "    wl_df['bwl surge'] = wl_df['bwl'] - wl_df['harmwl']\n",
    "    wl_df = wl_df.drop(columns=keys[0],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[1],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[2],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[3],axis=0)\n",
    "    del keys\n",
    "    return wl_df\n",
    "\n",
    "def locate_gaps(WL_data):\n",
    "    lengthMissVal = []\n",
    "    dates = []\n",
    "    count = 0\n",
    "    for i in range(len(WL_data)):\n",
    "        if pd.isna(WL_data['pwl'][i]):\n",
    "            if count == 0:  # Start of a new NaN gap\n",
    "                dates.append(WL_data['date'][i])  # Record the start date of the gap\n",
    "            count += 1  # Increment the gap length\n",
    "\n",
    "        else:\n",
    "            if count > 0:  # End of a NaN gap\n",
    "                lengthMissVal.append(count)\n",
    "                count = 0  # Reset count after recording the gap length\n",
    "    if count > 0:\n",
    "        lengthMissVal.append(count)\n",
    "\n",
    "    # Finalize the DataFrame\n",
    "    WL_data_gaps = pd.DataFrame()\n",
    "    WL_data_gaps['date'] = pd.to_datetime(dates)\n",
    "    WL_data_gaps['gapLength'] = lengthMissVal\n",
    "    WL_data_gaps['gapTime(min)'] = WL_data_gaps['gapLength'] * 6\n",
    "\n",
    "    del lengthMissVal,dates,count\n",
    "\n",
    "    return WL_data_gaps\n",
    "\n",
    "def eligible_gap_length(WL_gaps): #Function to sort the lengh of the gaps into three categories\n",
    "    WL_gaps_filter_6min = WL_gaps['gapLength'] == 1\n",
    "    WL_gaps_filter = (WL_gaps['gapLength'] <= 576) & (WL_gaps['gapLength'] > 1)\n",
    "\n",
    "    #filters the data into individual dataframes\n",
    "    linear_gaps = WL_gaps[WL_gaps_filter_6min]\n",
    "    gaps_less_5_days = WL_gaps[WL_gaps_filter]\n",
    "\n",
    "    del WL_gaps_filter,WL_gaps_filter_6min\n",
    "\n",
    "    return linear_gaps,gaps_less_5_days\n",
    "\n",
    "\n",
    "def linear_fill(Wl_data,linear_gaps): #function to fill in gaps with length of 1 using linear approach\n",
    "\n",
    "    if len(linear_gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(linear_gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "            new_value = ((Wl_data.loc[(index_locations[i])-1,'pwl surge']+ Wl_data.loc[index_locations[i]+1,'pwl surge']) / 2) + Wl_data.loc[index_locations[i],'harmwl']\n",
    "            Wl_data.loc[index_locations[i],'pwl'] = new_value\n",
    "\n",
    "        del matching_dates, index_locations, new_value\n",
    "        \n",
    "        return Wl_data\n",
    "    \n",
    "    else:\n",
    "        print('No single gaps to fill')\n",
    "\n",
    "        return Wl_data\n",
    "\n",
    "\n",
    "def check_bwl(Wl_data,gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        valid_gaps = []\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            is_valid = Wl_data['bwl'][index_locations[i]:index_locations[i]+gap_length[i]].isna().sum() == 0\n",
    "            valid_gaps.append(is_valid)\n",
    "        \n",
    "        filtered_gaps = gaps[valid_gaps].reset_index(drop=True)\n",
    "\n",
    "        del matching_dates, index_locations, gap_length, valid_gaps, is_valid\n",
    "\n",
    "        print(len(filtered_gaps))\n",
    "\n",
    "        return filtered_gaps\n",
    "    \n",
    "    else:\n",
    "        print('No gaps avaliable to fill')\n",
    "\n",
    "        return gaps\n",
    "\n",
    "\n",
    "def poly_gap_fill(Wl_data, gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        poly_df_list = list()\n",
    "        \n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        gap_date_list = list()\n",
    "\n",
    "        adjustment_list = []\n",
    "\n",
    "        for i in range(len(matching_dates)):\n",
    "\n",
    "            gap_date_df = pd.DataFrame()\n",
    "\n",
    "            gap_date_df['date'] = Wl_data['date'][index_locations[i]:index_locations[i]+gap_length[i]]\n",
    "\n",
    "            gap_date_list.append(gap_date_df)\n",
    "            \n",
    "\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            if index_locations[i]- 2161  > 0 and index_locations[i]+2161+gap_length[i] < len(Wl_data):\n",
    "\n",
    "                pwl_30_days = Wl_data['pwl'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                bwl_30_days = Wl_data['bwl'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                dates = Wl_data['date'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                linear_df = pd.DataFrame()\n",
    "\n",
    "                linear_df['pwl 30'] = pwl_30_days\n",
    "                linear_df['bwl 30'] = bwl_30_days\n",
    "                linear_df['dates'] = dates\n",
    "\n",
    "                linear_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "                slope, intercept, *_ = stats.linregress(linear_df['bwl 30'],linear_df['pwl 30'])\n",
    "\n",
    "                poly_df = pd.DataFrame({'bwl': bwl_30_days, 'pwl': pwl_30_days,'date' : pd.to_datetime(dates)})\n",
    "\n",
    "                poly_df['mwl linear'] = intercept + slope*poly_df['bwl']\n",
    "\n",
    "\n",
    "\n",
    "                #outliers = poly_df[abs(poly_df['mwl linear'] - poly_df['pwl']) > 0.1]\n",
    "\n",
    "                #print(f\"Number of outliers detected: {len(outliers)}\")\n",
    "\n",
    "                mask = abs(poly_df['mwl linear'] - poly_df['pwl']) > 0.1\n",
    "                \n",
    "                poly_df.loc[mask, 'pwl'] = np.nan\n",
    "                poly_df.loc[mask, 'mwl linear'] = np.nan\n",
    "                poly_df.loc[mask, 'bwl'] = np.nan\n",
    "                \n",
    "                '''plt.scatter(poly_df['pwl surge'], poly_df['bwl surge'])\n",
    "\n",
    "                plt.scatter(poly_df['mwl surge linear'],poly_df['bwl surge'] , color = 'red', linestyle = 'dashed', label = 'linear model')\n",
    "\n",
    "                plt.title('pwl surge vs bwl surge')\n",
    "\n",
    "                plt.show()\n",
    "\n",
    "                plt.clf()'''\n",
    "                \n",
    "            \n",
    "\n",
    "                \n",
    "                if poly_df['bwl'].isna().sum() + poly_df['pwl'].isna().sum() < len(Wl_data)*0.1:\n",
    "\n",
    "                    poly_df_copy = poly_df.copy()\n",
    "\n",
    "                    poly_df_copy.dropna(inplace=True)\n",
    "\n",
    "                    poly =np.polynomial.polynomial.Polynomial.fit(poly_df_copy['pwl'],poly_df_copy['bwl'],4)\n",
    "\n",
    "                    coeffs = np.polyfit(poly_df_copy['bwl'],poly_df_copy['pwl'],4)\n",
    "\n",
    "                    poly1 = np.poly1d(coeffs)\n",
    "\n",
    "                    pred_values = poly1(poly_df['bwl'])\n",
    "\n",
    "                    poly_df['mwl'] = pred_values\n",
    "\n",
    "                    '''plt.scatter([poly_df['pwl surge']], poly_df['bwl surge'])\n",
    "\n",
    "                    plt.scatter(poly_df['mwl surge'],poly_df['bwl surge'], color = 'black', linestyle = 'dashed')\n",
    "\n",
    "                    plt.title('pwl surge vs bwl surge (poly)')\n",
    "\n",
    "                    plt.show()\n",
    "\n",
    "                    plt.clf()'''\n",
    "\n",
    "                    poly_df_list.append(poly_df)\n",
    "\n",
    "                    del poly_df_copy, poly, pred_values\n",
    "\n",
    "\n",
    "                else:\n",
    "                   print('Can not fill gap not enough points')\n",
    "\n",
    "\n",
    "            else:\n",
    "                print('Can not fill gap out of bounds')\n",
    "        \n",
    "        print(len(index_locations))\n",
    "        return poly_df_list, index_locations, gap_length, gap_date_list, adjustment_list\n",
    "\n",
    "\n",
    "    else:\n",
    "        print('No gaps to Fill')\n",
    "        index_locations  = []\n",
    "        gap_length = []\n",
    "        gap_date_list=[]\n",
    "\n",
    "        poly_df_list = []\n",
    "\n",
    "        return poly_df_list, index_locations, gap_length, gap_date_list\n",
    "\n",
    "def fill_gaps(poly_list, gap_dates_list, wl_df):\n",
    "    matched_dates1 = []\n",
    "    matched_dates2 = []\n",
    "\n",
    "    # Process each gap and its corresponding poly_df\n",
    "    for gap_df, poly_df in zip(gap_dates_list, poly_list):\n",
    "        # Ensure dates are in datetime format\n",
    "        gap_df['date'] = pd.to_datetime(gap_df['date'])\n",
    "        poly_df['date'] = pd.to_datetime(poly_df['date'])\n",
    "\n",
    "        # Find common dates between gap_df and poly_df\n",
    "        common_dates = gap_df['date'][gap_df['date'].isin(poly_df['date'])]\n",
    "\n",
    "        # Filter both DataFrames for the common dates\n",
    "        filtered_gap_df = gap_df[gap_df['date'].isin(common_dates)]\n",
    "        filtered_poly_df = poly_df[poly_df['date'].isin(common_dates)]\n",
    "\n",
    "        # Append the filtered DataFrames\n",
    "        matched_dates1.append(filtered_gap_df)\n",
    "        matched_dates2.append(filtered_poly_df)\n",
    "\n",
    "    # Combine all matched DataFrames\n",
    "    match_df_1 = pd.concat(matched_dates1, ignore_index=True)\n",
    "    match_df_2 = pd.concat(matched_dates2, ignore_index=True)\n",
    "\n",
    "    # Merge the poly_df data with the original wl_df\n",
    "    Wl_data_total = match_df_2.merge(wl_df, on='date', how='outer')\n",
    "\n",
    "    # Clean up columns\n",
    "    Wl_data_total = Wl_data_total.drop(columns=['bwl_x', 'pwl_x', '#date+time'], errors='ignore')\n",
    "    Wl_data_total['pwl'] = Wl_data_total.get('pwl_y', None)\n",
    "    Wl_data_total['bwl'] = Wl_data_total.get('bwl_y', None)\n",
    "    Wl_data_total = Wl_data_total.drop(columns=['pwl_y', 'bwl_y'], errors='ignore')\n",
    "\n",
    "    # Clean up memory by deleting unnecessary variables\n",
    "    del poly_list, gap_dates_list, matched_dates1, matched_dates2, match_df_1, match_df_2\n",
    "\n",
    "    return Wl_data_total  \n",
    "\n",
    "\n",
    "def adjustment(filled_df, filtered_gaps, index_locations):\n",
    "\n",
    "\n",
    "\n",
    "    average_before_gap = np.nanmean(filled_df['pwl'][(index_locations[i]-6):index_locations[i]].tolist())\n",
    "    average_after_gap = np.nanmean(filled_df['pwl'][(index_locations[i]+1+gap_length[i]):index_locations[i]+6+gap_length[i]].tolist())\n",
    "\n",
    "    n_length = gap_length[i]\n",
    "\n",
    "    for k in range(n_length):\n",
    "\n",
    "        adjustment_value = (average_after_gap + (k / n_length)) * (average_before_gap - average_after_gap)\n",
    "\n",
    "        adjustment_list.append(adjustment_value)\n",
    "\n",
    "    adj_df = pd.DataFrame()\n",
    "    adj_df['values'] = adj_list\n",
    "\n",
    "    mwl_adj_df = filled_df.dropna(subset='mwl')\n",
    "\n",
    "    mwl_adj_df['mwl adjusted'] = mwl_adj_df['mwl']\n",
    "\n",
    "    mwl_adj_df['mwl adjusted'] = mwl_adj_df['mwl adjusted'] + adj_df['values']\n",
    "\n",
    "    print(mwl_adj_df)\n",
    "\n",
    "\n",
    "    return filled_df\n",
    "        \n",
    "\n",
    "def create_gaps(dataset):\n",
    "\n",
    "    import random\n",
    "\n",
    "    wl_data =  dataset.copy() #pd.DataFrame(dataset)\n",
    "\n",
    "    random_index = [random.randint(0,len(wl_data))for _ in range(1000)]\n",
    "\n",
    "    max_gap_size = 100\n",
    "    random_index = random.sample(range(len(wl_data) - max_gap_size), 1000)\n",
    "\n",
    "\n",
    "    #create one six min gap\n",
    "\n",
    "    wl_data.loc[random_index[0], 'pwl'] = np.nan\n",
    "    random_index = random_index[1:]\n",
    "\n",
    "\n",
    "    # create 5 30 min gaps\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 4, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[5:]\n",
    "\n",
    "    #create 10 1hr gaps\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 9, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[10:]\n",
    "\n",
    "    #creates 50 5 hr gaps\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 49, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[50:]\n",
    "\n",
    "    #creates 100 10hr gaps\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 99, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[100:]\n",
    "\n",
    "\n",
    "    #print((wl_data.isna().sum()))\n",
    "\n",
    "    return wl_data\n",
    "\n",
    "def cbi_gapfill(filepath):\n",
    "\n",
    "    print('Reading dataset')\n",
    "    wl_dataset = read_wl_csv(filepath)\n",
    "\n",
    "    gaps_true = input('Do you want to create artifical gaps y/n? ')\n",
    "\n",
    "    if str(gaps_true) == str('y'):\n",
    "        \n",
    "        wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "        print('Gaps Created')\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, adjustment_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF)\n",
    "\n",
    "            adj_values = adjustment(filled_df, adjustment_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
    "        \n",
    "        else:\n",
    "            adj_values = []\n",
    "\n",
    "            return dataset_LF, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
    "\n",
    "    elif str(gaps_true) == str('n'):\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, adjustment_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF)\n",
    "\n",
    "            adj_values = adjustment(filled_df, adjustment_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
    "        \n",
    "        else:\n",
    "            adj_values = []\n",
    "\n",
    "            return dataset_LF, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
    "    else:\n",
    "        print('Not an acceptable answer')\n",
    "        dataset_LF = []\n",
    "        Wl_gaps = []\n",
    "        dataset_LF = []\n",
    "        poly_wl_list = []\n",
    "        gap_list = []\n",
    "        adj_values = []\n",
    "        \n",
    "        return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, adj_values\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "filled_df, wl_dataset, all_gaps, dataset_LF, poly_wl, filled_gap_list, adj_values = cbi_gapfill(r'C:\\Users\\mrpro\\Documents\\Code\\CBI\\Gap_Filling\\P21_2016_gaps.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mwl linear</th>\n",
       "      <th>mwl</th>\n",
       "      <th>harmwl</th>\n",
       "      <th>pwl surge</th>\n",
       "      <th>bwl surge</th>\n",
       "      <th>pwl</th>\n",
       "      <th>bwl</th>\n",
       "      <th>pwl actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.436</td>\n",
       "      <td>0.369</td>\n",
       "      <td>1.183</td>\n",
       "      <td>1.805</td>\n",
       "      <td>2.619</td>\n",
       "      <td>1.805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-01 00:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.441</td>\n",
       "      <td>0.367</td>\n",
       "      <td>1.181</td>\n",
       "      <td>1.808</td>\n",
       "      <td>2.622</td>\n",
       "      <td>1.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-01 00:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.446</td>\n",
       "      <td>0.380</td>\n",
       "      <td>1.188</td>\n",
       "      <td>1.826</td>\n",
       "      <td>2.634</td>\n",
       "      <td>1.826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-01 00:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.451</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.196</td>\n",
       "      <td>1.843</td>\n",
       "      <td>2.647</td>\n",
       "      <td>1.843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-01 00:24:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.456</td>\n",
       "      <td>0.394</td>\n",
       "      <td>1.194</td>\n",
       "      <td>1.850</td>\n",
       "      <td>2.650</td>\n",
       "      <td>1.850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87835</th>\n",
       "      <td>2016-12-31 23:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.536</td>\n",
       "      <td>0.475</td>\n",
       "      <td>1.220</td>\n",
       "      <td>2.011</td>\n",
       "      <td>2.756</td>\n",
       "      <td>2.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87836</th>\n",
       "      <td>2016-12-31 23:36:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.541</td>\n",
       "      <td>0.483</td>\n",
       "      <td>1.225</td>\n",
       "      <td>2.024</td>\n",
       "      <td>2.766</td>\n",
       "      <td>2.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87837</th>\n",
       "      <td>2016-12-31 23:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.546</td>\n",
       "      <td>0.476</td>\n",
       "      <td>1.219</td>\n",
       "      <td>2.022</td>\n",
       "      <td>2.765</td>\n",
       "      <td>2.022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87838</th>\n",
       "      <td>2016-12-31 23:48:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.551</td>\n",
       "      <td>0.478</td>\n",
       "      <td>1.219</td>\n",
       "      <td>2.029</td>\n",
       "      <td>2.770</td>\n",
       "      <td>2.029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87839</th>\n",
       "      <td>2016-12-31 23:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.556</td>\n",
       "      <td>0.485</td>\n",
       "      <td>1.221</td>\n",
       "      <td>2.041</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87840 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     date  mwl linear  mwl  harmwl  pwl surge  bwl surge  \\\n",
       "0     2016-01-01 00:00:00         NaN  NaN   1.436      0.369      1.183   \n",
       "1     2016-01-01 00:06:00         NaN  NaN   1.441      0.367      1.181   \n",
       "2     2016-01-01 00:12:00         NaN  NaN   1.446      0.380      1.188   \n",
       "3     2016-01-01 00:18:00         NaN  NaN   1.451      0.392      1.196   \n",
       "4     2016-01-01 00:24:00         NaN  NaN   1.456      0.394      1.194   \n",
       "...                   ...         ...  ...     ...        ...        ...   \n",
       "87835 2016-12-31 23:30:00         NaN  NaN   1.536      0.475      1.220   \n",
       "87836 2016-12-31 23:36:00         NaN  NaN   1.541      0.483      1.225   \n",
       "87837 2016-12-31 23:42:00         NaN  NaN   1.546      0.476      1.219   \n",
       "87838 2016-12-31 23:48:00         NaN  NaN   1.551      0.478      1.219   \n",
       "87839 2016-12-31 23:54:00         NaN  NaN   1.556      0.485      1.221   \n",
       "\n",
       "         pwl    bwl  pwl actual  \n",
       "0      1.805  2.619       1.805  \n",
       "1      1.808  2.622       1.808  \n",
       "2      1.826  2.634       1.826  \n",
       "3      1.843  2.647       1.843  \n",
       "4      1.850  2.650       1.850  \n",
       "...      ...    ...         ...  \n",
       "87835  2.011  2.756       2.011  \n",
       "87836  2.024  2.766       2.024  \n",
       "87837  2.022  2.765       2.022  \n",
       "87838  2.029  2.770       2.029  \n",
       "87839  2.041  2.777       2.041  \n",
       "\n",
       "[87840 rows x 9 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df['pwl actual'] = wl_dataset['pwl']\n",
    "filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mwl adjusted'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\mrpro\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mwl adjusted'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[155], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m((filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmwl\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwl actual\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwl actual\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[1;32m----> 2\u001b[0m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madjusted error\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mabs\u001b[39m((filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmwl adjusted\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m-\u001b[39m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwl actual\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m/\u001b[39m filled_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpwl actual\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m\n\u001b[0;32m      3\u001b[0m filled_df\n",
      "File \u001b[1;32mc:\\Users\\mrpro\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\mrpro\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'mwl adjusted'"
     ]
    }
   ],
   "source": [
    "filled_df['error'] = abs((filled_df['mwl'] - filled_df['pwl actual']) / filled_df['pwl actual']) *100\n",
    "filled_df['adjusted error'] = abs((filled_df['mwl adjusted'] - filled_df['pwl actual']) / filled_df['pwl actual']) *100\n",
    "filled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mwl linear</th>\n",
       "      <th>mwl</th>\n",
       "      <th>harmwl</th>\n",
       "      <th>pwl surge</th>\n",
       "      <th>bwl surge</th>\n",
       "      <th>pwl</th>\n",
       "      <th>bwl</th>\n",
       "      <th>mwl adjusted</th>\n",
       "      <th>pwl actual</th>\n",
       "      <th>error</th>\n",
       "      <th>adjusted error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>2016-01-15 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.386</td>\n",
       "      <td>0.423</td>\n",
       "      <td>1.242</td>\n",
       "      <td>1.809</td>\n",
       "      <td>2.628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.809</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>2016-01-15 23:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.391</td>\n",
       "      <td>0.406</td>\n",
       "      <td>1.228</td>\n",
       "      <td>1.797</td>\n",
       "      <td>2.619</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.797</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>2016-01-15 23:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.395</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.236</td>\n",
       "      <td>1.811</td>\n",
       "      <td>2.631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.811</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>2016-01-15 23:18:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.400</td>\n",
       "      <td>0.442</td>\n",
       "      <td>1.256</td>\n",
       "      <td>1.842</td>\n",
       "      <td>2.656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.842</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3594</th>\n",
       "      <td>2016-01-15 23:24:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.405</td>\n",
       "      <td>0.433</td>\n",
       "      <td>1.249</td>\n",
       "      <td>1.838</td>\n",
       "      <td>2.654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.838</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3595</th>\n",
       "      <td>2016-01-15 23:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.410</td>\n",
       "      <td>0.409</td>\n",
       "      <td>1.229</td>\n",
       "      <td>1.819</td>\n",
       "      <td>2.639</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.819</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3596</th>\n",
       "      <td>2016-01-15 23:36:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.415</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.637</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3597</th>\n",
       "      <td>2016-01-15 23:42:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.420</td>\n",
       "      <td>0.401</td>\n",
       "      <td>1.223</td>\n",
       "      <td>1.821</td>\n",
       "      <td>2.643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3598</th>\n",
       "      <td>2016-01-15 23:48:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.425</td>\n",
       "      <td>0.402</td>\n",
       "      <td>1.222</td>\n",
       "      <td>1.827</td>\n",
       "      <td>2.647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.827</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>2016-01-15 23:54:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.430</td>\n",
       "      <td>0.392</td>\n",
       "      <td>1.215</td>\n",
       "      <td>1.822</td>\n",
       "      <td>2.645</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3600</th>\n",
       "      <td>2016-01-16 00:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.435</td>\n",
       "      <td>0.387</td>\n",
       "      <td>1.209</td>\n",
       "      <td>1.822</td>\n",
       "      <td>2.644</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.822</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3601</th>\n",
       "      <td>2016-01-16 00:06:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.440</td>\n",
       "      <td>0.376</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.640</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.816</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    date  mwl linear  mwl  harmwl  pwl surge  bwl surge  \\\n",
       "3590 2016-01-15 23:00:00         NaN  NaN   1.386      0.423      1.242   \n",
       "3591 2016-01-15 23:06:00         NaN  NaN   1.391      0.406      1.228   \n",
       "3592 2016-01-15 23:12:00         NaN  NaN   1.395      0.416      1.236   \n",
       "3593 2016-01-15 23:18:00         NaN  NaN   1.400      0.442      1.256   \n",
       "3594 2016-01-15 23:24:00         NaN  NaN   1.405      0.433      1.249   \n",
       "3595 2016-01-15 23:30:00         NaN  NaN   1.410      0.409      1.229   \n",
       "3596 2016-01-15 23:36:00         NaN  NaN   1.415      0.401      1.222   \n",
       "3597 2016-01-15 23:42:00         NaN  NaN   1.420      0.401      1.223   \n",
       "3598 2016-01-15 23:48:00         NaN  NaN   1.425      0.402      1.222   \n",
       "3599 2016-01-15 23:54:00         NaN  NaN   1.430      0.392      1.215   \n",
       "3600 2016-01-16 00:00:00         NaN  NaN   1.435      0.387      1.209   \n",
       "3601 2016-01-16 00:06:00         NaN  NaN   1.440      0.376      1.200   \n",
       "\n",
       "        pwl    bwl  mwl adjusted  pwl actual  error  adjusted error  \n",
       "3590  1.809  2.628           NaN       1.809    NaN             NaN  \n",
       "3591  1.797  2.619           NaN       1.797    NaN             NaN  \n",
       "3592  1.811  2.631           NaN       1.811    NaN             NaN  \n",
       "3593  1.842  2.656           NaN       1.842    NaN             NaN  \n",
       "3594  1.838  2.654           NaN       1.838    NaN             NaN  \n",
       "3595  1.819  2.639           NaN       1.819    NaN             NaN  \n",
       "3596  1.816  2.637           NaN       1.816    NaN             NaN  \n",
       "3597  1.821  2.643           NaN       1.821    NaN             NaN  \n",
       "3598  1.827  2.647           NaN       1.827    NaN             NaN  \n",
       "3599  1.822  2.645           NaN       1.822    NaN             NaN  \n",
       "3600  1.822  2.644           NaN       1.822    NaN             NaN  \n",
       "3601  1.816  2.640           NaN       1.816    NaN             NaN  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df[3590:3602]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>mwl linear</th>\n",
       "      <th>mwl</th>\n",
       "      <th>harmwl</th>\n",
       "      <th>pwl surge</th>\n",
       "      <th>bwl surge</th>\n",
       "      <th>pwl</th>\n",
       "      <th>bwl</th>\n",
       "      <th>mwl adjusted</th>\n",
       "      <th>pwl actual</th>\n",
       "      <th>error</th>\n",
       "      <th>adjusted error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87840</td>\n",
       "      <td>5809.000000</td>\n",
       "      <td>5809.000000</td>\n",
       "      <td>87840.000000</td>\n",
       "      <td>86132.000000</td>\n",
       "      <td>86275.000000</td>\n",
       "      <td>74489.000000</td>\n",
       "      <td>86275.000000</td>\n",
       "      <td>5580.000000</td>\n",
       "      <td>86132.000000</td>\n",
       "      <td>5702.000000</td>\n",
       "      <td>5473.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-07-01 23:57:00</td>\n",
       "      <td>1.838498</td>\n",
       "      <td>1.838144</td>\n",
       "      <td>1.555959</td>\n",
       "      <td>0.263662</td>\n",
       "      <td>1.062536</td>\n",
       "      <td>1.817205</td>\n",
       "      <td>2.617894</td>\n",
       "      <td>1.755798</td>\n",
       "      <td>1.818899</td>\n",
       "      <td>0.285444</td>\n",
       "      <td>21.539753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.890919</td>\n",
       "      <td>0.892175</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-1.609000</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.547577</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.001188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016-04-01 11:58:30</td>\n",
       "      <td>1.697219</td>\n",
       "      <td>1.696844</td>\n",
       "      <td>1.458000</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>1.693000</td>\n",
       "      <td>2.526000</td>\n",
       "      <td>1.335584</td>\n",
       "      <td>1.692000</td>\n",
       "      <td>0.108294</td>\n",
       "      <td>8.376366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-07-01 23:57:00</td>\n",
       "      <td>1.854125</td>\n",
       "      <td>1.854986</td>\n",
       "      <td>1.572000</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>1.056000</td>\n",
       "      <td>1.834000</td>\n",
       "      <td>2.628000</td>\n",
       "      <td>1.749761</td>\n",
       "      <td>1.835000</td>\n",
       "      <td>0.231685</td>\n",
       "      <td>20.071090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-10-01 11:55:30</td>\n",
       "      <td>1.995413</td>\n",
       "      <td>1.995399</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>1.128000</td>\n",
       "      <td>1.962000</td>\n",
       "      <td>2.722000</td>\n",
       "      <td>2.112593</td>\n",
       "      <td>1.966000</td>\n",
       "      <td>0.390440</td>\n",
       "      <td>31.703504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016-12-31 23:54:00</td>\n",
       "      <td>2.310423</td>\n",
       "      <td>2.313729</td>\n",
       "      <td>1.917000</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.593000</td>\n",
       "      <td>2.507000</td>\n",
       "      <td>3.124000</td>\n",
       "      <td>3.302941</td>\n",
       "      <td>2.507000</td>\n",
       "      <td>2.583990</td>\n",
       "      <td>70.952498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220967</td>\n",
       "      <td>0.221213</td>\n",
       "      <td>0.158702</td>\n",
       "      <td>0.147163</td>\n",
       "      <td>0.115146</td>\n",
       "      <td>0.220411</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.520910</td>\n",
       "      <td>0.220358</td>\n",
       "      <td>0.240393</td>\n",
       "      <td>15.285675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date   mwl linear          mwl        harmwl  \\\n",
       "count                87840  5809.000000  5809.000000  87840.000000   \n",
       "mean   2016-07-01 23:57:00     1.838498     1.838144      1.555959   \n",
       "min    2016-01-01 00:00:00     0.890919     0.892175      1.035000   \n",
       "25%    2016-04-01 11:58:30     1.697219     1.696844      1.458000   \n",
       "50%    2016-07-01 23:57:00     1.854125     1.854986      1.572000   \n",
       "75%    2016-10-01 11:55:30     1.995413     1.995399      1.675000   \n",
       "max    2016-12-31 23:54:00     2.310423     2.313729      1.917000   \n",
       "std                    NaN     0.220967     0.221213      0.158702   \n",
       "\n",
       "          pwl surge     bwl surge           pwl           bwl  mwl adjusted  \\\n",
       "count  86132.000000  86275.000000  74489.000000  86275.000000   5580.000000   \n",
       "mean       0.263662      1.062536      1.817205      2.617894      1.755798   \n",
       "min       -0.617000     -1.609000      0.585000      0.000000      0.547577   \n",
       "25%        0.187000      0.994000      1.693000      2.526000      1.335584   \n",
       "50%        0.262000      1.056000      1.834000      2.628000      1.749761   \n",
       "75%        0.342000      1.128000      1.962000      2.722000      2.112593   \n",
       "max        0.894000      1.593000      2.507000      3.124000      3.302941   \n",
       "std        0.147163      0.115146      0.220411      0.158955      0.520910   \n",
       "\n",
       "         pwl actual        error  adjusted error  \n",
       "count  86132.000000  5702.000000     5473.000000  \n",
       "mean       1.818899     0.285444       21.539753  \n",
       "min        0.585000     0.000024        0.001188  \n",
       "25%        1.692000     0.108294        8.376366  \n",
       "50%        1.835000     0.231685       20.071090  \n",
       "75%        1.966000     0.390440       31.703504  \n",
       "max        2.507000     2.583990       70.952498  \n",
       "std        0.220358     0.240393       15.285675  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
