{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  163\n",
      "Number of Linear Gaps filled: 5\n",
      "Single gaps filled\n",
      "132\n",
      "Number of gaps with backup water level: 132\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Gaps filled 128\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def read_wl_csv(file_path):\n",
    "    wl_df = pd.read_csv(file_path)\n",
    "\n",
    "    ##### if the csv is from lighthouse then this drop function is always true\n",
    "    ##### if the csv is not from lighthouse then you will need to modify the function\n",
    "\n",
    "    wl_df.drop(labels=range(len(wl_df)-6,len(wl_df)), axis=0, inplace=True)\n",
    "\n",
    "    keys = wl_df.keys().to_list()\n",
    "    \n",
    "    wl_df['date'] = pd.to_datetime(wl_df[keys[0]])\n",
    "    wl_df[keys[1]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[2]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[3]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df['pwl'] = pd.to_numeric(wl_df[keys[1]],errors= 'coerce')\n",
    "    wl_df['bwl'] = pd.to_numeric(wl_df[keys[2]],errors= 'coerce')\n",
    "    wl_df['harmwl'] = pd.to_numeric(wl_df[keys[3]],errors= 'coerce')\n",
    "    wl_df['pwl surge'] = wl_df['pwl'] - wl_df['harmwl']\n",
    "    wl_df['bwl surge'] = wl_df['bwl'] - wl_df['harmwl']\n",
    "    wl_df = wl_df.drop(columns=keys[0],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[1],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[2],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[3],axis=0)\n",
    "    del keys\n",
    "    return wl_df\n",
    "\n",
    "def locate_gaps(WL_data):\n",
    "    lengthMissVal = []\n",
    "    dates = []\n",
    "    count = 0\n",
    "    for i in range(len(WL_data)):\n",
    "        if pd.isna(WL_data['pwl'][i]):\n",
    "            if count == 0:  # Start of a new NaN gap\n",
    "                dates.append(WL_data['date'][i])  # Record the start date of the gap\n",
    "            count += 1  # Increment the gap length\n",
    "\n",
    "        else:\n",
    "            if count > 0:  # End of a NaN gap\n",
    "                lengthMissVal.append(count)\n",
    "                count = 0  # Reset count after recording the gap length\n",
    "    if count > 0:\n",
    "        lengthMissVal.append(count)\n",
    "\n",
    "    # Finalize the DataFrame\n",
    "    WL_data_gaps = pd.DataFrame()\n",
    "    WL_data_gaps['date'] = pd.to_datetime(dates)\n",
    "    WL_data_gaps['gapLength'] = lengthMissVal\n",
    "    WL_data_gaps['gapTime(min)'] = WL_data_gaps['gapLength'] * 6\n",
    "\n",
    "    del lengthMissVal,dates,count\n",
    "\n",
    "    return WL_data_gaps\n",
    "\n",
    "def eligible_gap_length(WL_gaps): #Function to sort the lengh of the gaps into three categories\n",
    "    WL_gaps_filter_6min = WL_gaps['gapLength'] == 1\n",
    "    WL_gaps_filter = (WL_gaps['gapLength'] <= 576) & (WL_gaps['gapLength'] > 1)\n",
    "\n",
    "    #filters the data into individual dataframes\n",
    "    linear_gaps = WL_gaps[WL_gaps_filter_6min]\n",
    "    gaps_less_5_days = WL_gaps[WL_gaps_filter]\n",
    "\n",
    "    del WL_gaps_filter,WL_gaps_filter_6min\n",
    "\n",
    "    return linear_gaps,gaps_less_5_days\n",
    "\n",
    "\n",
    "def linear_fill(Wl_data,linear_gaps): #function to fill in gaps with length of 1 using linear approach\n",
    "\n",
    "    if len(linear_gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(linear_gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "            new_value = ((Wl_data.loc[(index_locations[i])-1,'pwl surge']+ Wl_data.loc[index_locations[i]+1,'pwl surge']) / 2) + Wl_data.loc[index_locations[i],'harmwl']\n",
    "            Wl_data.loc[index_locations[i],'pwl'] = new_value\n",
    "\n",
    "        del matching_dates, index_locations, new_value\n",
    "        \n",
    "        return Wl_data\n",
    "    \n",
    "    else:\n",
    "        print('No single gaps to fill')\n",
    "\n",
    "        return Wl_data\n",
    "\n",
    "\n",
    "def check_bwl(Wl_data,gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        valid_gaps = []\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            is_valid = Wl_data['bwl'][index_locations[i]:index_locations[i]+gap_length[i]].isna().sum() == 0\n",
    "            valid_gaps.append(is_valid)\n",
    "        \n",
    "        filtered_gaps = gaps[valid_gaps].reset_index(drop=True)\n",
    "\n",
    "        del matching_dates, index_locations, gap_length, valid_gaps, is_valid\n",
    "\n",
    "        print(len(filtered_gaps))\n",
    "\n",
    "        return filtered_gaps\n",
    "    \n",
    "    else:\n",
    "        print('No gaps avaliable to fill')\n",
    "\n",
    "        return gaps\n",
    "\n",
    "\n",
    "def poly_gap_fill(Wl_data, gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        poly_df_list = []\n",
    "\n",
    "        gap_date_list = []\n",
    "\n",
    "        poly_filled_gaps = []\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        for i in range(len(matching_dates)):\n",
    "\n",
    "            gap_date_df = pd.DataFrame()\n",
    "\n",
    "            gap_date_df['date'] = Wl_data['date'][index_locations[i]:index_locations[i]+gap_length[i]]\n",
    "\n",
    "            gap_date_list.append(gap_date_df)\n",
    "            \n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            if index_locations[i]- 2161  > 0 and index_locations[i]+2161+gap_length[i] < len(Wl_data):\n",
    "\n",
    "                pwl_30_days = Wl_data['pwl'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                bwl_30_days = Wl_data['bwl'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                dates = Wl_data['date'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                linear_df = pd.DataFrame()\n",
    "\n",
    "                linear_df['pwl 30'] = pwl_30_days\n",
    "                linear_df['bwl 30'] = bwl_30_days\n",
    "                linear_df['dates'] = dates\n",
    "\n",
    "                linear_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "                slope, intercept, *_ = stats.linregress(linear_df['bwl 30'],linear_df['pwl 30'])\n",
    "\n",
    "                poly_df = pd.DataFrame({'bwl': bwl_30_days, 'pwl': pwl_30_days,'date' : pd.to_datetime(dates)})\n",
    "\n",
    "                poly_df['mwl linear'] = intercept + slope*poly_df['bwl']\n",
    "\n",
    "                mask = abs(poly_df['mwl linear'] - poly_df['pwl']) > 0.1\n",
    "                \n",
    "                poly_df.loc[mask, 'pwl'] = np.nan\n",
    "                poly_df.loc[mask, 'mwl linear'] = np.nan\n",
    "                poly_df.loc[mask, 'bwl'] = np.nan\n",
    "\n",
    "                if poly_df['bwl'].isna().sum() + poly_df['pwl'].isna().sum() < len(Wl_data)*0.1:\n",
    "\n",
    "                    poly_df_copy = poly_df.copy()\n",
    "\n",
    "                    poly_df_copy.dropna(inplace=True)\n",
    "\n",
    "                    poly =np.polynomial.polynomial.Polynomial.fit(poly_df_copy['pwl'],poly_df_copy['bwl'],4)\n",
    "\n",
    "                    coeffs = np.polyfit(poly_df_copy['bwl'],poly_df_copy['pwl'],4)\n",
    "\n",
    "                    poly1 = np.poly1d(coeffs)\n",
    "\n",
    "                    pred_values = poly1(poly_df['bwl'])\n",
    "\n",
    "                    poly_df['mwl'] = pred_values\n",
    "\n",
    "                    poly_df_list.append(poly_df)\n",
    "\n",
    "                    poly_filled_gaps.append((index_locations[i], gap_length[i]))\n",
    "\n",
    "                    del poly_df_copy, poly, pred_values\n",
    "\n",
    "                else:\n",
    "                   print('Can not fill gap not enough points')\n",
    "\n",
    "            else:\n",
    "                print('Can not fill gap out of bounds')\n",
    "\n",
    "        return poly_df_list, index_locations, gap_length, gap_date_list, poly_filled_gaps\n",
    "\n",
    "    else:\n",
    "        print('No gaps to Fill')\n",
    "\n",
    "        return [],[],[],[],[]\n",
    "\n",
    "def fill_gaps(poly_list, gap_dates_list, wl_df, poly_gap_list):\n",
    "\n",
    "    wl_df['mwl'] = np.nan\n",
    "\n",
    "    for i, (idx, length) in enumerate(poly_gap_list):\n",
    "\n",
    "        poly_df = poly_list[i]\n",
    "\n",
    "        gap_values = poly_df.loc[2160:2160+length, 'mwl'].values\n",
    "\n",
    "        wl_df.loc[idx:idx+length, 'mwl'] = gap_values\n",
    "\n",
    "    return wl_df\n",
    "\n",
    "def adjustment(filled_df, poly_gaps):\n",
    "\n",
    "\n",
    "    filled_df['mwl adjusted'] = np.nan\n",
    "    idx, length = map(list, zip(*poly_gaps))\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        adjustment_values = []\n",
    "\n",
    "        # Calculate averages before and after the gap\n",
    "        average_before = np.nanmean(filled_df['pwl'][idx[i] - 6:idx[i]])\n",
    "        average_after = np.nanmean(filled_df['pwl'][idx[i] + length[i]:idx[i] + length[i] + 6])\n",
    "\n",
    "        n_length = length[i]\n",
    "\n",
    "        for k in range(n_length):\n",
    "            value = (average_after + (k / n_length)) * (average_before - average_after)\n",
    "            adjustment_values.append(value)\n",
    "\n",
    "        filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl adjusted'] = (\n",
    "            filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl'] + adjustment_values\n",
    "        )\n",
    "\n",
    "    filled_df['new wl adjustment'] = filled_df['pwl'].combine_first(filled_df['mwl adjusted'])\n",
    "    filled_df['new wl'] = filled_df['pwl'].combine_first(filled_df['mwl'])\n",
    "    return filled_df\n",
    "\n",
    "        \n",
    "\n",
    "def create_gaps(dataset):\n",
    "\n",
    "    import random\n",
    "\n",
    "    wl_data =  dataset.copy() #pd.DataFrame(dataset)\n",
    "\n",
    "    random_index = [random.randint(0,len(wl_data))for _ in range(1000)]\n",
    "\n",
    "    max_gap_size = 100\n",
    "    random_index = random.sample(range(len(wl_data) - max_gap_size), 1000)\n",
    "\n",
    "\n",
    "    #create one six min gap\n",
    "\n",
    "    wl_data.loc[random_index[0], 'pwl'] = np.nan\n",
    "    random_index = random_index[1:]\n",
    "\n",
    "\n",
    "    # create 5 30 min gaps\n",
    "\n",
    "    for i in range(5):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 4, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[5:]\n",
    "\n",
    "    #create 10 1hr gaps\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 9, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[10:]\n",
    "\n",
    "    #creates 50 5 hr gaps\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 49, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[50:]\n",
    "\n",
    "    #creates 100 10hr gaps\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 99, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[100:]\n",
    "\n",
    "\n",
    "    #print((wl_data.isna().sum()))\n",
    "\n",
    "    return wl_data\n",
    "\n",
    "def cbi_gapfill(filepath):\n",
    "\n",
    "    print('Reading dataset')\n",
    "    wl_dataset = read_wl_csv(filepath)\n",
    "\n",
    "    gaps_true = input('Do you want to create artifical gaps y/n? ')\n",
    "\n",
    "    if str(gaps_true) == str('y'):\n",
    "        \n",
    "        wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "        print('Gaps Created')\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "            filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        \n",
    "        else:\n",
    "            #adj_values = []\n",
    "\n",
    "            return dataset_LF, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list\n",
    "\n",
    "    elif str(gaps_true) == str('n'):\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "            filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "    else:\n",
    "        print('Not an acceptable answer')\n",
    "        dataset_LF = []\n",
    "        Wl_gaps = []\n",
    "        dataset_LF = []\n",
    "        poly_wl_list = []\n",
    "        gap_list = []\n",
    "        poly_gap_list = []\n",
    "        \n",
    "        return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "filled_df, wl_dataset, all_gaps, dataset_LF, poly_wl, filled_gap_list, poly_gap_list = cbi_gapfill(r'/Users/rprocious/Waterlevels_CBI/CBI-2/Gap_Filling/pd_1732208271.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
