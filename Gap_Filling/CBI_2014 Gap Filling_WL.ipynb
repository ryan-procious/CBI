{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_wl_csv(file_path):\n",
    "    # Directly skip the last 6 footer lines and parse the first column as dates.\n",
    "    # Also mark invalid values as NaN during read.\n",
    "    wl_df = pd.read_csv(\n",
    "        file_path,\n",
    "        parse_dates=[0],\n",
    "        na_values=[-999, -99, 99, 'NA', 'RM'],\n",
    "        skipfooter=6,     # Skips the last 6 lines\n",
    "        engine='python'   \n",
    "    )\n",
    "\n",
    "    wl_df.columns = ['date', 'pwl', 'bwl', 'harmwl']\n",
    "\n",
    "    # Calculate surges\n",
    "    wl_df['pwl surge'] = wl_df['pwl'] - wl_df['harmwl']\n",
    "    wl_df['bwl surge'] = wl_df['bwl'] - wl_df['harmwl']\n",
    "\n",
    "    return wl_df\n",
    "\n",
    "def locate_gaps(WL_data):\n",
    "    # Boolean mask where 'pwl' is NaN\n",
    "    mask = WL_data['pwl'].isna()\n",
    "    \n",
    "    # Identify the start of each gap\n",
    "    # A gap starts when current row is NaN but previous row is not NaN.\n",
    "    gap_starts = mask & ~mask.shift(fill_value=False)\n",
    "    \n",
    "    # Identify the end of each gap\n",
    "    # A gap ends when current row is NaN but next row is not NaN.\n",
    "    gap_ends = mask & ~mask.shift(-1, fill_value=False)\n",
    "    \n",
    "    # Get the indices of the start and end of each gap\n",
    "    start_indices = WL_data.index[gap_starts]\n",
    "    end_indices = WL_data.index[gap_ends]\n",
    "    \n",
    "    # Calculate gap lengths (number of consecutive NaN entries)\n",
    "    gap_lengths = end_indices.values - start_indices.values + 1\n",
    "    \n",
    "    # Get corresponding start dates of each gap\n",
    "    start_dates = WL_data.loc[start_indices, 'date'].reset_index(drop=True)\n",
    "    \n",
    "    # Create the resulting DataFrame\n",
    "    WL_data_gaps = pd.DataFrame({\n",
    "        'date': start_dates,\n",
    "        'gapLength': gap_lengths\n",
    "    })\n",
    "    # Calculate total gap time in minutes (assuming each row represents 6 minutes)\n",
    "    WL_data_gaps['gapTime(min)'] = WL_data_gaps['gapLength'] * 6\n",
    "    \n",
    "    return WL_data_gaps\n",
    "\n",
    "def eligible_gap_length(WL_gaps):\n",
    "    # Select gaps of length exactly 1\n",
    "    linear_gaps = WL_gaps[WL_gaps['gapLength'] == 1]\n",
    "    \n",
    "    # Select gaps of length >1 but <= 576\n",
    "    gaps_less_5_days = WL_gaps[(WL_gaps['gapLength'] > 1) & (WL_gaps['gapLength'] <= 576)]\n",
    "\n",
    "    return linear_gaps, gaps_less_5_days\n",
    "\n",
    "def linear_fill(Wl_data, linear_gaps):\n",
    "    # If there are no single-length gaps, just return the original data\n",
    "    if linear_gaps.empty:\n",
    "        print('No single gaps to fill')\n",
    "        return Wl_data\n",
    "\n",
    "    # Get the indices of the rows in Wl_data that correspond to the single-gap dates\n",
    "    matching_idx = Wl_data[Wl_data['date'].isin(linear_gaps['date'])].index\n",
    "\n",
    "    # Calculate the new values in a vectorized manner\n",
    "    prev_surge = Wl_data.loc[matching_idx - 1, 'pwl surge'].values\n",
    "    next_surge = Wl_data.loc[matching_idx + 1, 'pwl surge'].values\n",
    "    harmwl_values = Wl_data.loc[matching_idx, 'harmwl'].values\n",
    "\n",
    "    new_values = ((prev_surge + next_surge) / 2) + harmwl_values\n",
    "\n",
    "    # Assign the calculated values back to the 'pwl' column\n",
    "    Wl_data.loc[matching_idx, 'pwl'] = new_values\n",
    "\n",
    "    return Wl_data\n",
    "\n",
    "\n",
    "def check_bwl(Wl_data, gaps):\n",
    "    if gaps.empty:\n",
    "        print('No gaps available to fill')\n",
    "        return gaps\n",
    "\n",
    "    # Extract the indexes and lengths of the gaps\n",
    "    matching_idx = Wl_data[Wl_data['date'].isin(gaps['date'])].index\n",
    "    gap_lengths = gaps['gapLength'].values\n",
    "\n",
    "    # Check each gap for completeness in the 'bwl' column\n",
    "    valid_gaps = [\n",
    "        Wl_data['bwl'].iloc[start: start + length].notna().all()\n",
    "        for start, length in zip(matching_idx, gap_lengths)\n",
    "    ]\n",
    "\n",
    "    # Filter gaps based on whether 'bwl' had no missing values\n",
    "    filtered_gaps = gaps[valid_gaps].reset_index(drop=True)\n",
    "\n",
    "    return filtered_gaps\n",
    "\n",
    "\n",
    "def poly_gap_fill(Wl_data, gaps):\n",
    "    # If no gaps, no need to process further\n",
    "    if gaps.empty:\n",
    "        print('No gaps to Fill')\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    # Extract relevant arrays and indices\n",
    "    Wl_date = Wl_data['date'].values\n",
    "    Wl_pwl = Wl_data['pwl'].values\n",
    "    Wl_bwl = Wl_data['bwl'].values\n",
    "    Wl_index = Wl_data.index\n",
    "\n",
    "    # Extract gaps info\n",
    "    gap_dates = gaps['date'].values\n",
    "    gap_lengths = gaps['gapLength'].values\n",
    "\n",
    "    # Identify indices in Wl_data that correspond to the gap start dates\n",
    "    # Since we're using isin, which might not preserve order perfectly in some edge cases,\n",
    "    # we assume that the order of gap_dates corresponds to the same order in Wl_data.\n",
    "    # If order is critical, you might need a more robust approach.\n",
    "    matching_mask = np.isin(Wl_date, gap_dates)\n",
    "    index_locations = Wl_index[matching_mask].to_numpy()\n",
    "\n",
    "    poly_df_list = []\n",
    "    gap_date_list = []\n",
    "    poly_filled_gaps = []\n",
    "\n",
    "    # Create a list of gap-date sub-dataframes (just the dates)\n",
    "    for start_idx, length in zip(index_locations, gap_lengths):\n",
    "        gap_date_df = pd.DataFrame({\n",
    "            'date': Wl_date[start_idx:start_idx + length]\n",
    "        })\n",
    "        gap_date_list.append(gap_date_df)\n",
    "\n",
    "    # Process each gap\n",
    "    for (start_idx, length) in zip(index_locations, gap_lengths):\n",
    "        # Bound check for the Â±2160 window\n",
    "        left_bound = start_idx - 2160\n",
    "        right_bound = start_idx + 2160 + length\n",
    "        \n",
    "        if left_bound < 0 or right_bound > len(Wl_data):\n",
    "            print('Cannot fill gap out of bounds')\n",
    "            continue\n",
    "\n",
    "        pwl_30 = Wl_pwl[left_bound:right_bound]\n",
    "        bwl_30 = Wl_bwl[left_bound:right_bound]\n",
    "        dates_30 = Wl_date[left_bound:right_bound]\n",
    "\n",
    "        # Create a temporary DataFrame\n",
    "        linear_df = pd.DataFrame({\n",
    "            'pwl 30': pwl_30,\n",
    "            'bwl 30': bwl_30,\n",
    "            'dates': pd.to_datetime(dates_30)\n",
    "        })\n",
    "        linear_df.dropna(inplace=True)\n",
    "\n",
    "        if linear_df.empty:\n",
    "            print('Cannot fill gap, no valid data in 30-day window')\n",
    "            continue\n",
    "\n",
    "        # Linear regression (bwl_30 vs pwl_30)\n",
    "        slope, intercept, *_ = stats.linregress(linear_df['bwl 30'], linear_df['pwl 30'])\n",
    "\n",
    "        poly_df = pd.DataFrame({\n",
    "            'bwl': bwl_30,\n",
    "            'pwl': pwl_30,\n",
    "            'date': pd.to_datetime(dates_30)\n",
    "        })\n",
    "\n",
    "        poly_df['mwl linear'] = intercept + slope * poly_df['bwl']\n",
    "\n",
    "        # Mask where linear fit differs from actual pwl by more than 0.1\n",
    "        mask = np.abs(poly_df['mwl linear'] - poly_df['pwl']) > 0.1\n",
    "        poly_df.loc[mask, ['pwl', 'mwl linear', 'bwl']] = np.nan\n",
    "\n",
    "        # Check if there are enough valid points\n",
    "        if poly_df['bwl'].isna().sum() + poly_df['pwl'].isna().sum() < len(Wl_data) * 0.1:\n",
    "            poly_df_copy = poly_df.dropna().copy()\n",
    "            if poly_df_copy.empty:\n",
    "                print('Cannot fill gap, no valid data after filtering')\n",
    "                continue\n",
    "\n",
    "            # Fit polynomial of degree 4 (pwl as a function of bwl)\n",
    "            # Note: We're fitting pwl vs bwl but naming poly1 accordingly.\n",
    "            coeffs = np.polyfit(poly_df_copy['bwl'], poly_df_copy['pwl'], 4)\n",
    "            poly1 = np.poly1d(coeffs)\n",
    "            pred_values = poly1(poly_df['bwl'])\n",
    "\n",
    "            poly_df['mwl'] = pred_values\n",
    "            poly_df_list.append(poly_df)\n",
    "            poly_filled_gaps.append((start_idx, length))\n",
    "        else:\n",
    "            print('Cannot fill gap, not enough valid points after filtering')\n",
    "\n",
    "    return poly_df_list, index_locations, gap_lengths, gap_date_list, poly_filled_gaps\n",
    "\n",
    "def fill_gaps(poly_list, gap_dates_list, wl_df, poly_gap_list):\n",
    "    # Add mwl column if not already present\n",
    "    if 'mwl' not in wl_df.columns:\n",
    "        wl_df['mwl'] = np.nan\n",
    "\n",
    "    # For each gap to be filled\n",
    "    for i, (idx, length) in enumerate(poly_gap_list):\n",
    "        poly_df = poly_list[i]\n",
    "\n",
    "        # Compute start and end indices for poly_df slice\n",
    "        start = 2160\n",
    "        end = 2160 + length\n",
    "\n",
    "        # Extract gap values as a numpy array\n",
    "        gap_values = poly_df['mwl'].iloc[start:end].to_numpy()\n",
    "\n",
    "        # Assign these values back to wl_df using iloc for clarity\n",
    "        wl_df.iloc[idx:idx+length, wl_df.columns.get_loc('mwl')] = gap_values\n",
    "\n",
    "    return wl_df\n",
    "\n",
    "\n",
    "def adjustment(filled_df, poly_gaps):\n",
    "\n",
    "\n",
    "    filled_df['mwl adjusted'] = np.nan\n",
    "    idx, length = map(list, zip(*poly_gaps))\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        adjustment_values = []\n",
    "\n",
    "        # Calculate averages before and after the gap\n",
    "        average_before = np.nanmean(filled_df['pwl'][idx[i] - 6:idx[i]])\n",
    "        average_after = np.nanmean(filled_df['pwl'][idx[i] + length[i]:idx[i] + length[i] + 6])\n",
    "\n",
    "        n_length = length[i]\n",
    "\n",
    "        for k in range(n_length):\n",
    "            value = (average_after + (k+1 / n_length)) * (average_before - average_after)\n",
    "            adjustment_values.append(value)\n",
    "\n",
    "        filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl adjusted'] = (\n",
    "            filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl'] + adjustment_values\n",
    "        )\n",
    "\n",
    "    filled_df['new wl adjustment'] = filled_df['pwl'].combine_first(filled_df['mwl adjusted'])\n",
    "    filled_df['new wl'] = filled_df['pwl'].combine_first(filled_df['mwl'])\n",
    "    return filled_df\n",
    "\n",
    "        \n",
    "\n",
    "def create_gaps(dataset):\n",
    "\n",
    "    import random\n",
    "\n",
    "    wl_data =  dataset.copy()\n",
    "\n",
    "    random_index = [random.randint(0,len(wl_data))for _ in range(1000)]\n",
    "\n",
    "    max_gap_size = 100\n",
    "    random_index = random.sample(range(len(wl_data) - max_gap_size), 1000)\n",
    "\n",
    "\n",
    "    #create one six min gap\n",
    "\n",
    "    wl_data.loc[random_index[0], 'pwl'] = np.nan\n",
    "    random_index = random_index[1:]\n",
    "\n",
    "    # create 5 30 min gaps\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 4, 'pwl'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[100:]\n",
    "\n",
    "    #create 10 1hr gaps\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 9, 'pwl'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[10:]\n",
    "\n",
    "    #creates 50 5 hr gaps\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 49, 'pwl'] = np.nan\n",
    "    \n",
    "    random_index = random_index[50:]\n",
    "\n",
    "    #creates 100 10hr gaps\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 99, 'pwl'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[10:]\n",
    "\n",
    "    return wl_data\n",
    "\n",
    "def cbi_gapfill(filepath):\n",
    "\n",
    "    print('Reading dataset')\n",
    "    wl_dataset = read_wl_csv(filepath)\n",
    "\n",
    "    wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "    print('Gaps Created')\n",
    "\n",
    "    Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "    print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "    linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "    print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "    dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "    print('Single gaps filled')\n",
    "\n",
    "    valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "    print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "    if len(valid_multi_gaps) > 0:\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "            filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "    else:\n",
    "        return wl_dataset,wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "\n",
    "\n",
    "    '''gaps_true = input('Do you want to create artifical gaps y/n? ')\n",
    "\n",
    "    if str(gaps_true) == str('y'):\n",
    "        \n",
    "        wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "        print('Gaps Created')\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        if len(valid_multi_gaps) > 0:\n",
    "\n",
    "            poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "            if len(poly_wl_list) > 0 :\n",
    "\n",
    "                filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "                filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "                print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "            \n",
    "            else:\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        else:\n",
    "            return wl_dataset,wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "\n",
    "    elif str(gaps_true) == str('n'):\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "        if len(valid_multi_gaps) > 0:\n",
    "\n",
    "            poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "            if len(poly_wl_list) > 0 :\n",
    "\n",
    "                filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "                filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "                print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "            \n",
    "            else:\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        else:\n",
    "            return wl_dataset,wl_dataset,Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "    else:\n",
    "        print('Not an acceptable answer')\n",
    "        dataset_LF = []\n",
    "        Wl_gaps = []\n",
    "        dataset_LF = []\n",
    "        poly_wl_list = []\n",
    "        gap_list = []\n",
    "        poly_gap_list = []\n",
    "        \n",
    "        return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  162\n",
      "Number of Linear Gaps filled: 8\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 126\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 117\n",
      "Run 2/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  153\n",
      "Number of Linear Gaps filled: 7\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 120\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 117\n",
      "Run 3/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  164\n",
      "Number of Linear Gaps filled: 9\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 128\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 121\n",
      "Run 4/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  160\n",
      "Number of Linear Gaps filled: 8\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 125\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 116\n",
      "Run 5/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  160\n",
      "Number of Linear Gaps filled: 7\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 126\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 120\n",
      "Run 6/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  155\n",
      "Number of Linear Gaps filled: 9\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 120\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 110\n",
      "Run 7/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  157\n",
      "Number of Linear Gaps filled: 8\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 123\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 116\n",
      "Run 8/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  160\n",
      "Number of Linear Gaps filled: 9\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 124\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 121\n",
      "Run 9/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  163\n",
      "Number of Linear Gaps filled: 8\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 129\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 121\n",
      "Run 10/10\n",
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  165\n",
      "Number of Linear Gaps filled: 9\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 131\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Cannot fill gap out of bounds\n",
      "Gaps filled 127\n",
      "Mean Error per run: [0.2675386516409648, 0.22124020361121782, 0.30212085843373493, 0.2519831842923795, 0.2473394883631468, 0.2528874812967581, 0.24102058910452176, 0.21988381933584766, 0.2363053942685896, 0.2986332401478943]\n",
      "Mean Difference per run: [0.004579576907868724, 0.0038776411832500963, 0.004948418674698796, 0.004425447122861586, 0.004368820927101366, 0.004500947630922693, 0.0041297409122253975, 0.003925397847484131, 0.004167634388462259, 0.0052351880241680955]\n",
      "Overall Mean Error: 0.254\n",
      "Overall Mean Difference: 0.004\n"
     ]
    }
   ],
   "source": [
    "filepath = r'C:\\Users\\mrpro\\Documents\\Code\\CBI\\Gap_Filling\\pd_1732232133.csv'\n",
    "\n",
    "# Lists to store the results of each run\n",
    "mean_error_list = []\n",
    "mean_adjusted_error_list = []\n",
    "mean_difference_list = []\n",
    "\n",
    "num_runs = 10\n",
    "\n",
    "for i in range(num_runs):\n",
    "    print(f\"Run {i+1}/{num_runs}\")\n",
    "    filled_df, wl_dataset, all_gaps, dataset_LF, poly_wl, filled_gap_list, adjusted_gaps = cbi_gapfill(filepath)\n",
    "    \n",
    "    # Calculate error metrics\n",
    "    filled_df['pwl actual'] = wl_dataset['pwl']\n",
    "    filled_df['error'] = np.abs((filled_df['mwl'] - filled_df['pwl actual']) / filled_df['pwl actual']) * 100\n",
    "    filled_df['difference'] = np.abs(filled_df['pwl actual'] - filled_df['mwl'])\n",
    "\n",
    "    filled_df = filled_df.round(3)\n",
    "    # Compute and store the desired statistics\n",
    "    mean_error_list.append(filled_df['error'].mean())\n",
    "    mean_difference_list.append(filled_df['difference'].mean())\n",
    "\n",
    "# After completing all runs, print or analyze the results\n",
    "print(\"Mean Error per run:\", mean_error_list)\n",
    "print(\"Mean Difference per run:\", mean_difference_list)\n",
    "\n",
    "# You could also summarize across all runs if desired\n",
    "print(\"Overall Mean Error:\", round(np.mean(mean_error_list),3))\n",
    "print(\"Overall Mean Difference:\", round(np.mean(mean_difference_list),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
