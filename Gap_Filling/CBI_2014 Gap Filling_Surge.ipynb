{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "import matplotlib.dates as mdates\n",
    "from scipy import stats\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def read_wl_csv(file_path):\n",
    "    wl_df = pd.read_csv(file_path)\n",
    "\n",
    "    ##### if the csv is from lighthouse then this drop function is always true\n",
    "    ##### if the csv is not from lighthouse then you will need to modify the function\n",
    "\n",
    "    wl_df.drop(labels=range(len(wl_df)-6,len(wl_df)), axis=0, inplace=True)\n",
    "\n",
    "    keys = wl_df.keys().to_list()\n",
    "    \n",
    "    wl_df['date'] = pd.to_datetime(wl_df[keys[0]])\n",
    "    wl_df[keys[1]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[2]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df[keys[3]].replace([-999, -99, 99, 'NA', 'RM'], np.nan, inplace=True)\n",
    "    wl_df['pwl'] = pd.to_numeric(wl_df[keys[1]],errors= 'coerce')\n",
    "    wl_df['bwl'] = pd.to_numeric(wl_df[keys[2]],errors= 'coerce')\n",
    "    wl_df['harmwl'] = pd.to_numeric(wl_df[keys[3]],errors= 'coerce')\n",
    "    wl_df['pwl surge'] = wl_df['pwl'] - wl_df['harmwl']\n",
    "    wl_df['bwl surge'] = wl_df['bwl'] - wl_df['harmwl']\n",
    "    wl_df = wl_df.drop(columns=keys[0],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[1],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[2],axis=0)\n",
    "    wl_df = wl_df.drop(columns=keys[3],axis=0)\n",
    "    del keys\n",
    "    return wl_df\n",
    "\n",
    "def locate_gaps(WL_data):\n",
    "    lengthMissVal = []\n",
    "    dates = []\n",
    "    count = 0\n",
    "    for i in range(len(WL_data)):\n",
    "        if pd.isna(WL_data['pwl surge'][i]):\n",
    "            if count == 0:  # Start of a new NaN gap\n",
    "                dates.append(WL_data['date'][i])  # Record the start date of the gap\n",
    "            count += 1 \n",
    "        else:\n",
    "            if count > 0:  # End of a NaN gap\n",
    "                lengthMissVal.append(count)\n",
    "                count = 0  # Reset count after recording the gap length\n",
    "    if count > 0:\n",
    "        lengthMissVal.append(count)\n",
    "\n",
    "    # Finalize the DataFrame\n",
    "    WL_data_gaps = pd.DataFrame()\n",
    "    WL_data_gaps['date'] = pd.to_datetime(dates)\n",
    "    WL_data_gaps['gapLength'] = lengthMissVal\n",
    "    WL_data_gaps['gapTime(min)'] = WL_data_gaps['gapLength'] * 6\n",
    "\n",
    "    del lengthMissVal,dates,count\n",
    "\n",
    "    return WL_data_gaps\n",
    "\n",
    "def eligible_gap_length(WL_gaps): #Function to sort the lengh of the gaps into three categories\n",
    "    WL_gaps_filter_6min = WL_gaps['gapLength'] == 1\n",
    "    WL_gaps_filter = (WL_gaps['gapLength'] <= 576) & (WL_gaps['gapLength'] > 1)\n",
    "\n",
    "    #filters the data into individual dataframes\n",
    "    linear_gaps = WL_gaps[WL_gaps_filter_6min]\n",
    "    gaps_less_5_days = WL_gaps[WL_gaps_filter]\n",
    "\n",
    "    del WL_gaps_filter,WL_gaps_filter_6min\n",
    "\n",
    "    return linear_gaps,gaps_less_5_days\n",
    "\n",
    "\n",
    "def linear_fill(Wl_data,linear_gaps): #function to fill in gaps with length of 1 using linear approach\n",
    "\n",
    "    if len(linear_gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(linear_gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "            new_value = ((Wl_data.loc[(index_locations[i])-1,'pwl surge']+ Wl_data.loc[index_locations[i]+1,'pwl surge']) / 2) + Wl_data.loc[index_locations[i],'harmwl']\n",
    "            Wl_data.loc[index_locations[i],'pwl'] = new_value\n",
    "\n",
    "        del matching_dates, index_locations, new_value\n",
    "        \n",
    "        return Wl_data\n",
    "    \n",
    "    else:\n",
    "        print('No single gaps to fill')\n",
    "\n",
    "        return Wl_data\n",
    "\n",
    "\n",
    "def check_bwl(Wl_data,gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        valid_gaps = []\n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            is_valid = Wl_data['bwl surge'][index_locations[i]:index_locations[i]+gap_length[i]].isna().sum() == 0\n",
    "            valid_gaps.append(is_valid)\n",
    "        \n",
    "        filtered_gaps = gaps[valid_gaps].reset_index(drop=True)\n",
    "\n",
    "        del matching_dates, index_locations, gap_length, valid_gaps, is_valid\n",
    "\n",
    "        return filtered_gaps\n",
    "    \n",
    "    else:\n",
    "        print('No gaps avaliable to fill')\n",
    "\n",
    "        return gaps\n",
    "\n",
    "\n",
    "def poly_gap_fill(Wl_data, gaps):\n",
    "\n",
    "    if len(gaps) > 0:\n",
    "\n",
    "        poly_df_list = []\n",
    "\n",
    "        gap_date_list = []\n",
    "\n",
    "        poly_filled_gaps = []\n",
    "\n",
    "        matching_dates = Wl_data[Wl_data['date'].isin(gaps['date'])]\n",
    "\n",
    "        index_locations = matching_dates.index.tolist()\n",
    "\n",
    "        gap_length = gaps['gapLength'].tolist()\n",
    "\n",
    "        for i in range(len(matching_dates)):\n",
    "\n",
    "            gap_date_df = pd.DataFrame()\n",
    "\n",
    "            gap_date_df['date'] = Wl_data['date'][index_locations[i]:index_locations[i]+gap_length[i]]\n",
    "\n",
    "            gap_date_list.append(gap_date_df)\n",
    "            \n",
    "\n",
    "        for i in range(len(index_locations)):\n",
    "\n",
    "            if index_locations[i]- 2161  > 0 and index_locations[i]+2161+gap_length[i] < len(Wl_data):\n",
    "\n",
    "                pwl_30_days = Wl_data['pwl surge'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                bwl_30_days = Wl_data['bwl surge'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                dates = Wl_data['date'][(index_locations[i]- 2160):index_locations[i]+2160+gap_length[i]].tolist()\n",
    "\n",
    "                linear_df = pd.DataFrame()\n",
    "\n",
    "                linear_df['pwl surge 30'] = pwl_30_days\n",
    "                linear_df['bwl surge 30'] = bwl_30_days\n",
    "                linear_df['dates'] = dates\n",
    "\n",
    "                linear_df.dropna(inplace=True)\n",
    "\n",
    "\n",
    "                slope, intercept, *_ = stats.linregress(linear_df['bwl surge 30'],linear_df['pwl surge 30'])\n",
    "\n",
    "                poly_df = pd.DataFrame({'bwl surge': bwl_30_days, 'pwl surge': pwl_30_days,'date' : pd.to_datetime(dates)})\n",
    "\n",
    "                poly_df['mwl surge linear'] = intercept + slope*poly_df['bwl surge']\n",
    "\n",
    "                mask = abs(poly_df['mwl surge linear'] - poly_df['pwl surge']) > 0.1\n",
    "                \n",
    "                poly_df.loc[mask, 'pwl surge'] = np.nan\n",
    "                poly_df.loc[mask, 'mwl surge linear'] = np.nan\n",
    "                poly_df.loc[mask, 'bwl surge'] = np.nan\n",
    "\n",
    "                if poly_df['bwl surge'].isna().sum() + poly_df['pwl surge'].isna().sum() < len(Wl_data)*0.1:\n",
    "\n",
    "                    poly_df_copy = poly_df.copy()\n",
    "\n",
    "                    poly_df_copy.dropna(inplace=True)\n",
    "\n",
    "                    poly =np.polynomial.polynomial.Polynomial.fit(poly_df_copy['pwl surge'],poly_df_copy['bwl surge'],4)\n",
    "\n",
    "                    coeffs = np.polyfit(poly_df_copy['bwl surge'],poly_df_copy['pwl surge'],4)\n",
    "\n",
    "                    poly1 = np.poly1d(coeffs)\n",
    "\n",
    "                    pred_values = poly1(poly_df['bwl surge'])\n",
    "\n",
    "                    poly_df['mwl surge'] = pred_values\n",
    "\n",
    "                    poly_df_list.append(poly_df)\n",
    "\n",
    "                    poly_filled_gaps.append((index_locations[i], gap_length[i]))\n",
    "\n",
    "                    del poly_df_copy, poly, pred_values\n",
    "\n",
    "                else:\n",
    "                   print('Can not fill gap not enough points')\n",
    "\n",
    "            else:\n",
    "                print('Can not fill gap out of bounds')\n",
    "\n",
    "        return poly_df_list, index_locations, gap_length, gap_date_list, poly_filled_gaps\n",
    "\n",
    "    else:\n",
    "        print('No gaps to Fill')\n",
    "\n",
    "        return [],[],[],[],[]\n",
    "\n",
    "def fill_gaps(poly_list, gap_dates_list, wl_df, poly_gap_list):\n",
    "\n",
    "    wl_df['mwl surge'] = np.nan\n",
    "\n",
    "    for i, (idx, length) in enumerate(poly_gap_list):\n",
    "\n",
    "        poly_df = poly_list[i]\n",
    "\n",
    "        gap_values = poly_df.loc[2160:2160+length, 'mwl surge'].values\n",
    "\n",
    "        wl_df.loc[idx:idx+length, 'mwl surge'] = gap_values\n",
    "\n",
    "    return wl_df\n",
    "\n",
    "def adjustment(filled_df, poly_gaps):\n",
    "\n",
    "\n",
    "    filled_df['mwl surge adjusted'] = np.nan\n",
    "    idx, length = map(list, zip(*poly_gaps))\n",
    "\n",
    "    for i in range(len(idx)):\n",
    "        adjustment_values = []\n",
    "\n",
    "        # Calculate averages before and after the gap\n",
    "        average_before = np.nanmean(filled_df['pwl surge'][idx[i] - 6:idx[i]])\n",
    "        average_after = np.nanmean(filled_df['pwl surge'][idx[i] + length[i]:idx[i] + length[i] + 6])\n",
    "\n",
    "        n_length = length[i]\n",
    "\n",
    "        for k in range(n_length):\n",
    "            value = (average_after + (k+1 / n_length)) * (average_before - average_after)\n",
    "            adjustment_values.append(value)\n",
    "\n",
    "        filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl surge adjusted'] = (\n",
    "            filled_df.loc[idx[i]:idx[i] + length[i] - 1, 'mwl surge'] + adjustment_values\n",
    "        )\n",
    "\n",
    "    filled_df['new wl adjustment'] = filled_df['pwl surge'].combine_first(filled_df['mwl surge adjusted'])\n",
    "    filled_df['new wl'] = filled_df['pwl surge'].combine_first(filled_df['mwl surge'])\n",
    "    return filled_df\n",
    "\n",
    "        \n",
    "\n",
    "def create_gaps(dataset):\n",
    "\n",
    "    import random\n",
    "\n",
    "    wl_data =  dataset.copy()\n",
    "\n",
    "    random_index = [random.randint(0,len(wl_data))for _ in range(1000)]\n",
    "\n",
    "    max_gap_size = 100\n",
    "    random_index = random.sample(range(len(wl_data) - max_gap_size), 1000)\n",
    "\n",
    "\n",
    "    #create one six min gap\n",
    "\n",
    "    wl_data.loc[random_index[0], 'pwl surge'] = np.nan\n",
    "    random_index = random_index[1:]\n",
    "\n",
    "    # create 5 30 min gaps\n",
    "\n",
    "    for i in range(4):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 4, 'pwl surge'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[100:]\n",
    "\n",
    "    #create 10 1hr gaps\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 9, 'pwl surge'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[10:]\n",
    "\n",
    "    #creates 50 5 hr gaps\n",
    "\n",
    "    for i in range(50):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 49, 'pwl surge'] = np.nan\n",
    "    \n",
    "    random_index = random_index[50:]\n",
    "\n",
    "    #creates 100 10hr gaps\n",
    "\n",
    "    for i in range(100):\n",
    "\n",
    "        wl_data.loc[random_index[i]:random_index[i] + 99, 'pwl surge'] = np.nan\n",
    "    \n",
    "    #random_index = random_index[10:]\n",
    "\n",
    "    return wl_data\n",
    "\n",
    "def cbi_gapfill(filepath):\n",
    "\n",
    "    print('Reading dataset')\n",
    "    wl_dataset = read_wl_csv(filepath)\n",
    "\n",
    "    wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "    print('Gaps Created')\n",
    "\n",
    "    Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "    print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "    linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "    print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "    dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "    print('Single gaps filled')\n",
    "\n",
    "    valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "    print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "    if len(valid_multi_gaps) > 0:\n",
    "\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "        if len(poly_wl_list) > 0 :\n",
    "\n",
    "            filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "            filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "            print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        \n",
    "        else:\n",
    "\n",
    "            return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "    else:\n",
    "        return wl_dataset,wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "\n",
    "\n",
    "    '''gaps_true = input('Do you want to create artifical gaps y/n? ')\n",
    "\n",
    "    if str(gaps_true) == str('y'):\n",
    "        \n",
    "        wl_dataset_gaps = create_gaps(wl_dataset)\n",
    "\n",
    "        print('Gaps Created')\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset_gaps)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset_gaps,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "\n",
    "        if len(valid_multi_gaps) > 0:\n",
    "\n",
    "            poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "            if len(poly_wl_list) > 0 :\n",
    "\n",
    "                filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "                filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "                print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "            \n",
    "            else:\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        else:\n",
    "            return wl_dataset,wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "\n",
    "    elif str(gaps_true) == str('n'):\n",
    "\n",
    "        Wl_gaps = locate_gaps(wl_dataset)\n",
    "\n",
    "        print('Total number of gaps: ', len(Wl_gaps))\n",
    "\n",
    "        linear_gaps,multi_gaps = eligible_gap_length(Wl_gaps)\n",
    "\n",
    "        print('Number of Linear Gaps filled:', len(linear_gaps))\n",
    "\n",
    "        dataset_LF = linear_fill(wl_dataset,linear_gaps)\n",
    "\n",
    "        print('Single gaps filled')\n",
    "\n",
    "        valid_multi_gaps = check_bwl(dataset_LF,multi_gaps)\n",
    "\n",
    "        print('Number of gaps with backup water level:', len(valid_multi_gaps))\n",
    "        poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "        if len(valid_multi_gaps) > 0:\n",
    "\n",
    "            poly_wl_list, index_location, gap_length, gap_list, poly_gap_list = poly_gap_fill(dataset_LF,valid_multi_gaps)\n",
    "\n",
    "\n",
    "            if len(poly_wl_list) > 0 :\n",
    "\n",
    "                filled_df = fill_gaps(poly_wl_list,gap_list,dataset_LF,poly_gap_list)\n",
    "\n",
    "                filled_df = adjustment(filled_df, poly_gap_list)\n",
    "\n",
    "                print('Gaps filled', + len(poly_wl_list))\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "            \n",
    "            else:\n",
    "\n",
    "                return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "        else:\n",
    "            return wl_dataset,wl_dataset,Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list\n",
    "    else:\n",
    "        print('Not an acceptable answer')\n",
    "        dataset_LF = []\n",
    "        Wl_gaps = []\n",
    "        dataset_LF = []\n",
    "        poly_wl_list = []\n",
    "        gap_list = []\n",
    "        poly_gap_list = []\n",
    "        \n",
    "        return filled_df, wl_dataset, Wl_gaps, dataset_LF, poly_wl_list, gap_list, poly_gap_list'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading dataset\n",
      "Gaps Created\n",
      "Total number of gaps:  153\n",
      "Number of Linear Gaps filled: 8\n",
      "Single gaps filled\n",
      "Number of gaps with backup water level: 118\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Can not fill gap out of bounds\n",
      "Gaps filled 114\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filled_df, wl_dataset, all_gaps, dataset_LF, poly_wl, filled_gap_list, adjusted_gaps = cbi_gapfill(r'C:\\Users\\mrpro\\Documents\\Code\\CBI\\Gap_Filling\\pd_1732232133.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "filled_df['pwl surge actual'] = wl_dataset['pwl surge']\n",
    "filled_df['error'] = abs((filled_df['mwl surge'] - filled_df['pwl surge actual']) / filled_df['pwl surge actual']) *100\n",
    "filled_df['adjusted error'] = abs((filled_df['mwl surge adjusted'] - filled_df['pwl surge actual']) / filled_df['pwl surge actual']) *100\n",
    "filled_df['difference'] = abs(filled_df['pwl surge actual'] - filled_df['mwl surge'])\n",
    "filled_df.replace([np.inf, -np.inf], np.nan, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>pwl</th>\n",
       "      <th>bwl</th>\n",
       "      <th>harmwl</th>\n",
       "      <th>pwl surge</th>\n",
       "      <th>bwl surge</th>\n",
       "      <th>mwl surge</th>\n",
       "      <th>mwl surge adjusted</th>\n",
       "      <th>new wl adjustment</th>\n",
       "      <th>new wl</th>\n",
       "      <th>pwl surge actual</th>\n",
       "      <th>error</th>\n",
       "      <th>adjusted error</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>87840</td>\n",
       "      <td>86262.000000</td>\n",
       "      <td>86275.000000</td>\n",
       "      <td>87840.000000</td>\n",
       "      <td>74864.000000</td>\n",
       "      <td>86275.000000</td>\n",
       "      <td>10689.000000</td>\n",
       "      <td>10578.000000</td>\n",
       "      <td>85442.000000</td>\n",
       "      <td>85442.000000</td>\n",
       "      <td>86255.000000</td>\n",
       "      <td>10686.000000</td>\n",
       "      <td>10575.000000</td>\n",
       "      <td>1.068900e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2016-07-01 23:57:00</td>\n",
       "      <td>1.818991</td>\n",
       "      <td>2.617894</td>\n",
       "      <td>1.555959</td>\n",
       "      <td>0.262546</td>\n",
       "      <td>1.062536</td>\n",
       "      <td>0.268233</td>\n",
       "      <td>0.392996</td>\n",
       "      <td>0.278696</td>\n",
       "      <td>0.263245</td>\n",
       "      <td>0.263556</td>\n",
       "      <td>43.711008</td>\n",
       "      <td>2141.045105</td>\n",
       "      <td>3.630562e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2016-01-01 00:00:00</td>\n",
       "      <td>0.585000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.035000</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-1.609000</td>\n",
       "      <td>-0.249297</td>\n",
       "      <td>-18.578354</td>\n",
       "      <td>-18.578354</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>-0.617000</td>\n",
       "      <td>0.000154</td>\n",
       "      <td>0.000836</td>\n",
       "      <td>6.440741e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2016-04-01 11:58:30</td>\n",
       "      <td>1.692000</td>\n",
       "      <td>2.526000</td>\n",
       "      <td>1.458000</td>\n",
       "      <td>0.186000</td>\n",
       "      <td>0.994000</td>\n",
       "      <td>0.189162</td>\n",
       "      <td>-1.450181</td>\n",
       "      <td>0.174000</td>\n",
       "      <td>0.186041</td>\n",
       "      <td>0.187000</td>\n",
       "      <td>6.161422</td>\n",
       "      <td>274.058161</td>\n",
       "      <td>1.666802e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2016-07-01 23:57:00</td>\n",
       "      <td>1.835000</td>\n",
       "      <td>2.628000</td>\n",
       "      <td>1.572000</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>1.056000</td>\n",
       "      <td>0.254962</td>\n",
       "      <td>0.165617</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.261000</td>\n",
       "      <td>0.262000</td>\n",
       "      <td>12.249307</td>\n",
       "      <td>772.973765</td>\n",
       "      <td>3.112888e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2016-10-01 11:55:30</td>\n",
       "      <td>1.966000</td>\n",
       "      <td>2.722000</td>\n",
       "      <td>1.675000</td>\n",
       "      <td>0.344000</td>\n",
       "      <td>1.128000</td>\n",
       "      <td>0.332481</td>\n",
       "      <td>2.276166</td>\n",
       "      <td>0.356786</td>\n",
       "      <td>0.342000</td>\n",
       "      <td>0.341000</td>\n",
       "      <td>19.315686</td>\n",
       "      <td>1856.205306</td>\n",
       "      <td>4.911989e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2016-12-31 23:54:00</td>\n",
       "      <td>2.507000</td>\n",
       "      <td>3.124000</td>\n",
       "      <td>1.917000</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>1.593000</td>\n",
       "      <td>0.973773</td>\n",
       "      <td>26.309834</td>\n",
       "      <td>26.309834</td>\n",
       "      <td>0.973773</td>\n",
       "      <td>0.894000</td>\n",
       "      <td>16645.813023</td>\n",
       "      <td>408446.605905</td>\n",
       "      <td>1.703499e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220214</td>\n",
       "      <td>0.158955</td>\n",
       "      <td>0.158702</td>\n",
       "      <td>0.148248</td>\n",
       "      <td>0.115146</td>\n",
       "      <td>0.133523</td>\n",
       "      <td>4.534771</td>\n",
       "      <td>1.602124</td>\n",
       "      <td>0.146515</td>\n",
       "      <td>0.147103</td>\n",
       "      <td>346.437719</td>\n",
       "      <td>10981.654547</td>\n",
       "      <td>2.739428e-02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      date           pwl           bwl        harmwl  \\\n",
       "count                87840  86262.000000  86275.000000  87840.000000   \n",
       "mean   2016-07-01 23:57:00      1.818991      2.617894      1.555959   \n",
       "min    2016-01-01 00:00:00      0.585000      0.000000      1.035000   \n",
       "25%    2016-04-01 11:58:30      1.692000      2.526000      1.458000   \n",
       "50%    2016-07-01 23:57:00      1.835000      2.628000      1.572000   \n",
       "75%    2016-10-01 11:55:30      1.966000      2.722000      1.675000   \n",
       "max    2016-12-31 23:54:00      2.507000      3.124000      1.917000   \n",
       "std                    NaN      0.220214      0.158955      0.158702   \n",
       "\n",
       "          pwl surge     bwl surge     mwl surge  mwl surge adjusted  \\\n",
       "count  74864.000000  86275.000000  10689.000000        10578.000000   \n",
       "mean       0.262546      1.062536      0.268233            0.392996   \n",
       "min       -0.617000     -1.609000     -0.249297          -18.578354   \n",
       "25%        0.186000      0.994000      0.189162           -1.450181   \n",
       "50%        0.262000      1.056000      0.254962            0.165617   \n",
       "75%        0.344000      1.128000      0.332481            2.276166   \n",
       "max        0.894000      1.593000      0.973773           26.309834   \n",
       "std        0.148248      0.115146      0.133523            4.534771   \n",
       "\n",
       "       new wl adjustment        new wl  pwl surge actual         error  \\\n",
       "count       85442.000000  85442.000000      86255.000000  10686.000000   \n",
       "mean            0.278696      0.263245          0.263556     43.711008   \n",
       "min           -18.578354     -0.617000         -0.617000      0.000154   \n",
       "25%             0.174000      0.186041          0.187000      6.161422   \n",
       "50%             0.261000      0.261000          0.262000     12.249307   \n",
       "75%             0.356786      0.342000          0.341000     19.315686   \n",
       "max            26.309834      0.973773          0.894000  16645.813023   \n",
       "std             1.602124      0.146515          0.147103    346.437719   \n",
       "\n",
       "       adjusted error    difference  \n",
       "count    10575.000000  1.068900e+04  \n",
       "mean      2141.045105  3.630562e-02  \n",
       "min          0.000836  6.440741e-07  \n",
       "25%        274.058161  1.666802e-02  \n",
       "50%        772.973765  3.112888e-02  \n",
       "75%       1856.205306  4.911989e-02  \n",
       "max     408446.605905  1.703499e-01  \n",
       "std      10981.654547  2.739428e-02  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filled_df.describe()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
