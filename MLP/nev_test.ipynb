{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0358c342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:24:27.356120: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, median_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f878319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM limited to 10000 MB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-02 10:24:30.246170: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-02 10:24:33.585068: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2025-06-02 10:24:33.585160: I external/local_xla/xla/stream_executor/rocm/rocm_executor.cc:920] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]  # MB\n",
    "        )\n",
    "        print(\"VRAM limited to 10000 MB.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Memory configuration must be set at program start:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7aa9595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Drop last 6 rows\n",
    "    df = df.iloc[:-6]\n",
    "    \n",
    "    # Convert date column to datetime\n",
    "    df['#date+time'] = pd.to_datetime(df['#date+time'], errors='coerce')\n",
    "    df = df.rename(columns={'#date+time': 'date_time'})\n",
    "    \n",
    "    # Convert all other columns to numeric\n",
    "    for col in df.columns:\n",
    "        if col != 'date_time':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "def wind_to_uv(speed, direction_deg):\n",
    "    # Convert to radians\n",
    "    direction_rad = np.deg2rad(direction_deg)\n",
    "\n",
    "    # U = -speed * sin(direction), V = -speed * cos(direction)\n",
    "    # This converts FROM meteorological TO Cartesian\n",
    "    u = -speed * np.sin(direction_rad)\n",
    "    v = -speed * np.cos(direction_rad)\n",
    "    return u, v\n",
    "\n",
    "def prepare_dataframe(df):\n",
    "    # Rename columns to a consistent format\n",
    "    df = df.rename(columns={\n",
    "        df.columns[0]: 'date_time',\n",
    "        df.columns[1]: 'pwl',\n",
    "        df.columns[2]: 'wsd',\n",
    "        df.columns[3]: 'wdr'\n",
    "    })\n",
    "    \n",
    "    # Convert wind to U/V components\n",
    "    u, v = wind_to_uv(df['wsd'], df['wdr'])\n",
    "    df[['u', 'v']] = np.column_stack((u, v))\n",
    "    \n",
    "    # Drop raw wind columns\n",
    "    df.drop(columns=['wsd', 'wdr'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def input_output_arrays(source_df, target_df, wl_window, wind_window):\n",
    "\n",
    "    wl_window = wl_window * 10\n",
    "    wind_window = wind_window * 10\n",
    "\n",
    "    source_df = source_df.reset_index(drop=True)\n",
    "    target_df = target_df.reset_index(drop=True)\n",
    "\n",
    "    source_pwl = source_df['pwl'].to_numpy()\n",
    "    source_u   = source_df['u'].to_numpy()\n",
    "    source_v   = source_df['v'].to_numpy()\n",
    "    target_pwl = target_df['pwl'].to_numpy()\n",
    "\n",
    "    X, y, indices = [], [], []\n",
    "\n",
    "    for t in range(max(wl_window, wind_window), len(source_df) - wl_window):\n",
    "        # Water level window: centered at t\n",
    "        wl_slice = slice(t - wl_window, t + wl_window + 1)\n",
    "\n",
    "        # Wind window: past `wind_window` values ending at t\n",
    "        wind_slice = slice(t - wind_window + 1, t + 1)\n",
    "\n",
    "        pwl_input = source_pwl[wl_slice]\n",
    "        u_input = source_u[wind_slice]\n",
    "        v_input = source_v[wind_slice]\n",
    "        target = target_pwl[t]\n",
    "\n",
    "        if (\n",
    "            np.isnan(pwl_input).any() or\n",
    "            np.isnan(u_input).any() or\n",
    "            np.isnan(v_input).any() or\n",
    "            np.isnan(target)\n",
    "        ):\n",
    "            continue\n",
    "\n",
    "        features = np.concatenate([pwl_input, u_input, v_input])\n",
    "        X.append(features)\n",
    "        y.append(target)\n",
    "        indices.append(t)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(indices)\n",
    "\n",
    "\n",
    "\n",
    "def calculate_central_frequency_percentage(testing_label_array, predictions, cm):\n",
    "  \"\"\"Find the percentage of predictions with a central frequency (CF) of less than\n",
    "  or equal to a given number of centimeters (cm)\n",
    "\n",
    "\tArgs:\n",
    "        testing_label_array (array): Testing labels\n",
    "\n",
    "        predictions (array): Model predictions\n",
    "\n",
    "        cm (int): Number of centimeters\n",
    "\n",
    "\tReturns:\n",
    "\t\t(float): central frequency (CF) percentage\n",
    "\t\"\"\"\n",
    "  less_than_cm_counter = 0\n",
    "\n",
    "  # Convert cm to m\n",
    "  cm_to_m = cm / 100\n",
    "\n",
    "  for index, prediction in enumerate(predictions):\n",
    "    if abs(testing_label_array[index] - prediction) <= cm_to_m:\n",
    "      less_than_cm_counter += 1\n",
    "\n",
    "  cf_percentage = (less_than_cm_counter / len(predictions)) * 100\n",
    "\n",
    "  return cf_percentage\n",
    "\n",
    "\n",
    "def evaluate_model(model, testing_input_array, testing_label_array):\n",
    "  \"\"\"Calculates loss, makes predictions, and calculates Central Frequency (CF),\n",
    "  Mean Squared Error (MSE), Root Mean Squared Error(RMSE), Mean Absolute Error (MAE),\n",
    "  Median Absolute Error, and R-squared (R2)\n",
    "\n",
    "\tArgs:\n",
    "        model (tf.keras.model): The trained model\n",
    "\n",
    "        testing_input_array (array): Testing inputs\n",
    "\n",
    "        testing_label_array (array): Testing labels\n",
    "\t\"\"\"\n",
    "  print(\"Calculating Loss:\")\n",
    "  test_loss = model.evaluate(testing_input_array, testing_label_array, batch_size = len(testing_input_array))\n",
    "\n",
    "  print(\"Loss:\", test_loss)\n",
    "\n",
    "\n",
    "  print(\"\\nGenerating output predictions with model:\")\n",
    "  predictions = model.predict(testing_input_array, batch_size = len(testing_input_array))\n",
    "\n",
    "  # Calculate evaluation metrics\n",
    "  cf_15cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 15)\n",
    "  cf_5cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 5)\n",
    "  cf_1cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 1)\n",
    "  mse = mean_squared_error(testing_label_array, predictions)\n",
    "  rmse = root_mean_squared_error(testing_label_array, predictions)\n",
    "  mae = mean_absolute_error(testing_label_array, predictions)\n",
    "  medae = median_absolute_error(testing_label_array, predictions)\n",
    "  r2 = r2_score(testing_label_array, predictions)\n",
    "\n",
    "  print(\"\\nCentral Frequency Percentage 15cm:\", cf_15cm_percentage)\n",
    "  print(\"\\nCentral Frequency Percentage 5cm:\", cf_5cm_percentage)\n",
    "  print(\"\\nCentral Frequency Percentage 1cm:\", cf_1cm_percentage)\n",
    "  print(\"Mean Squared Error:\", mse)\n",
    "  print(\"Root Mean Squared Error:\", rmse)\n",
    "  print(\"Mean Absolute Error:\", mae)\n",
    "  print(\"Median Absolute Error:\", medae)\n",
    "  print(\"R-squared:\", r2)\n",
    "\n",
    "\n",
    "file_paths = {\n",
    "    'pi08': '/home/ryan/Downloads/pIsabel_pwl+wind_june2008-2009.csv',\n",
    "    'cg08': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_june2008-2009.csv',\n",
    "    'pi09': '/home/ryan/Downloads/pIsabel_pwl+wind+surge_mar2009-apr2010.csv',\n",
    "    'cg09': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_mar2009-apr2010.csv',\n",
    "    'pi11': '//home/ryan/Downloads/pIsabel_pwl+wind+surge_mar2011-apr2012.csv',\n",
    "    'cg11': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_mar2011-apr2012.csv',\n",
    "\n",
    "}\n",
    "\n",
    "datasets = {key: load_and_clean_csv(path) for key, path in file_paths.items()}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    datasets[name] = prepare_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7860cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60689, 121) (60689,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, indices_train = input_output_arrays(datasets['cg08'], datasets['pi08'], wl_window=3, wind_window=3)\n",
    "X_val, y_val, indices_val = input_output_arrays(datasets['cg09'], datasets['pi09'], wl_window=3, wind_window=3)\n",
    "X_test, y_test, indices_test = input_output_arrays(datasets['cg11'], datasets['pi11'], wl_window=3, wind_window=3)\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f6e725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(1, kernel_initializer = 'normal' ))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a72645b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 996ms/step - loss: 2.5496 - mae: 1.5800\n",
      "Epoch 1: val_loss improved from inf to 2.42555, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 2.5496 - mae: 1.5800 - val_loss: 2.4256 - val_mae: 1.5442\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.4539 - mae: 1.5501\n",
      "Epoch 2: val_loss improved from 2.42555 to 2.33133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 2.4539 - mae: 1.5501 - val_loss: 2.3313 - val_mae: 1.5139\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.3592 - mae: 1.5199\n",
      "Epoch 3: val_loss improved from 2.33133 to 2.23684, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 2.3592 - mae: 1.5199 - val_loss: 2.2368 - val_mae: 1.4829\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2.2639 - mae: 1.4889\n",
      "Epoch 4: val_loss improved from 2.23684 to 2.14165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 2.2639 - mae: 1.4889 - val_loss: 2.1416 - val_mae: 1.4509\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 2.1678 - mae: 1.4569\n",
      "Epoch 5: val_loss improved from 2.14165 to 2.04556, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 2.1678 - mae: 1.4569 - val_loss: 2.0456 - val_mae: 1.4180\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0699 - mae: 1.4236\n",
      "Epoch 6: val_loss improved from 2.04556 to 1.94898, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 2.0699 - mae: 1.4236 - val_loss: 1.9490 - val_mae: 1.3841\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.9737 - mae: 1.3900\n",
      "Epoch 7: val_loss improved from 1.94898 to 1.85225, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 1.9737 - mae: 1.3900 - val_loss: 1.8522 - val_mae: 1.3493\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.8751 - mae: 1.3548\n",
      "Epoch 8: val_loss improved from 1.85225 to 1.75570, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 1.8751 - mae: 1.3548 - val_loss: 1.7557 - val_mae: 1.3136\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.7784 - mae: 1.3193\n",
      "Epoch 9: val_loss improved from 1.75570 to 1.65961, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 1.7784 - mae: 1.3193 - val_loss: 1.6596 - val_mae: 1.2772\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.6810 - mae: 1.2826\n",
      "Epoch 10: val_loss improved from 1.65961 to 1.56413, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 1.6810 - mae: 1.2826 - val_loss: 1.5641 - val_mae: 1.2399\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 1.5850 - mae: 1.2454\n",
      "Epoch 11: val_loss improved from 1.56413 to 1.46942, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 1.5850 - mae: 1.2454 - val_loss: 1.4694 - val_mae: 1.2017\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.4891 - mae: 1.2071\n",
      "Epoch 12: val_loss improved from 1.46942 to 1.37558, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 1.4891 - mae: 1.2071 - val_loss: 1.3756 - val_mae: 1.1627\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 1.3941 - mae: 1.1678\n",
      "Epoch 13: val_loss improved from 1.37558 to 1.28278, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 1.3941 - mae: 1.1678 - val_loss: 1.2828 - val_mae: 1.1227\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.3005 - mae: 1.1279\n",
      "Epoch 14: val_loss improved from 1.28278 to 1.19117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 1.3005 - mae: 1.1279 - val_loss: 1.1912 - val_mae: 1.0819\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.2077 - mae: 1.0867\n",
      "Epoch 15: val_loss improved from 1.19117 to 1.10096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 1.2077 - mae: 1.0867 - val_loss: 1.1010 - val_mae: 1.0400\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.1173 - mae: 1.0451\n",
      "Epoch 16: val_loss improved from 1.10096 to 1.01235, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 1.1173 - mae: 1.0451 - val_loss: 1.0124 - val_mae: 0.9973\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 1.0278 - mae: 1.0022\n",
      "Epoch 17: val_loss improved from 1.01235 to 0.92561, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 1.0278 - mae: 1.0022 - val_loss: 0.9256 - val_mae: 0.9535\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.9396 - mae: 0.9580\n",
      "Epoch 18: val_loss improved from 0.92561 to 0.84101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.9396 - mae: 0.9580 - val_loss: 0.8410 - val_mae: 0.9088\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.8544 - mae: 0.9133\n",
      "Epoch 19: val_loss improved from 0.84101 to 0.75884, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.8544 - mae: 0.9133 - val_loss: 0.7588 - val_mae: 0.8632\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.7725 - mae: 0.8681\n",
      "Epoch 20: val_loss improved from 0.75884 to 0.67943, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.7725 - mae: 0.8681 - val_loss: 0.6794 - val_mae: 0.8167\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6918 - mae: 0.8211\n",
      "Epoch 21: val_loss improved from 0.67943 to 0.60309, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.6918 - mae: 0.8211 - val_loss: 0.6031 - val_mae: 0.7693\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.6151 - mae: 0.7738\n",
      "Epoch 22: val_loss improved from 0.60309 to 0.53016, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.6151 - mae: 0.7738 - val_loss: 0.5302 - val_mae: 0.7212\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.5417 - mae: 0.7257\n",
      "Epoch 23: val_loss improved from 0.53016 to 0.46098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.5417 - mae: 0.7257 - val_loss: 0.4610 - val_mae: 0.6723\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.4721 - mae: 0.6767\n",
      "Epoch 24: val_loss improved from 0.46098 to 0.39589, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.4721 - mae: 0.6767 - val_loss: 0.3959 - val_mae: 0.6228\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.4071 - mae: 0.6274\n",
      "Epoch 25: val_loss improved from 0.39589 to 0.33518, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.4071 - mae: 0.6274 - val_loss: 0.3352 - val_mae: 0.5728\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3459 - mae: 0.5773\n",
      "Epoch 26: val_loss improved from 0.33518 to 0.27917, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.3459 - mae: 0.5773 - val_loss: 0.2792 - val_mae: 0.5225\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.2892 - mae: 0.5266\n",
      "Epoch 27: val_loss improved from 0.27917 to 0.22812, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.2892 - mae: 0.5266 - val_loss: 0.2281 - val_mae: 0.4719\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.2378 - mae: 0.4759\n",
      "Epoch 28: val_loss improved from 0.22812 to 0.18224, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.2378 - mae: 0.4759 - val_loss: 0.1822 - val_mae: 0.4212\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1922 - mae: 0.4254\n",
      "Epoch 29: val_loss improved from 0.18224 to 0.14171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1922 - mae: 0.4254 - val_loss: 0.1417 - val_mae: 0.3707\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1510 - mae: 0.3745\n",
      "Epoch 30: val_loss improved from 0.14171 to 0.10662, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.1510 - mae: 0.3745 - val_loss: 0.1066 - val_mae: 0.3207\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1157 - mae: 0.3241\n",
      "Epoch 31: val_loss improved from 0.10662 to 0.07699, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.1157 - mae: 0.3241 - val_loss: 0.0770 - val_mae: 0.2712\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0863 - mae: 0.2748\n",
      "Epoch 32: val_loss improved from 0.07699 to 0.05275, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0863 - mae: 0.2748 - val_loss: 0.0528 - val_mae: 0.2228\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0619 - mae: 0.2260\n",
      "Epoch 33: val_loss improved from 0.05275 to 0.03374, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0619 - mae: 0.2260 - val_loss: 0.0337 - val_mae: 0.1756\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0431 - mae: 0.1791\n",
      "Epoch 34: val_loss improved from 0.03374 to 0.01967, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0431 - mae: 0.1791 - val_loss: 0.0197 - val_mae: 0.1303\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0291 - mae: 0.1342\n",
      "Epoch 35: val_loss improved from 0.01967 to 0.01015, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0291 - mae: 0.1342 - val_loss: 0.0102 - val_mae: 0.0892\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0194 - mae: 0.0960\n",
      "Epoch 36: val_loss improved from 0.01015 to 0.00471, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0194 - mae: 0.0960 - val_loss: 0.0047 - val_mae: 0.0575\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0144 - mae: 0.0727\n",
      "Epoch 37: val_loss improved from 0.00471 to 0.00276, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0144 - mae: 0.0727 - val_loss: 0.0028 - val_mae: 0.0421\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0127 - mae: 0.0698\n",
      "Epoch 38: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0127 - mae: 0.0698 - val_loss: 0.0036 - val_mae: 0.0480\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0136 - mae: 0.0836\n",
      "Epoch 39: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0136 - mae: 0.0836 - val_loss: 0.0067 - val_mae: 0.0683\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0169 - mae: 0.1048\n",
      "Epoch 40: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0169 - mae: 0.1048 - val_loss: 0.0111 - val_mae: 0.0928\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0217 - mae: 0.1262\n",
      "Epoch 41: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0217 - mae: 0.1262 - val_loss: 0.0163 - val_mae: 0.1162\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0272 - mae: 0.1464\n",
      "Epoch 42: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0272 - mae: 0.1464 - val_loss: 0.0216 - val_mae: 0.1366\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0327 - mae: 0.1640\n",
      "Epoch 43: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0327 - mae: 0.1640 - val_loss: 0.0265 - val_mae: 0.1534\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0378 - mae: 0.1782\n",
      "Epoch 44: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0378 - mae: 0.1782 - val_loss: 0.0306 - val_mae: 0.1661\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0422 - mae: 0.1897\n",
      "Epoch 45: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0422 - mae: 0.1897 - val_loss: 0.0336 - val_mae: 0.1750\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0452 - mae: 0.1970\n",
      "Epoch 46: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0452 - mae: 0.1970 - val_loss: 0.0353 - val_mae: 0.1801\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0471 - mae: 0.2018\n",
      "Epoch 47: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0471 - mae: 0.2018 - val_loss: 0.0358 - val_mae: 0.1817\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0475 - mae: 0.2031\n",
      "Epoch 48: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0475 - mae: 0.2031 - val_loss: 0.0351 - val_mae: 0.1800\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0470 - mae: 0.2025\n",
      "Epoch 49: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0470 - mae: 0.2025 - val_loss: 0.0333 - val_mae: 0.1753\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0450 - mae: 0.1978\n",
      "Epoch 50: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0450 - mae: 0.1978 - val_loss: 0.0307 - val_mae: 0.1681\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0424 - mae: 0.1920\n",
      "Epoch 51: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0424 - mae: 0.1920 - val_loss: 0.0275 - val_mae: 0.1587\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0391 - mae: 0.1838\n",
      "Epoch 52: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0391 - mae: 0.1838 - val_loss: 0.0240 - val_mae: 0.1475\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0355 - mae: 0.1745\n",
      "Epoch 53: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0355 - mae: 0.1745 - val_loss: 0.0203 - val_mae: 0.1348\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0316 - mae: 0.1635\n",
      "Epoch 54: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0316 - mae: 0.1635 - val_loss: 0.0167 - val_mae: 0.1211\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0277 - mae: 0.1521\n",
      "Epoch 55: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0277 - mae: 0.1521 - val_loss: 0.0133 - val_mae: 0.1067\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0244 - mae: 0.1405\n",
      "Epoch 56: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0244 - mae: 0.1405 - val_loss: 0.0103 - val_mae: 0.0922\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0211 - mae: 0.1283\n",
      "Epoch 57: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0211 - mae: 0.1283 - val_loss: 0.0078 - val_mae: 0.0781\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0184 - mae: 0.1161\n",
      "Epoch 58: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0184 - mae: 0.1161 - val_loss: 0.0057 - val_mae: 0.0650\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0160 - mae: 0.1041\n",
      "Epoch 59: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0160 - mae: 0.1041 - val_loss: 0.0041 - val_mae: 0.0534\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0146 - mae: 0.0938\n",
      "Epoch 60: val_loss did not improve from 0.00276\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0146 - mae: 0.0938 - val_loss: 0.0030 - val_mae: 0.0440\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0134 - mae: 0.0839\n",
      "Epoch 61: val_loss improved from 0.00276 to 0.00232, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0134 - mae: 0.0839 - val_loss: 0.0023 - val_mae: 0.0376\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0125 - mae: 0.0757\n",
      "Epoch 62: val_loss improved from 0.00232 to 0.00201, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0125 - mae: 0.0757 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0120 - mae: 0.0687\n",
      "Epoch 63: val_loss improved from 0.00201 to 0.00200, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0120 - mae: 0.0687 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0119 - mae: 0.0638\n",
      "Epoch 64: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0119 - mae: 0.0638 - val_loss: 0.0022 - val_mae: 0.0383\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0613\n",
      "Epoch 65: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0122 - mae: 0.0613 - val_loss: 0.0026 - val_mae: 0.0421\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0123 - mae: 0.0606\n",
      "Epoch 66: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0123 - mae: 0.0606 - val_loss: 0.0030 - val_mae: 0.0462\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0130 - mae: 0.0623\n",
      "Epoch 67: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0130 - mae: 0.0623 - val_loss: 0.0035 - val_mae: 0.0501\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0130 - mae: 0.0636\n",
      "Epoch 68: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0130 - mae: 0.0636 - val_loss: 0.0040 - val_mae: 0.0536\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0136 - mae: 0.0658\n",
      "Epoch 69: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0136 - mae: 0.0658 - val_loss: 0.0044 - val_mae: 0.0565\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0140 - mae: 0.0676\n",
      "Epoch 70: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0140 - mae: 0.0676 - val_loss: 0.0047 - val_mae: 0.0587\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0138 - mae: 0.0684\n",
      "Epoch 71: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0138 - mae: 0.0684 - val_loss: 0.0049 - val_mae: 0.0601\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0146 - mae: 0.0706\n",
      "Epoch 72: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0146 - mae: 0.0706 - val_loss: 0.0050 - val_mae: 0.0609\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0142 - mae: 0.0704\n",
      "Epoch 73: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0142 - mae: 0.0704 - val_loss: 0.0050 - val_mae: 0.0609\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0146 - mae: 0.0710\n",
      "Epoch 74: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0146 - mae: 0.0710 - val_loss: 0.0049 - val_mae: 0.0603\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0143 - mae: 0.0702\n",
      "Epoch 75: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0143 - mae: 0.0702 - val_loss: 0.0048 - val_mae: 0.0592\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0142 - mae: 0.0696\n",
      "Epoch 76: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0142 - mae: 0.0696 - val_loss: 0.0045 - val_mae: 0.0575\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0141 - mae: 0.0684\n",
      "Epoch 77: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0141 - mae: 0.0684 - val_loss: 0.0042 - val_mae: 0.0555\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0136 - mae: 0.0666\n",
      "Epoch 78: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0136 - mae: 0.0666 - val_loss: 0.0039 - val_mae: 0.0533\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0133 - mae: 0.0654\n",
      "Epoch 79: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0133 - mae: 0.0654 - val_loss: 0.0036 - val_mae: 0.0509\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0129 - mae: 0.0634\n",
      "Epoch 80: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0129 - mae: 0.0634 - val_loss: 0.0033 - val_mae: 0.0484\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0126 - mae: 0.0619\n",
      "Epoch 81: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0126 - mae: 0.0619 - val_loss: 0.0030 - val_mae: 0.0459\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0128 - mae: 0.0620\n",
      "Epoch 82: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0128 - mae: 0.0620 - val_loss: 0.0027 - val_mae: 0.0436\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0123 - mae: 0.0607\n",
      "Epoch 83: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0123 - mae: 0.0607 - val_loss: 0.0025 - val_mae: 0.0415\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0123 - mae: 0.0604\n",
      "Epoch 84: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0123 - mae: 0.0604 - val_loss: 0.0023 - val_mae: 0.0395\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0121 - mae: 0.0606\n",
      "Epoch 85: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0121 - mae: 0.0606 - val_loss: 0.0022 - val_mae: 0.0379\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0610\n",
      "Epoch 86: val_loss did not improve from 0.00200\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0118 - mae: 0.0610 - val_loss: 0.0021 - val_mae: 0.0366\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0117 - mae: 0.0614\n",
      "Epoch 87: val_loss improved from 0.00200 to 0.00200, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0117 - mae: 0.0614 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0119 - mae: 0.0629\n",
      "Epoch 88: val_loss improved from 0.00200 to 0.00196, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0119 - mae: 0.0629 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0640\n",
      "Epoch 89: val_loss improved from 0.00196 to 0.00195, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0116 - mae: 0.0640 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0650\n",
      "Epoch 90: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0116 - mae: 0.0650 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0666\n",
      "Epoch 91: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0118 - mae: 0.0666 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0679\n",
      "Epoch 92: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0122 - mae: 0.0679 - val_loss: 0.0020 - val_mae: 0.0347\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0120 - mae: 0.0686\n",
      "Epoch 93: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0120 - mae: 0.0686 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0121 - mae: 0.0695\n",
      "Epoch 94: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0121 - mae: 0.0695 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0699\n",
      "Epoch 95: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0120 - mae: 0.0699 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0122 - mae: 0.0705\n",
      "Epoch 96: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0122 - mae: 0.0705 - val_loss: 0.0021 - val_mae: 0.0352\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0704\n",
      "Epoch 97: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0120 - mae: 0.0704 - val_loss: 0.0021 - val_mae: 0.0352\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0121 - mae: 0.0704\n",
      "Epoch 98: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0121 - mae: 0.0704 - val_loss: 0.0021 - val_mae: 0.0352\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0123 - mae: 0.0707\n",
      "Epoch 99: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0123 - mae: 0.0707 - val_loss: 0.0020 - val_mae: 0.0351\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0121 - mae: 0.0702\n",
      "Epoch 100: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0121 - mae: 0.0702 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0121 - mae: 0.0700\n",
      "Epoch 101: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0121 - mae: 0.0700 - val_loss: 0.0020 - val_mae: 0.0348\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0117 - mae: 0.0688\n",
      "Epoch 102: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0117 - mae: 0.0688 - val_loss: 0.0020 - val_mae: 0.0347\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0117 - mae: 0.0682\n",
      "Epoch 103: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0117 - mae: 0.0682 - val_loss: 0.0020 - val_mae: 0.0346\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0679\n",
      "Epoch 104: val_loss did not improve from 0.00195\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0118 - mae: 0.0679 - val_loss: 0.0020 - val_mae: 0.0345\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0675\n",
      "Epoch 105: val_loss improved from 0.00195 to 0.00195, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0118 - mae: 0.0675 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0659\n",
      "Epoch 106: val_loss improved from 0.00195 to 0.00194, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0115 - mae: 0.0659 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0661\n",
      "Epoch 107: val_loss improved from 0.00194 to 0.00194, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0118 - mae: 0.0661 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0646\n",
      "Epoch 108: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0112 - mae: 0.0646 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0642\n",
      "Epoch 109: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0114 - mae: 0.0642 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0639\n",
      "Epoch 110: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0116 - mae: 0.0639 - val_loss: 0.0020 - val_mae: 0.0350\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0639\n",
      "Epoch 111: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0118 - mae: 0.0639 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0628\n",
      "Epoch 112: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0114 - mae: 0.0628 - val_loss: 0.0020 - val_mae: 0.0354\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0113 - mae: 0.0626\n",
      "Epoch 113: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0113 - mae: 0.0626 - val_loss: 0.0020 - val_mae: 0.0356\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0626\n",
      "Epoch 114: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0116 - mae: 0.0626 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0620\n",
      "Epoch 115: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0115 - mae: 0.0620 - val_loss: 0.0020 - val_mae: 0.0359\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0117 - mae: 0.0624\n",
      "Epoch 116: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0117 - mae: 0.0624 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0619\n",
      "Epoch 117: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0116 - mae: 0.0619 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0614\n",
      "Epoch 118: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0114 - mae: 0.0614 - val_loss: 0.0020 - val_mae: 0.0361\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0620\n",
      "Epoch 119: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0115 - mae: 0.0620 - val_loss: 0.0020 - val_mae: 0.0361\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0117 - mae: 0.0622\n",
      "Epoch 120: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0117 - mae: 0.0622 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0117 - mae: 0.0622\n",
      "Epoch 121: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0117 - mae: 0.0622 - val_loss: 0.0020 - val_mae: 0.0360\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0617\n",
      "Epoch 122: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0114 - mae: 0.0617 - val_loss: 0.0020 - val_mae: 0.0359\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0115 - mae: 0.0616\n",
      "Epoch 123: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0115 - mae: 0.0616 - val_loss: 0.0020 - val_mae: 0.0358\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0614\n",
      "Epoch 124: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0113 - mae: 0.0614 - val_loss: 0.0020 - val_mae: 0.0357\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0618\n",
      "Epoch 125: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0114 - mae: 0.0618 - val_loss: 0.0020 - val_mae: 0.0356\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0624\n",
      "Epoch 126: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0116 - mae: 0.0624 - val_loss: 0.0020 - val_mae: 0.0355\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0115 - mae: 0.0623\n",
      "Epoch 127: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0115 - mae: 0.0623 - val_loss: 0.0020 - val_mae: 0.0353\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0118 - mae: 0.0629\n",
      "Epoch 128: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0118 - mae: 0.0629 - val_loss: 0.0020 - val_mae: 0.0352\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0629\n",
      "Epoch 129: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0115 - mae: 0.0629 - val_loss: 0.0019 - val_mae: 0.0351\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0115 - mae: 0.0627\n",
      "Epoch 130: val_loss did not improve from 0.00194\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0115 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0350\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0117 - mae: 0.0634\n",
      "Epoch 131: val_loss improved from 0.00194 to 0.00193, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0117 - mae: 0.0634 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0638\n",
      "Epoch 132: val_loss improved from 0.00193 to 0.00193, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0118 - mae: 0.0638 - val_loss: 0.0019 - val_mae: 0.0349\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0628\n",
      "Epoch 133: val_loss improved from 0.00193 to 0.00192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0112 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0348\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0636\n",
      "Epoch 134: val_loss improved from 0.00192 to 0.00192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0115 - mae: 0.0636 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0631\n",
      "Epoch 135: val_loss improved from 0.00192 to 0.00192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0113 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0633\n",
      "Epoch 136: val_loss improved from 0.00192 to 0.00192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0114 - mae: 0.0633 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0640\n",
      "Epoch 137: val_loss improved from 0.00192 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0116 - mae: 0.0640 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0643\n",
      "Epoch 138: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0118 - mae: 0.0643 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0641\n",
      "Epoch 139: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0115 - mae: 0.0641 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0638\n",
      "Epoch 140: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0113 - mae: 0.0638 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0640\n",
      "Epoch 141: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0115 - mae: 0.0640 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0116 - mae: 0.0640\n",
      "Epoch 142: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0116 - mae: 0.0640 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0637\n",
      "Epoch 143: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0114 - mae: 0.0637 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0636\n",
      "Epoch 144: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0114 - mae: 0.0636 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0117 - mae: 0.0642\n",
      "Epoch 145: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0117 - mae: 0.0642 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0632\n",
      "Epoch 146: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0112 - mae: 0.0632 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0115 - mae: 0.0635\n",
      "Epoch 147: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0115 - mae: 0.0635 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0117 - mae: 0.0641\n",
      "Epoch 148: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0117 - mae: 0.0641 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0635\n",
      "Epoch 149: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0115 - mae: 0.0635 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0118 - mae: 0.0642\n",
      "Epoch 150: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0118 - mae: 0.0642 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0633\n",
      "Epoch 151: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0116 - mae: 0.0633 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0631\n",
      "Epoch 152: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0113 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0629\n",
      "Epoch 153: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0114 - mae: 0.0629 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0635\n",
      "Epoch 154: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0116 - mae: 0.0635 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0117 - mae: 0.0637\n",
      "Epoch 155: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0117 - mae: 0.0637 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0628\n",
      "Epoch 156: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0114 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0634\n",
      "Epoch 157: val_loss did not improve from 0.00191\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0116 - mae: 0.0634 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0632\n",
      "Epoch 158: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0115 - mae: 0.0632 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 159: val_loss improved from 0.00191 to 0.00191, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0116 - mae: 0.0632\n",
      "Epoch 160: val_loss improved from 0.00191 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0116 - mae: 0.0632 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0628\n",
      "Epoch 161: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0114 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0625\n",
      "Epoch 162: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0112 - mae: 0.0625 - val_loss: 0.0019 - val_mae: 0.0347\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0631\n",
      "Epoch 163: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0114 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0631\n",
      "Epoch 164: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0115 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0116 - mae: 0.0632\n",
      "Epoch 165: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0116 - mae: 0.0632 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0116 - mae: 0.0634\n",
      "Epoch 166: val_loss improved from 0.00190 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0116 - mae: 0.0634 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0116 - mae: 0.0635\n",
      "Epoch 167: val_loss improved from 0.00190 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0116 - mae: 0.0635 - val_loss: 0.0019 - val_mae: 0.0346\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0630\n",
      "Epoch 168: val_loss improved from 0.00189 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0114 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0630\n",
      "Epoch 169: val_loss improved from 0.00189 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0115 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0628\n",
      "Epoch 170: val_loss improved from 0.00189 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0112 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0117 - mae: 0.0636\n",
      "Epoch 171: val_loss improved from 0.00189 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0117 - mae: 0.0636 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0115 - mae: 0.0632\n",
      "Epoch 172: val_loss improved from 0.00189 to 0.00189, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0115 - mae: 0.0632 - val_loss: 0.0019 - val_mae: 0.0345\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0640\n",
      "Epoch 173: val_loss improved from 0.00189 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0118 - mae: 0.0640 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0631\n",
      "Epoch 174: val_loss improved from 0.00188 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0114 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0116 - mae: 0.0635\n",
      "Epoch 175: val_loss improved from 0.00188 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0116 - mae: 0.0635 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0631\n",
      "Epoch 176: val_loss improved from 0.00188 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0113 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 177: val_loss improved from 0.00188 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0344\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0631\n",
      "Epoch 178: val_loss improved from 0.00188 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0114 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0112 - mae: 0.0631\n",
      "Epoch 179: val_loss improved from 0.00188 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 130ms/step - loss: 0.0112 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 180: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0631\n",
      "Epoch 181: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0114 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 182: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0630\n",
      "Epoch 183: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0114 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0630\n",
      "Epoch 184: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0113 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0628\n",
      "Epoch 185: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0112 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0112 - mae: 0.0629\n",
      "Epoch 186: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0629\n",
      "Epoch 187: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0113 - mae: 0.0629 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0630\n",
      "Epoch 188: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0113 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0112 - mae: 0.0628\n",
      "Epoch 189: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0112 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0114 - mae: 0.0633\n",
      "Epoch 190: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0114 - mae: 0.0633 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0627\n",
      "Epoch 191: val_loss improved from 0.00187 to 0.00187, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0112 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0624\n",
      "Epoch 192: val_loss improved from 0.00187 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0109 - mae: 0.0624 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0630\n",
      "Epoch 193: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0113 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 194: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0625\n",
      "Epoch 195: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0110 - mae: 0.0625 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0628\n",
      "Epoch 196: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0113 - mae: 0.0628 - val_loss: 0.0019 - val_mae: 0.0343\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0113 - mae: 0.0631\n",
      "Epoch 197: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0113 - mae: 0.0631 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 198: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0627\n",
      "Epoch 199: val_loss improved from 0.00186 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0113 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0115 - mae: 0.0634\n",
      "Epoch 200: val_loss improved from 0.00186 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0115 - mae: 0.0634 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0112 - mae: 0.0627\n",
      "Epoch 201: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0112 - mae: 0.0627 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0114 - mae: 0.0630\n",
      "Epoch 202: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0114 - mae: 0.0630 - val_loss: 0.0019 - val_mae: 0.0342\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 203: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0622\n",
      "Epoch 204: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0110 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 205: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0627\n",
      "Epoch 206: val_loss improved from 0.00185 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0113 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0625\n",
      "Epoch 207: val_loss improved from 0.00185 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0110 - mae: 0.0625 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 208: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0629\n",
      "Epoch 209: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0113 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0627\n",
      "Epoch 210: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0110 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0631\n",
      "Epoch 211: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0113 - mae: 0.0631 - val_loss: 0.0018 - val_mae: 0.0341\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0113 - mae: 0.0630\n",
      "Epoch 212: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0113 - mae: 0.0630 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 213: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0630\n",
      "Epoch 214: val_loss improved from 0.00184 to 0.00184, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0113 - mae: 0.0630 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0627\n",
      "Epoch 215: val_loss improved from 0.00184 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0110 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0628\n",
      "Epoch 216: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0111 - mae: 0.0628 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0626\n",
      "Epoch 217: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0109 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0624\n",
      "Epoch 218: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0110 - mae: 0.0624 - val_loss: 0.0018 - val_mae: 0.0340\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0622\n",
      "Epoch 219: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0109 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0627\n",
      "Epoch 220: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0110 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0112 - mae: 0.0629\n",
      "Epoch 221: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 222: val_loss improved from 0.00183 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 223: val_loss improved from 0.00183 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0629\n",
      "Epoch 224: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0113 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0112 - mae: 0.0626\n",
      "Epoch 225: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0112 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0112 - mae: 0.0629\n",
      "Epoch 226: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0112 - mae: 0.0627\n",
      "Epoch 227: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0112 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 228: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0109 - mae: 0.0622\n",
      "Epoch 229: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0109 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0339\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0625\n",
      "Epoch 230: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0110 - mae: 0.0625 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0625\n",
      "Epoch 231: val_loss improved from 0.00182 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0110 - mae: 0.0625 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0618\n",
      "Epoch 232: val_loss improved from 0.00182 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0107 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 233: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0107 - mae: 0.0619\n",
      "Epoch 234: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0107 - mae: 0.0619 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 235: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0625\n",
      "Epoch 236: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0111 - mae: 0.0625 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 237: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0622\n",
      "Epoch 238: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0109 - mae: 0.0622 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0627\n",
      "Epoch 239: val_loss improved from 0.00181 to 0.00181, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0110 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0338\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 240: val_loss improved from 0.00181 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0620\n",
      "Epoch 241: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0108 - mae: 0.0620 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 242: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0619\n",
      "Epoch 243: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0108 - mae: 0.0619 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 244: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0619\n",
      "Epoch 245: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0108 - mae: 0.0619 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0620\n",
      "Epoch 246: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0108 - mae: 0.0620 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0112 - mae: 0.0629\n",
      "Epoch 247: val_loss improved from 0.00180 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0337\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0624\n",
      "Epoch 248: val_loss improved from 0.00180 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0110 - mae: 0.0624 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0619\n",
      "Epoch 249: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0108 - mae: 0.0619 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0629\n",
      "Epoch 250: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0111 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0110 - mae: 0.0624\n",
      "Epoch 251: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0110 - mae: 0.0624 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0111 - mae: 0.0626\n",
      "Epoch 252: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0111 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0629\n",
      "Epoch 253: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0112 - mae: 0.0629 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 254: val_loss improved from 0.00179 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0018 - val_mae: 0.0336\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0110 - mae: 0.0625\n",
      "Epoch 255: val_loss improved from 0.00179 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0110 - mae: 0.0625 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0620\n",
      "Epoch 256: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0107 - mae: 0.0620 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0620\n",
      "Epoch 257: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0107 - mae: 0.0620 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0624\n",
      "Epoch 258: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0109 - mae: 0.0624 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0111 - mae: 0.0627\n",
      "Epoch 259: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0111 - mae: 0.0627 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 260: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0621\n",
      "Epoch 261: val_loss improved from 0.00178 to 0.00178, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0106 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0335\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 262: val_loss improved from 0.00178 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 263: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 264: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 265: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0623\n",
      "Epoch 266: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0107 - mae: 0.0623 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 267: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0107 - mae: 0.0621\n",
      "Epoch 268: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0107 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 269: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 270: val_loss improved from 0.00177 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 271: val_loss improved from 0.00177 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0105 - mae: 0.0615\n",
      "Epoch 272: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0105 - mae: 0.0615 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0621\n",
      "Epoch 273: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0108 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 274: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0334\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 275: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0618\n",
      "Epoch 276: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0107 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 277: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0621\n",
      "Epoch 278: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0109 - mae: 0.0621 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0614\n",
      "Epoch 279: val_loss improved from 0.00176 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0105 - mae: 0.0614 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0110 - mae: 0.0626\n",
      "Epoch 280: val_loss improved from 0.00176 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0110 - mae: 0.0626 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0108 - mae: 0.0619\n",
      "Epoch 281: val_loss improved from 0.00175 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0108 - mae: 0.0619 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0615\n",
      "Epoch 282: val_loss improved from 0.00175 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0615 - val_loss: 0.0018 - val_mae: 0.0333\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0109 - mae: 0.0621\n",
      "Epoch 283: val_loss improved from 0.00175 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0109 - mae: 0.0621 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0618\n",
      "Epoch 284: val_loss improved from 0.00175 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0107 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 285: val_loss improved from 0.00175 to 0.00175, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0616\n",
      "Epoch 286: val_loss improved from 0.00175 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0107 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 287: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0109 - mae: 0.0623\n",
      "Epoch 288: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0017 - val_mae: 0.0332\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 289: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0109 - mae: 0.0624\n",
      "Epoch 290: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0109 - mae: 0.0624 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 291: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0620\n",
      "Epoch 292: val_loss improved from 0.00174 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0107 - mae: 0.0620 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0105 - mae: 0.0617\n",
      "Epoch 293: val_loss improved from 0.00174 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0105 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0105 - mae: 0.0617\n",
      "Epoch 294: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0105 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0621\n",
      "Epoch 295: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0107 - mae: 0.0621 - val_loss: 0.0017 - val_mae: 0.0331\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0107 - mae: 0.0620\n",
      "Epoch 296: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0107 - mae: 0.0620 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0618\n",
      "Epoch 297: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0107 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 298: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0619\n",
      "Epoch 299: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0107 - mae: 0.0619 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0106 - mae: 0.0619\n",
      "Epoch 300: val_loss improved from 0.00173 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0106 - mae: 0.0619 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 301: val_loss improved from 0.00173 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0107 - mae: 0.0619\n",
      "Epoch 302: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0107 - mae: 0.0619 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0615\n",
      "Epoch 303: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0104 - mae: 0.0615 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0617\n",
      "Epoch 304: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0105 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0616\n",
      "Epoch 305: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0106 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0330\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0616\n",
      "Epoch 306: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0106 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0620\n",
      "Epoch 307: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0106 - mae: 0.0620 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 308: val_loss improved from 0.00172 to 0.00172, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 309: val_loss improved from 0.00172 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0611\n",
      "Epoch 310: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0104 - mae: 0.0611 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0109 - mae: 0.0620\n",
      "Epoch 311: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0109 - mae: 0.0620 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0614\n",
      "Epoch 312: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0105 - mae: 0.0614 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0613\n",
      "Epoch 313: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0329\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0618\n",
      "Epoch 314: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0106 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0107 - mae: 0.0617\n",
      "Epoch 315: val_loss improved from 0.00171 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0107 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 316: val_loss improved from 0.00171 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 317: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0613\n",
      "Epoch 318: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0104 - mae: 0.0616\n",
      "Epoch 319: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0104 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0619\n",
      "Epoch 320: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0619 - val_loss: 0.0017 - val_mae: 0.0328\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0613\n",
      "Epoch 321: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0105 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0613\n",
      "Epoch 322: val_loss improved from 0.00170 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0106 - mae: 0.0619\n",
      "Epoch 323: val_loss improved from 0.00170 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0106 - mae: 0.0619 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0105 - mae: 0.0617\n",
      "Epoch 324: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0105 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0107 - mae: 0.0621\n",
      "Epoch 325: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0107 - mae: 0.0621 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 326: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0610\n",
      "Epoch 327: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 0.0017 - val_mae: 0.0327\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0103 - mae: 0.0616\n",
      "Epoch 328: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0103 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0105 - mae: 0.0618\n",
      "Epoch 329: val_loss improved from 0.00169 to 0.00169, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0105 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0104 - mae: 0.0612\n",
      "Epoch 330: val_loss improved from 0.00169 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0104 - mae: 0.0612 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - mae: 0.0613\n",
      "Epoch 331: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0105 - mae: 0.0615\n",
      "Epoch 332: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0105 - mae: 0.0615 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0106 - mae: 0.0617\n",
      "Epoch 333: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0106 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0614\n",
      "Epoch 334: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0104 - mae: 0.0614 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0101 - mae: 0.0609\n",
      "Epoch 335: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0326\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0105 - mae: 0.0615\n",
      "Epoch 336: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0105 - mae: 0.0615 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 337: val_loss improved from 0.00168 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0609\n",
      "Epoch 338: val_loss improved from 0.00168 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0102 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0618\n",
      "Epoch 339: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0105 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0105 - mae: 0.0617\n",
      "Epoch 340: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0105 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0616\n",
      "Epoch 341: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0105 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0102 - mae: 0.0613\n",
      "Epoch 342: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0102 - mae: 0.0613 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0612\n",
      "Epoch 343: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0103 - mae: 0.0612 - val_loss: 0.0017 - val_mae: 0.0325\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0104 - mae: 0.0614\n",
      "Epoch 344: val_loss improved from 0.00167 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0104 - mae: 0.0614 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - mae: 0.0615\n",
      "Epoch 345: val_loss improved from 0.00167 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0104 - mae: 0.0615 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0104 - mae: 0.0614\n",
      "Epoch 346: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0104 - mae: 0.0614 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0104 - mae: 0.0616\n",
      "Epoch 347: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0104 - mae: 0.0616 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 348: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0104 - mae: 0.0615\n",
      "Epoch 349: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0104 - mae: 0.0615 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0102 - mae: 0.0612\n",
      "Epoch 350: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0102 - mae: 0.0612 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 351: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0609\n",
      "Epoch 352: val_loss improved from 0.00166 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0105 - mae: 0.0618\n",
      "Epoch 353: val_loss improved from 0.00166 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0105 - mae: 0.0618 - val_loss: 0.0017 - val_mae: 0.0324\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0609\n",
      "Epoch 354: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 355: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0101 - mae: 0.0608\n",
      "Epoch 356: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0101 - mae: 0.0608 - val_loss: 0.0017 - val_mae: 0.0323\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0102 - mae: 0.0610\n",
      "Epoch 357: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0608\n",
      "Epoch 358: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0102 - mae: 0.0608 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0610\n",
      "Epoch 359: val_loss improved from 0.00165 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - mae: 0.0612\n",
      "Epoch 360: val_loss improved from 0.00165 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0103 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0323\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - mae: 0.0611\n",
      "Epoch 361: val_loss improved from 0.00164 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0103 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0103 - mae: 0.0610\n",
      "Epoch 362: val_loss improved from 0.00164 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0103 - mae: 0.0610 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 363: val_loss improved from 0.00164 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0105 - mae: 0.0615\n",
      "Epoch 364: val_loss improved from 0.00164 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0105 - mae: 0.0615 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0612\n",
      "Epoch 365: val_loss improved from 0.00164 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0103 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0322\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0103 - mae: 0.0614\n",
      "Epoch 366: val_loss improved from 0.00164 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0103 - mae: 0.0614 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0611\n",
      "Epoch 367: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0103 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0105 - mae: 0.0615\n",
      "Epoch 368: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0105 - mae: 0.0615 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0101 - mae: 0.0608\n",
      "Epoch 369: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0101 - mae: 0.0608 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0103 - mae: 0.0612\n",
      "Epoch 370: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0103 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0100 - mae: 0.0608\n",
      "Epoch 371: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0100 - mae: 0.0608 - val_loss: 0.0016 - val_mae: 0.0321\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0101 - mae: 0.0609\n",
      "Epoch 372: val_loss improved from 0.00163 to 0.00163, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 373: val_loss improved from 0.00163 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0611\n",
      "Epoch 374: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0100 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0100 - mae: 0.0605\n",
      "Epoch 375: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0100 - mae: 0.0605 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 376: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 377: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 378: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0610\n",
      "Epoch 379: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0609\n",
      "Epoch 380: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0102 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0104 - mae: 0.0612\n",
      "Epoch 381: val_loss improved from 0.00162 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0104 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0102 - mae: 0.0610\n",
      "Epoch 382: val_loss improved from 0.00162 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0101 - mae: 0.0606\n",
      "Epoch 383: val_loss improved from 0.00161 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0101 - mae: 0.0606 - val_loss: 0.0016 - val_mae: 0.0320\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0102 - mae: 0.0612\n",
      "Epoch 384: val_loss improved from 0.00161 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0102 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0103 - mae: 0.0615\n",
      "Epoch 385: val_loss improved from 0.00161 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0103 - mae: 0.0615 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0604\n",
      "Epoch 386: val_loss improved from 0.00161 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0099 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0613\n",
      "Epoch 387: val_loss improved from 0.00161 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0102 - mae: 0.0613 - val_loss: 0.0016 - val_mae: 0.0319\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0611\n",
      "Epoch 388: val_loss improved from 0.00161 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0102 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 389: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0102 - mae: 0.0612\n",
      "Epoch 390: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0102 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0609\n",
      "Epoch 391: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0100 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0607\n",
      "Epoch 392: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0606\n",
      "Epoch 393: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0098 - mae: 0.0606 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0604\n",
      "Epoch 394: val_loss improved from 0.00160 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0099 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0100 - mae: 0.0609\n",
      "Epoch 395: val_loss improved from 0.00160 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0100 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0318\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0099 - mae: 0.0605\n",
      "Epoch 396: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0099 - mae: 0.0605 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0609\n",
      "Epoch 397: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0100 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0606\n",
      "Epoch 398: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0100 - mae: 0.0606 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0605\n",
      "Epoch 399: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0099 - mae: 0.0605 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0102 - mae: 0.0612\n",
      "Epoch 400: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0102 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0604\n",
      "Epoch 401: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0098 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0606\n",
      "Epoch 402: val_loss improved from 0.00159 to 0.00159, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0100 - mae: 0.0606 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0098 - mae: 0.0602\n",
      "Epoch 403: val_loss improved from 0.00159 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0098 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0100 - mae: 0.0605\n",
      "Epoch 404: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0100 - mae: 0.0605 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0097 - mae: 0.0598\n",
      "Epoch 405: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0097 - mae: 0.0598 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0101 - mae: 0.0607\n",
      "Epoch 406: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0101 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0602\n",
      "Epoch 407: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0099 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0317\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 408: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0603\n",
      "Epoch 409: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0098 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0603\n",
      "Epoch 410: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0098 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0599\n",
      "Epoch 411: val_loss improved from 0.00158 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0098 - mae: 0.0599 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0603\n",
      "Epoch 412: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0097 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0098 - mae: 0.0598\n",
      "Epoch 413: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0098 - mae: 0.0598 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0608\n",
      "Epoch 414: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0101 - mae: 0.0608 - val_loss: 0.0016 - val_mae: 0.0316\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 415: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 416: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0095 - mae: 0.0597 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0604\n",
      "Epoch 417: val_loss improved from 0.00157 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0099 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0599\n",
      "Epoch 418: val_loss improved from 0.00157 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0098 - mae: 0.0599 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0602\n",
      "Epoch 419: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0099 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0098 - mae: 0.0603\n",
      "Epoch 420: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0098 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0097 - mae: 0.0598\n",
      "Epoch 421: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0097 - mae: 0.0598 - val_loss: 0.0016 - val_mae: 0.0315\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0098 - mae: 0.0604\n",
      "Epoch 422: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0098 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0603\n",
      "Epoch 423: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0099 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0100 - mae: 0.0605\n",
      "Epoch 424: val_loss improved from 0.00156 to 0.00156, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0100 - mae: 0.0605 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0609\n",
      "Epoch 425: val_loss improved from 0.00156 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0101 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0098 - mae: 0.0603\n",
      "Epoch 426: val_loss improved from 0.00155 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0098 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0314\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 427: val_loss improved from 0.00155 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0016 - val_mae: 0.0313\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 428: val_loss improved from 0.00155 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0601\n",
      "Epoch 429: val_loss improved from 0.00155 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0097 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 430: val_loss improved from 0.00155 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0096 - mae: 0.0598 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0100 - mae: 0.0608\n",
      "Epoch 431: val_loss improved from 0.00155 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0100 - mae: 0.0608 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0098 - mae: 0.0601\n",
      "Epoch 432: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0098 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 433: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0096 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0313\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0601\n",
      "Epoch 434: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0096 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0097 - mae: 0.0601\n",
      "Epoch 435: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0097 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0601\n",
      "Epoch 436: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0098 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 437: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - mae: 0.0595\n",
      "Epoch 438: val_loss improved from 0.00154 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0096 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 439: val_loss improved from 0.00154 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 440: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 441: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0596\n",
      "Epoch 442: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0096 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0098 - mae: 0.0602\n",
      "Epoch 443: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0098 - mae: 0.0602 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0597\n",
      "Epoch 444: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0096 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0603\n",
      "Epoch 445: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0099 - mae: 0.0603 - val_loss: 0.0015 - val_mae: 0.0312\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 446: val_loss improved from 0.00153 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0606\n",
      "Epoch 447: val_loss improved from 0.00153 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0099 - mae: 0.0606 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 448: val_loss improved from 0.00152 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0094 - mae: 0.0593\n",
      "Epoch 449: val_loss improved from 0.00152 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0094 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0311\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 450: val_loss improved from 0.00152 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 451: val_loss improved from 0.00152 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0597\n",
      "Epoch 452: val_loss improved from 0.00152 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0096 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0095 - mae: 0.0599\n",
      "Epoch 453: val_loss improved from 0.00152 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0095 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 454: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0096 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 455: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0310\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0096 - mae: 0.0597\n",
      "Epoch 456: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0096 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 457: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0094 - mae: 0.0593\n",
      "Epoch 458: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0094 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 459: val_loss improved from 0.00151 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - mae: 0.0598\n",
      "Epoch 460: val_loss improved from 0.00151 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0096 - mae: 0.0598 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0603\n",
      "Epoch 461: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0099 - mae: 0.0603 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0097 - mae: 0.0598\n",
      "Epoch 462: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0097 - mae: 0.0598 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 463: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0309\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 464: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 465: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0094 - mae: 0.0595\n",
      "Epoch 466: val_loss improved from 0.00150 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0094 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0601\n",
      "Epoch 467: val_loss improved from 0.00150 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0097 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 468: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0095 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0599\n",
      "Epoch 469: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0097 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0308\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0600\n",
      "Epoch 470: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0097 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - mae: 0.0600\n",
      "Epoch 471: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0096 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0092 - mae: 0.0592\n",
      "Epoch 472: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0092 - mae: 0.0592 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 473: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0095 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 474: val_loss improved from 0.00149 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0095 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 475: val_loss improved from 0.00149 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 476: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0094 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 477: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0096 - mae: 0.0597\n",
      "Epoch 478: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0096 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 479: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0307\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0589\n",
      "Epoch 480: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0092 - mae: 0.0589 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0590\n",
      "Epoch 481: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0093 - mae: 0.0590 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0099 - mae: 0.0601\n",
      "Epoch 482: val_loss improved from 0.00148 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0099 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 483: val_loss improved from 0.00148 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 484: val_loss improved from 0.00147 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0094 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 485: val_loss improved from 0.00147 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0596\n",
      "Epoch 486: val_loss improved from 0.00147 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0096 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0306\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0096 - mae: 0.0593\n",
      "Epoch 487: val_loss improved from 0.00147 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0096 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0596\n",
      "Epoch 488: val_loss improved from 0.00147 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0094 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0590\n",
      "Epoch 489: val_loss improved from 0.00147 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0093 - mae: 0.0590 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0092 - mae: 0.0590\n",
      "Epoch 490: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 127ms/step - loss: 0.0092 - mae: 0.0590 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0095 - mae: 0.0596\n",
      "Epoch 491: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0095 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0305\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0096 - mae: 0.0596\n",
      "Epoch 492: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0096 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 493: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0093 - mae: 0.0593\n",
      "Epoch 494: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 131ms/step - loss: 0.0093 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 495: val_loss improved from 0.00146 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0094 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0593\n",
      "Epoch 496: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0093 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 497: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0094 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0304\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 498: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0095 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0303\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 0.0095 - mae: 0.0595\n",
      "Epoch 499: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0095 - mae: 0.0595 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0595\n",
      "Epoch 500: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0094 - mae: 0.0595 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0597\n",
      "Epoch 501: val_loss improved from 0.00145 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0094 - mae: 0.0597 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0094 - mae: 0.0595\n",
      "Epoch 502: val_loss improved from 0.00145 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0094 - mae: 0.0595 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0588\n",
      "Epoch 503: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0095 - mae: 0.0597\n",
      "Epoch 504: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0095 - mae: 0.0597 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0592\n",
      "Epoch 505: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0094 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0588\n",
      "Epoch 506: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0303\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0096 - mae: 0.0599\n",
      "Epoch 507: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 132ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0589\n",
      "Epoch 508: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0092 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 509: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0590\n",
      "Epoch 510: val_loss improved from 0.00144 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0094 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 511: val_loss improved from 0.00144 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0592\n",
      "Epoch 512: val_loss improved from 0.00143 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0094 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0594\n",
      "Epoch 513: val_loss improved from 0.00143 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0094 - mae: 0.0594 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0592\n",
      "Epoch 514: val_loss improved from 0.00143 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0094 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0302\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0094 - mae: 0.0593\n",
      "Epoch 515: val_loss improved from 0.00143 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0094 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0589\n",
      "Epoch 516: val_loss improved from 0.00143 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0091 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0589\n",
      "Epoch 517: val_loss improved from 0.00143 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0092 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 518: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 519: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 520: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0301\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0593\n",
      "Epoch 521: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0093 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0300\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0592\n",
      "Epoch 522: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0093 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0300\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 523: val_loss improved from 0.00142 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0300\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 524: val_loss improved from 0.00141 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0300\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0592\n",
      "Epoch 525: val_loss improved from 0.00141 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0091 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0590\n",
      "Epoch 526: val_loss improved from 0.00141 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0093 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0592\n",
      "Epoch 527: val_loss improved from 0.00141 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0091 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0582\n",
      "Epoch 528: val_loss improved from 0.00141 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0089 - mae: 0.0582 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0092 - mae: 0.0591\n",
      "Epoch 529: val_loss improved from 0.00141 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0092 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0091 - mae: 0.0587\n",
      "Epoch 530: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0091 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 531: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 532: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 533: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 596ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0299\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0089 - mae: 0.0583\n",
      "Epoch 534: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0089 - mae: 0.0583 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0587\n",
      "Epoch 535: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 557ms/step - loss: 0.0091 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0592\n",
      "Epoch 536: val_loss improved from 0.00140 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0093 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0588\n",
      "Epoch 537: val_loss improved from 0.00140 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0584\n",
      "Epoch 538: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0090 - mae: 0.0584 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0091 - mae: 0.0587\n",
      "Epoch 539: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0091 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0298\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 540: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0592\n",
      "Epoch 541: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0092 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 542: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 543: val_loss improved from 0.00139 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0587\n",
      "Epoch 544: val_loss improved from 0.00138 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0091 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0297\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0588\n",
      "Epoch 545: val_loss improved from 0.00138 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0593\n",
      "Epoch 546: val_loss improved from 0.00138 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0093 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0591\n",
      "Epoch 547: val_loss improved from 0.00138 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0091 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0091 - mae: 0.0590\n",
      "Epoch 548: val_loss improved from 0.00138 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0091 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 549: val_loss improved from 0.00138 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0296\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 550: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 551: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0093 - mae: 0.0591\n",
      "Epoch 552: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0093 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0093 - mae: 0.0594\n",
      "Epoch 553: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0093 - mae: 0.0594 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 554: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0089 - mae: 0.0584\n",
      "Epoch 555: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0089 - mae: 0.0584 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0586\n",
      "Epoch 556: val_loss improved from 0.00137 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0090 - mae: 0.0586 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 557: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0583\n",
      "Epoch 558: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0089 - mae: 0.0583 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0587\n",
      "Epoch 559: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0091 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0587\n",
      "Epoch 560: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0092 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0295\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 561: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0590\n",
      "Epoch 562: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0091 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0581\n",
      "Epoch 563: val_loss improved from 0.00136 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0089 - mae: 0.0581 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0091 - mae: 0.0586\n",
      "Epoch 564: val_loss improved from 0.00136 to 0.00135, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0091 - mae: 0.0586 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0591\n",
      "Epoch 565: val_loss improved from 0.00135 to 0.00135, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0092 - mae: 0.0591 - val_loss: 0.0014 - val_mae: 0.0294\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0586\n",
      "Epoch 566: val_loss improved from 0.00135 to 0.00135, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0091 - mae: 0.0586 - val_loss: 0.0013 - val_mae: 0.0293\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 567: val_loss improved from 0.00135 to 0.00135, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 157ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0293\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 568: val_loss improved from 0.00135 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0293\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0092 - mae: 0.0589\n",
      "Epoch 569: val_loss improved from 0.00134 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0092 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0292\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0091 - mae: 0.0589\n",
      "Epoch 570: val_loss improved from 0.00134 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0091 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0292\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 571: val_loss improved from 0.00134 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0292\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0583\n",
      "Epoch 572: val_loss improved from 0.00134 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0089 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0090 - mae: 0.0589\n",
      "Epoch 573: val_loss improved from 0.00134 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0090 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 574: val_loss improved from 0.00133 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0586\n",
      "Epoch 575: val_loss improved from 0.00133 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0089 - mae: 0.0586 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0583\n",
      "Epoch 576: val_loss improved from 0.00133 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0088 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0579\n",
      "Epoch 577: val_loss improved from 0.00133 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0087 - mae: 0.0579 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0586\n",
      "Epoch 578: val_loss improved from 0.00133 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0090 - mae: 0.0586 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0090 - mae: 0.0587\n",
      "Epoch 579: val_loss improved from 0.00133 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0090 - mae: 0.0587 - val_loss: 0.0013 - val_mae: 0.0291\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 580: val_loss improved from 0.00132 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - mae: 0.0584\n",
      "Epoch 581: val_loss improved from 0.00132 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0089 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0585\n",
      "Epoch 582: val_loss improved from 0.00132 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0090 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 583: val_loss improved from 0.00132 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0089 - mae: 0.0583\n",
      "Epoch 584: val_loss improved from 0.00132 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0089 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0290\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0581\n",
      "Epoch 585: val_loss improved from 0.00131 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0088 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0092 - mae: 0.0589\n",
      "Epoch 586: val_loss improved from 0.00131 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0092 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0583\n",
      "Epoch 587: val_loss improved from 0.00131 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0089 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0289\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0091 - mae: 0.0588\n",
      "Epoch 588: val_loss improved from 0.00131 to 0.00130, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0091 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0288\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0581\n",
      "Epoch 589: val_loss improved from 0.00130 to 0.00130, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0087 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0288\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - mae: 0.0581\n",
      "Epoch 590: val_loss improved from 0.00130 to 0.00130, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0087 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0287\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0583\n",
      "Epoch 591: val_loss improved from 0.00130 to 0.00130, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0088 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0287\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0591\n",
      "Epoch 592: val_loss improved from 0.00130 to 0.00129, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0091 - mae: 0.0591 - val_loss: 0.0013 - val_mae: 0.0287\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0088 - mae: 0.0584\n",
      "Epoch 593: val_loss improved from 0.00129 to 0.00129, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0088 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 594: val_loss improved from 0.00129 to 0.00129, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0286\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0585\n",
      "Epoch 595: val_loss improved from 0.00129 to 0.00128, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0088 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0589\n",
      "Epoch 596: val_loss improved from 0.00128 to 0.00128, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0089 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0586\n",
      "Epoch 597: val_loss improved from 0.00128 to 0.00128, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0087 - mae: 0.0586 - val_loss: 0.0013 - val_mae: 0.0285\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0086 - mae: 0.0581\n",
      "Epoch 598: val_loss improved from 0.00128 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0086 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0284\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0581\n",
      "Epoch 599: val_loss improved from 0.00127 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0086 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0284\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0582\n",
      "Epoch 600: val_loss improved from 0.00127 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0087 - mae: 0.0582 - val_loss: 0.0013 - val_mae: 0.0284\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0584\n",
      "Epoch 601: val_loss improved from 0.00127 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0087 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0283\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0090 - mae: 0.0588\n",
      "Epoch 602: val_loss improved from 0.00127 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0090 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0283\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 603: val_loss improved from 0.00126 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0013 - val_mae: 0.0283\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0583\n",
      "Epoch 604: val_loss improved from 0.00126 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0088 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0283\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0087 - mae: 0.0582\n",
      "Epoch 605: val_loss improved from 0.00126 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0087 - mae: 0.0582 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0580\n",
      "Epoch 606: val_loss improved from 0.00126 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0086 - mae: 0.0580 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 607: val_loss improved from 0.00125 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0282\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0585\n",
      "Epoch 608: val_loss improved from 0.00125 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0088 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0281\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0577\n",
      "Epoch 609: val_loss improved from 0.00125 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0086 - mae: 0.0577 - val_loss: 0.0012 - val_mae: 0.0281\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0578\n",
      "Epoch 610: val_loss improved from 0.00125 to 0.00124, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0085 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0280\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0088 - mae: 0.0581\n",
      "Epoch 611: val_loss improved from 0.00124 to 0.00124, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0088 - mae: 0.0581 - val_loss: 0.0012 - val_mae: 0.0280\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0583\n",
      "Epoch 612: val_loss improved from 0.00124 to 0.00124, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0087 - mae: 0.0583 - val_loss: 0.0012 - val_mae: 0.0280\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0086 - mae: 0.0579\n",
      "Epoch 613: val_loss improved from 0.00124 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0086 - mae: 0.0579 - val_loss: 0.0012 - val_mae: 0.0279\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0582\n",
      "Epoch 614: val_loss improved from 0.00123 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0086 - mae: 0.0582 - val_loss: 0.0012 - val_mae: 0.0279\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0085 - mae: 0.0578\n",
      "Epoch 615: val_loss improved from 0.00123 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0085 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0279\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0088 - mae: 0.0586\n",
      "Epoch 616: val_loss improved from 0.00123 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0088 - mae: 0.0586 - val_loss: 0.0012 - val_mae: 0.0278\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0586\n",
      "Epoch 617: val_loss improved from 0.00123 to 0.00122, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0087 - mae: 0.0586 - val_loss: 0.0012 - val_mae: 0.0278\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0580\n",
      "Epoch 618: val_loss improved from 0.00122 to 0.00122, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0085 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0277\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0083 - mae: 0.0575\n",
      "Epoch 619: val_loss improved from 0.00122 to 0.00122, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0083 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0277\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0582\n",
      "Epoch 620: val_loss improved from 0.00122 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0086 - mae: 0.0582 - val_loss: 0.0012 - val_mae: 0.0277\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0086 - mae: 0.0583\n",
      "Epoch 621: val_loss improved from 0.00121 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0086 - mae: 0.0583 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0084 - mae: 0.0577\n",
      "Epoch 622: val_loss improved from 0.00121 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0084 - mae: 0.0577 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0585\n",
      "Epoch 623: val_loss improved from 0.00121 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0087 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0276\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0584\n",
      "Epoch 624: val_loss improved from 0.00120 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0086 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0275\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0579\n",
      "Epoch 625: val_loss improved from 0.00120 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0085 - mae: 0.0579 - val_loss: 0.0012 - val_mae: 0.0275\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0084 - mae: 0.0578\n",
      "Epoch 626: val_loss improved from 0.00120 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0084 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0275\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0085 - mae: 0.0579\n",
      "Epoch 627: val_loss improved from 0.00120 to 0.00119, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0085 - mae: 0.0579 - val_loss: 0.0012 - val_mae: 0.0274\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0086 - mae: 0.0580\n",
      "Epoch 628: val_loss improved from 0.00119 to 0.00119, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0086 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0274\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0084 - mae: 0.0578\n",
      "Epoch 629: val_loss improved from 0.00119 to 0.00119, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0084 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0274\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0083 - mae: 0.0571\n",
      "Epoch 630: val_loss improved from 0.00119 to 0.00118, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0083 - mae: 0.0571 - val_loss: 0.0012 - val_mae: 0.0273\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 631: val_loss improved from 0.00118 to 0.00118, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0012 - val_mae: 0.0273\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0085 - mae: 0.0578\n",
      "Epoch 632: val_loss improved from 0.00118 to 0.00118, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0085 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0273\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0083 - mae: 0.0574\n",
      "Epoch 633: val_loss improved from 0.00118 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0083 - mae: 0.0574 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0084 - mae: 0.0577\n",
      "Epoch 634: val_loss improved from 0.00117 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0084 - mae: 0.0577 - val_loss: 0.0012 - val_mae: 0.0272\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0083 - mae: 0.0574\n",
      "Epoch 635: val_loss improved from 0.00117 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0083 - mae: 0.0574 - val_loss: 0.0012 - val_mae: 0.0271\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0571\n",
      "Epoch 636: val_loss improved from 0.00117 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0082 - mae: 0.0571 - val_loss: 0.0012 - val_mae: 0.0271\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0083 - mae: 0.0574\n",
      "Epoch 637: val_loss improved from 0.00116 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0083 - mae: 0.0574 - val_loss: 0.0012 - val_mae: 0.0271\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0083 - mae: 0.0572\n",
      "Epoch 638: val_loss improved from 0.00116 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0083 - mae: 0.0572 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0575\n",
      "Epoch 639: val_loss improved from 0.00116 to 0.00115, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0083 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0270\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 640: val_loss improved from 0.00115 to 0.00115, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0269\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0083 - mae: 0.0575\n",
      "Epoch 641: val_loss improved from 0.00115 to 0.00115, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0083 - mae: 0.0575 - val_loss: 0.0011 - val_mae: 0.0269\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 642: val_loss improved from 0.00115 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0268\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0571\n",
      "Epoch 643: val_loss improved from 0.00114 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0082 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0268\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0081 - mae: 0.0570\n",
      "Epoch 644: val_loss improved from 0.00114 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0081 - mae: 0.0570 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 645: val_loss improved from 0.00113 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0267\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0572\n",
      "Epoch 646: val_loss improved from 0.00113 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0082 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0082 - mae: 0.0570\n",
      "Epoch 647: val_loss improved from 0.00113 to 0.00112, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0082 - mae: 0.0570 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0081 - mae: 0.0569\n",
      "Epoch 648: val_loss improved from 0.00112 to 0.00112, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0081 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0081 - mae: 0.0571\n",
      "Epoch 649: val_loss improved from 0.00112 to 0.00112, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0081 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0266\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0081 - mae: 0.0571\n",
      "Epoch 650: val_loss improved from 0.00112 to 0.00111, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0081 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0570\n",
      "Epoch 651: val_loss improved from 0.00111 to 0.00111, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0081 - mae: 0.0570 - val_loss: 0.0011 - val_mae: 0.0265\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0571\n",
      "Epoch 652: val_loss improved from 0.00111 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0082 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0264\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0081 - mae: 0.0568\n",
      "Epoch 653: val_loss improved from 0.00110 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0081 - mae: 0.0568 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - mae: 0.0568\n",
      "Epoch 654: val_loss improved from 0.00110 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0080 - mae: 0.0568 - val_loss: 0.0011 - val_mae: 0.0263\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - mae: 0.0567\n",
      "Epoch 655: val_loss improved from 0.00110 to 0.00109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0080 - mae: 0.0567 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - mae: 0.0566\n",
      "Epoch 656: val_loss improved from 0.00109 to 0.00109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0080 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0082 - mae: 0.0569\n",
      "Epoch 657: val_loss improved from 0.00109 to 0.00108, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0082 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0262\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0565\n",
      "Epoch 658: val_loss improved from 0.00108 to 0.00108, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0079 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0564\n",
      "Epoch 659: val_loss improved from 0.00108 to 0.00108, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0079 - mae: 0.0564 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0563\n",
      "Epoch 660: val_loss improved from 0.00108 to 0.00107, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0079 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0261\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - mae: 0.0563\n",
      "Epoch 661: val_loss improved from 0.00107 to 0.00107, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0079 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0260\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0564\n",
      "Epoch 662: val_loss improved from 0.00107 to 0.00107, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0079 - mae: 0.0564 - val_loss: 0.0011 - val_mae: 0.0260\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0080 - mae: 0.0563\n",
      "Epoch 663: val_loss improved from 0.00107 to 0.00106, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0080 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0080 - mae: 0.0564\n",
      "Epoch 664: val_loss improved from 0.00106 to 0.00106, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0080 - mae: 0.0564 - val_loss: 0.0011 - val_mae: 0.0259\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0563\n",
      "Epoch 665: val_loss improved from 0.00106 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0078 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0258\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0078 - mae: 0.0562\n",
      "Epoch 666: val_loss improved from 0.00105 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0078 - mae: 0.0562 - val_loss: 0.0010 - val_mae: 0.0257\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0565\n",
      "Epoch 667: val_loss improved from 0.00105 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0079 - mae: 0.0565 - val_loss: 0.0010 - val_mae: 0.0257\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0568\n",
      "Epoch 668: val_loss improved from 0.00105 to 0.00104, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0080 - mae: 0.0568 - val_loss: 0.0010 - val_mae: 0.0256\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0566\n",
      "Epoch 669: val_loss improved from 0.00104 to 0.00104, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0079 - mae: 0.0566 - val_loss: 0.0010 - val_mae: 0.0256\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0079 - mae: 0.0565\n",
      "Epoch 670: val_loss improved from 0.00104 to 0.00103, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0079 - mae: 0.0565 - val_loss: 0.0010 - val_mae: 0.0255\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0078 - mae: 0.0562\n",
      "Epoch 671: val_loss improved from 0.00103 to 0.00103, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0078 - mae: 0.0562 - val_loss: 0.0010 - val_mae: 0.0255\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mae: 0.0562\n",
      "Epoch 672: val_loss improved from 0.00103 to 0.00102, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0078 - mae: 0.0562 - val_loss: 0.0010 - val_mae: 0.0255\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0078 - mae: 0.0561\n",
      "Epoch 673: val_loss improved from 0.00102 to 0.00102, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0078 - mae: 0.0561 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0559\n",
      "Epoch 674: val_loss improved from 0.00102 to 0.00102, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0078 - mae: 0.0559 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0554\n",
      "Epoch 675: val_loss improved from 0.00102 to 0.00101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0076 - mae: 0.0554 - val_loss: 0.0010 - val_mae: 0.0254\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0556\n",
      "Epoch 676: val_loss improved from 0.00101 to 0.00101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0077 - mae: 0.0556 - val_loss: 0.0010 - val_mae: 0.0253\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0553\n",
      "Epoch 677: val_loss improved from 0.00101 to 0.00100, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0076 - mae: 0.0553 - val_loss: 0.0010 - val_mae: 0.0252\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0558\n",
      "Epoch 678: val_loss improved from 0.00100 to 0.00100, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0078 - mae: 0.0558 - val_loss: 9.9984e-04 - val_mae: 0.0252\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0078 - mae: 0.0559\n",
      "Epoch 679: val_loss improved from 0.00100 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0078 - mae: 0.0559 - val_loss: 9.9479e-04 - val_mae: 0.0251\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0077 - mae: 0.0559\n",
      "Epoch 680: val_loss improved from 0.00099 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0077 - mae: 0.0559 - val_loss: 9.8999e-04 - val_mae: 0.0250\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0558\n",
      "Epoch 681: val_loss improved from 0.00099 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0077 - mae: 0.0558 - val_loss: 9.8555e-04 - val_mae: 0.0249\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0563\n",
      "Epoch 682: val_loss improved from 0.00099 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0077 - mae: 0.0563 - val_loss: 9.8117e-04 - val_mae: 0.0249\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0563\n",
      "Epoch 683: val_loss improved from 0.00098 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0078 - mae: 0.0563 - val_loss: 9.7687e-04 - val_mae: 0.0248\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0559\n",
      "Epoch 684: val_loss improved from 0.00098 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0076 - mae: 0.0559 - val_loss: 9.7277e-04 - val_mae: 0.0248\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0078 - mae: 0.0560\n",
      "Epoch 685: val_loss improved from 0.00097 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0078 - mae: 0.0560 - val_loss: 9.6886e-04 - val_mae: 0.0248\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076 - mae: 0.0556\n",
      "Epoch 686: val_loss improved from 0.00097 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0076 - mae: 0.0556 - val_loss: 9.6526e-04 - val_mae: 0.0247\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0556\n",
      "Epoch 687: val_loss improved from 0.00097 to 0.00096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0077 - mae: 0.0556 - val_loss: 9.6144e-04 - val_mae: 0.0247\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077 - mae: 0.0559\n",
      "Epoch 688: val_loss improved from 0.00096 to 0.00096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0077 - mae: 0.0559 - val_loss: 9.5711e-04 - val_mae: 0.0246\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0553\n",
      "Epoch 689: val_loss improved from 0.00096 to 0.00095, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0075 - mae: 0.0553 - val_loss: 9.5280e-04 - val_mae: 0.0246\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - mae: 0.0553\n",
      "Epoch 690: val_loss improved from 0.00095 to 0.00095, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0075 - mae: 0.0553 - val_loss: 9.4846e-04 - val_mae: 0.0245\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0553\n",
      "Epoch 691: val_loss improved from 0.00095 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0075 - mae: 0.0553 - val_loss: 9.4407e-04 - val_mae: 0.0245\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0549\n",
      "Epoch 692: val_loss improved from 0.00094 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - loss: 0.0074 - mae: 0.0549 - val_loss: 9.4004e-04 - val_mae: 0.0244\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0554\n",
      "Epoch 693: val_loss improved from 0.00094 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0077 - mae: 0.0554 - val_loss: 9.3562e-04 - val_mae: 0.0244\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - mae: 0.0553\n",
      "Epoch 694: val_loss improved from 0.00094 to 0.00093, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0075 - mae: 0.0553 - val_loss: 9.3099e-04 - val_mae: 0.0243\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0552\n",
      "Epoch 695: val_loss improved from 0.00093 to 0.00093, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0074 - mae: 0.0552 - val_loss: 9.2649e-04 - val_mae: 0.0242\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0550\n",
      "Epoch 696: val_loss improved from 0.00093 to 0.00092, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0074 - mae: 0.0550 - val_loss: 9.2228e-04 - val_mae: 0.0242\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0553\n",
      "Epoch 697: val_loss improved from 0.00092 to 0.00092, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0075 - mae: 0.0553 - val_loss: 9.1814e-04 - val_mae: 0.0241\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0555\n",
      "Epoch 698: val_loss improved from 0.00092 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0076 - mae: 0.0555 - val_loss: 9.1380e-04 - val_mae: 0.0241\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0075 - mae: 0.0551\n",
      "Epoch 699: val_loss improved from 0.00091 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0075 - mae: 0.0551 - val_loss: 9.0970e-04 - val_mae: 0.0240\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0551\n",
      "Epoch 700: val_loss improved from 0.00091 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0075 - mae: 0.0551 - val_loss: 9.0615e-04 - val_mae: 0.0240\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - mae: 0.0551\n",
      "Epoch 701: val_loss improved from 0.00091 to 0.00090, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0075 - mae: 0.0551 - val_loss: 9.0234e-04 - val_mae: 0.0239\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0552\n",
      "Epoch 702: val_loss improved from 0.00090 to 0.00090, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0076 - mae: 0.0552 - val_loss: 8.9803e-04 - val_mae: 0.0239\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0554\n",
      "Epoch 703: val_loss improved from 0.00090 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0076 - mae: 0.0554 - val_loss: 8.9327e-04 - val_mae: 0.0238\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0552\n",
      "Epoch 704: val_loss improved from 0.00089 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0075 - mae: 0.0552 - val_loss: 8.8865e-04 - val_mae: 0.0237\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0076 - mae: 0.0556\n",
      "Epoch 705: val_loss improved from 0.00089 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0076 - mae: 0.0556 - val_loss: 8.8410e-04 - val_mae: 0.0236\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0554\n",
      "Epoch 706: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0075 - mae: 0.0554 - val_loss: 8.7989e-04 - val_mae: 0.0236\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0075 - mae: 0.0554\n",
      "Epoch 707: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0075 - mae: 0.0554 - val_loss: 8.7599e-04 - val_mae: 0.0235\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - mae: 0.0552\n",
      "Epoch 708: val_loss improved from 0.00088 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0074 - mae: 0.0552 - val_loss: 8.7264e-04 - val_mae: 0.0235\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0554\n",
      "Epoch 709: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0076 - mae: 0.0554 - val_loss: 8.6965e-04 - val_mae: 0.0235\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0548\n",
      "Epoch 710: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0074 - mae: 0.0548 - val_loss: 8.6691e-04 - val_mae: 0.0235\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0073 - mae: 0.0542\n",
      "Epoch 711: val_loss improved from 0.00087 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0073 - mae: 0.0542 - val_loss: 8.6466e-04 - val_mae: 0.0235\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0546\n",
      "Epoch 712: val_loss improved from 0.00086 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0074 - mae: 0.0546 - val_loss: 8.6049e-04 - val_mae: 0.0234\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - mae: 0.0544\n",
      "Epoch 713: val_loss improved from 0.00086 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0074 - mae: 0.0544 - val_loss: 8.5553e-04 - val_mae: 0.0233\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0073 - mae: 0.0544\n",
      "Epoch 714: val_loss improved from 0.00086 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0073 - mae: 0.0544 - val_loss: 8.5054e-04 - val_mae: 0.0233\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0549\n",
      "Epoch 715: val_loss improved from 0.00085 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0074 - mae: 0.0549 - val_loss: 8.4541e-04 - val_mae: 0.0232\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0547\n",
      "Epoch 716: val_loss improved from 0.00085 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 8.4095e-04 - val_mae: 0.0231\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0544\n",
      "Epoch 717: val_loss improved from 0.00084 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0073 - mae: 0.0544 - val_loss: 8.3729e-04 - val_mae: 0.0230\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0072 - mae: 0.0542\n",
      "Epoch 718: val_loss improved from 0.00084 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0072 - mae: 0.0542 - val_loss: 8.3486e-04 - val_mae: 0.0230\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0546\n",
      "Epoch 719: val_loss improved from 0.00083 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0074 - mae: 0.0546 - val_loss: 8.3233e-04 - val_mae: 0.0230\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0540\n",
      "Epoch 720: val_loss improved from 0.00083 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0074 - mae: 0.0540 - val_loss: 8.2913e-04 - val_mae: 0.0230\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0538\n",
      "Epoch 721: val_loss improved from 0.00083 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0072 - mae: 0.0538 - val_loss: 8.2519e-04 - val_mae: 0.0229\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0541\n",
      "Epoch 722: val_loss improved from 0.00083 to 0.00082, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0073 - mae: 0.0541 - val_loss: 8.1978e-04 - val_mae: 0.0228\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0542\n",
      "Epoch 723: val_loss improved from 0.00082 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0073 - mae: 0.0542 - val_loss: 8.1431e-04 - val_mae: 0.0227\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0542\n",
      "Epoch 724: val_loss improved from 0.00081 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0072 - mae: 0.0542 - val_loss: 8.0944e-04 - val_mae: 0.0227\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0545\n",
      "Epoch 725: val_loss improved from 0.00081 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0073 - mae: 0.0545 - val_loss: 8.0511e-04 - val_mae: 0.0226\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0544\n",
      "Epoch 726: val_loss improved from 0.00081 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0072 - mae: 0.0544 - val_loss: 8.0137e-04 - val_mae: 0.0225\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0540\n",
      "Epoch 727: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 129ms/step - loss: 0.0071 - mae: 0.0540 - val_loss: 7.9891e-04 - val_mae: 0.0225\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - mae: 0.0543\n",
      "Epoch 728: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0072 - mae: 0.0543 - val_loss: 7.9652e-04 - val_mae: 0.0225\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0073 - mae: 0.0541\n",
      "Epoch 729: val_loss improved from 0.00080 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0073 - mae: 0.0541 - val_loss: 7.9376e-04 - val_mae: 0.0225\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0542\n",
      "Epoch 730: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0074 - mae: 0.0542 - val_loss: 7.8950e-04 - val_mae: 0.0224\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0536\n",
      "Epoch 731: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0071 - mae: 0.0536 - val_loss: 7.8521e-04 - val_mae: 0.0223\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - mae: 0.0540\n",
      "Epoch 732: val_loss improved from 0.00079 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0072 - mae: 0.0540 - val_loss: 7.8147e-04 - val_mae: 0.0223\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 733: val_loss improved from 0.00078 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 7.7880e-04 - val_mae: 0.0222\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0540\n",
      "Epoch 734: val_loss improved from 0.00078 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0073 - mae: 0.0540 - val_loss: 7.7564e-04 - val_mae: 0.0222\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0536\n",
      "Epoch 735: val_loss improved from 0.00078 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0071 - mae: 0.0536 - val_loss: 7.7273e-04 - val_mae: 0.0222\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0538\n",
      "Epoch 736: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0072 - mae: 0.0538 - val_loss: 7.6921e-04 - val_mae: 0.0221\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0540\n",
      "Epoch 737: val_loss improved from 0.00077 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0073 - mae: 0.0540 - val_loss: 7.6489e-04 - val_mae: 0.0220\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0542\n",
      "Epoch 738: val_loss improved from 0.00076 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0073 - mae: 0.0542 - val_loss: 7.6020e-04 - val_mae: 0.0219\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0541\n",
      "Epoch 739: val_loss improved from 0.00076 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0071 - mae: 0.0541 - val_loss: 7.5664e-04 - val_mae: 0.0219\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0542\n",
      "Epoch 740: val_loss improved from 0.00076 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0072 - mae: 0.0542 - val_loss: 7.5394e-04 - val_mae: 0.0219\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0541\n",
      "Epoch 741: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0071 - mae: 0.0541 - val_loss: 7.5251e-04 - val_mae: 0.0219\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0537\n",
      "Epoch 742: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0070 - mae: 0.0537 - val_loss: 7.5131e-04 - val_mae: 0.0219\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0534\n",
      "Epoch 743: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 7.4993e-04 - val_mae: 0.0219\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0533\n",
      "Epoch 744: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0071 - mae: 0.0533 - val_loss: 7.4704e-04 - val_mae: 0.0218\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0534\n",
      "Epoch 745: val_loss improved from 0.00075 to 0.00074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 7.4246e-04 - val_mae: 0.0217\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0539\n",
      "Epoch 746: val_loss improved from 0.00074 to 0.00074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0073 - mae: 0.0539 - val_loss: 7.3700e-04 - val_mae: 0.0216\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0533\n",
      "Epoch 747: val_loss improved from 0.00074 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0069 - mae: 0.0533 - val_loss: 7.3391e-04 - val_mae: 0.0216\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0535\n",
      "Epoch 748: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0071 - mae: 0.0535 - val_loss: 7.3195e-04 - val_mae: 0.0215\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0536\n",
      "Epoch 749: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0071 - mae: 0.0536 - val_loss: 7.3113e-04 - val_mae: 0.0216\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0531\n",
      "Epoch 750: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0070 - mae: 0.0531 - val_loss: 7.3028e-04 - val_mae: 0.0216\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0530\n",
      "Epoch 751: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0070 - mae: 0.0530 - val_loss: 7.2812e-04 - val_mae: 0.0215\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0531\n",
      "Epoch 752: val_loss improved from 0.00073 to 0.00072, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 7.2316e-04 - val_mae: 0.0214\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0072 - mae: 0.0533\n",
      "Epoch 753: val_loss improved from 0.00072 to 0.00072, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0072 - mae: 0.0533 - val_loss: 7.1811e-04 - val_mae: 0.0213\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0534\n",
      "Epoch 754: val_loss improved from 0.00072 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 7.1423e-04 - val_mae: 0.0213\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0070 - mae: 0.0534\n",
      "Epoch 755: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 7.1202e-04 - val_mae: 0.0212\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 756: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 7.1025e-04 - val_mae: 0.0212\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0532\n",
      "Epoch 757: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0070 - mae: 0.0532 - val_loss: 7.0963e-04 - val_mae: 0.0212\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0536\n",
      "Epoch 758: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0071 - mae: 0.0536 - val_loss: 7.0677e-04 - val_mae: 0.0212\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0535\n",
      "Epoch 759: val_loss improved from 0.00071 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0071 - mae: 0.0535 - val_loss: 7.0298e-04 - val_mae: 0.0211\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0536\n",
      "Epoch 760: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0071 - mae: 0.0536 - val_loss: 6.9970e-04 - val_mae: 0.0210\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0533\n",
      "Epoch 761: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0070 - mae: 0.0533 - val_loss: 6.9736e-04 - val_mae: 0.0210\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0538\n",
      "Epoch 762: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0071 - mae: 0.0538 - val_loss: 6.9522e-04 - val_mae: 0.0210\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 763: val_loss improved from 0.00070 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 6.9378e-04 - val_mae: 0.0210\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0070 - mae: 0.0531\n",
      "Epoch 764: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0070 - mae: 0.0531 - val_loss: 6.9372e-04 - val_mae: 0.0210\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0526\n",
      "Epoch 765: val_loss did not improve from 0.00069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0069 - mae: 0.0526 - val_loss: 6.9411e-04 - val_mae: 0.0210\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0525\n",
      "Epoch 766: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0069 - mae: 0.0525 - val_loss: 6.9277e-04 - val_mae: 0.0210\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0527\n",
      "Epoch 767: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0070 - mae: 0.0527 - val_loss: 6.8751e-04 - val_mae: 0.0209\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0534\n",
      "Epoch 768: val_loss improved from 0.00069 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 6.8073e-04 - val_mae: 0.0207\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0539\n",
      "Epoch 769: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0071 - mae: 0.0539 - val_loss: 6.7686e-04 - val_mae: 0.0206\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0068 - mae: 0.0535\n",
      "Epoch 770: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0068 - mae: 0.0535 - val_loss: 6.7535e-04 - val_mae: 0.0206\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0069 - mae: 0.0537\n",
      "Epoch 771: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0069 - mae: 0.0537 - val_loss: 6.7658e-04 - val_mae: 0.0207\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0532\n",
      "Epoch 772: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0070 - mae: 0.0532 - val_loss: 6.8007e-04 - val_mae: 0.0208\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0521\n",
      "Epoch 773: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0068 - mae: 0.0521 - val_loss: 6.8274e-04 - val_mae: 0.0208\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0528\n",
      "Epoch 774: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0071 - mae: 0.0528 - val_loss: 6.7593e-04 - val_mae: 0.0207\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0528\n",
      "Epoch 775: val_loss improved from 0.00068 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0071 - mae: 0.0528 - val_loss: 6.6767e-04 - val_mae: 0.0205\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0538\n",
      "Epoch 776: val_loss improved from 0.00067 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0071 - mae: 0.0538 - val_loss: 6.6273e-04 - val_mae: 0.0204\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0537\n",
      "Epoch 777: val_loss improved from 0.00066 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0069 - mae: 0.0537 - val_loss: 6.6087e-04 - val_mae: 0.0204\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0069 - mae: 0.0536\n",
      "Epoch 778: val_loss did not improve from 0.00066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0069 - mae: 0.0536 - val_loss: 6.6151e-04 - val_mae: 0.0204\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0538\n",
      "Epoch 779: val_loss did not improve from 0.00066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0071 - mae: 0.0538 - val_loss: 6.6453e-04 - val_mae: 0.0205\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0529\n",
      "Epoch 780: val_loss did not improve from 0.00066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0070 - mae: 0.0529 - val_loss: 6.6671e-04 - val_mae: 0.0205\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0526\n",
      "Epoch 781: val_loss did not improve from 0.00066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0070 - mae: 0.0526 - val_loss: 6.6444e-04 - val_mae: 0.0205\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0527\n",
      "Epoch 782: val_loss improved from 0.00066 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0071 - mae: 0.0527 - val_loss: 6.5875e-04 - val_mae: 0.0204\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0529\n",
      "Epoch 783: val_loss improved from 0.00066 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0070 - mae: 0.0529 - val_loss: 6.5350e-04 - val_mae: 0.0203\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0531\n",
      "Epoch 784: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 6.5114e-04 - val_mae: 0.0202\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 785: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 6.5148e-04 - val_mae: 0.0202\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0534\n",
      "Epoch 786: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 6.5182e-04 - val_mae: 0.0202\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0528\n",
      "Epoch 787: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 6.5207e-04 - val_mae: 0.0203\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0526\n",
      "Epoch 788: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0069 - mae: 0.0526 - val_loss: 6.5128e-04 - val_mae: 0.0202\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0528\n",
      "Epoch 789: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0070 - mae: 0.0528 - val_loss: 6.4790e-04 - val_mae: 0.0202\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0525\n",
      "Epoch 790: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0068 - mae: 0.0525 - val_loss: 6.4540e-04 - val_mae: 0.0201\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0529\n",
      "Epoch 791: val_loss improved from 0.00065 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0070 - mae: 0.0529 - val_loss: 6.4323e-04 - val_mae: 0.0201\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0070 - mae: 0.0533\n",
      "Epoch 792: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0070 - mae: 0.0533 - val_loss: 6.4062e-04 - val_mae: 0.0200\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 793: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 6.3814e-04 - val_mae: 0.0200\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0534\n",
      "Epoch 794: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0069 - mae: 0.0534 - val_loss: 6.3729e-04 - val_mae: 0.0200\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 795: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 6.3702e-04 - val_mae: 0.0200\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0533\n",
      "Epoch 796: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0070 - mae: 0.0533 - val_loss: 6.3670e-04 - val_mae: 0.0200\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0529\n",
      "Epoch 797: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0069 - mae: 0.0529 - val_loss: 6.3562e-04 - val_mae: 0.0200\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0069 - mae: 0.0528\n",
      "Epoch 798: val_loss improved from 0.00064 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 6.3388e-04 - val_mae: 0.0199\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0069 - mae: 0.0527\n",
      "Epoch 799: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0069 - mae: 0.0527 - val_loss: 6.3337e-04 - val_mae: 0.0199\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0528\n",
      "Epoch 800: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 6.3155e-04 - val_mae: 0.0199\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0523\n",
      "Epoch 801: val_loss did not improve from 0.00063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0068 - mae: 0.0523 - val_loss: 6.3191e-04 - val_mae: 0.0199\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0525\n",
      "Epoch 802: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0069 - mae: 0.0525 - val_loss: 6.3147e-04 - val_mae: 0.0199\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0068 - mae: 0.0524\n",
      "Epoch 803: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 6.3027e-04 - val_mae: 0.0199\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0524\n",
      "Epoch 804: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - loss: 0.0069 - mae: 0.0524 - val_loss: 6.2807e-04 - val_mae: 0.0198\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0521\n",
      "Epoch 805: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 6.2752e-04 - val_mae: 0.0198\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0530\n",
      "Epoch 806: val_loss improved from 0.00063 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - loss: 0.0069 - mae: 0.0530 - val_loss: 6.2424e-04 - val_mae: 0.0197\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0525\n",
      "Epoch 807: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0068 - mae: 0.0525 - val_loss: 6.2281e-04 - val_mae: 0.0197\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0523\n",
      "Epoch 808: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 6.2412e-04 - val_mae: 0.0197\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0524\n",
      "Epoch 809: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 6.2484e-04 - val_mae: 0.0198\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0069 - mae: 0.0523\n",
      "Epoch 810: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0069 - mae: 0.0523 - val_loss: 6.2312e-04 - val_mae: 0.0197\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0522\n",
      "Epoch 811: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0068 - mae: 0.0522 - val_loss: 6.1963e-04 - val_mae: 0.0197\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0527\n",
      "Epoch 812: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0069 - mae: 0.0527 - val_loss: 6.1607e-04 - val_mae: 0.0196\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0534\n",
      "Epoch 813: val_loss improved from 0.00062 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0069 - mae: 0.0534 - val_loss: 6.1287e-04 - val_mae: 0.0195\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0532\n",
      "Epoch 814: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0068 - mae: 0.0532 - val_loss: 6.1246e-04 - val_mae: 0.0195\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0530\n",
      "Epoch 815: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0068 - mae: 0.0530 - val_loss: 6.1488e-04 - val_mae: 0.0196\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0523\n",
      "Epoch 816: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 6.2035e-04 - val_mae: 0.0197\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0517\n",
      "Epoch 817: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0067 - mae: 0.0517 - val_loss: 6.2136e-04 - val_mae: 0.0197\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0514\n",
      "Epoch 818: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0514 - val_loss: 6.1814e-04 - val_mae: 0.0196\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0520\n",
      "Epoch 819: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0068 - mae: 0.0520 - val_loss: 6.1138e-04 - val_mae: 0.0195\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 820: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 6.0656e-04 - val_mae: 0.0194\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mae: 0.0530\n",
      "Epoch 821: val_loss improved from 0.00061 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0069 - mae: 0.0530 - val_loss: 6.0454e-04 - val_mae: 0.0194\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0531\n",
      "Epoch 822: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0068 - mae: 0.0531 - val_loss: 6.0439e-04 - val_mae: 0.0194\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 823: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 6.0772e-04 - val_mae: 0.0194\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0524\n",
      "Epoch 824: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 6.1171e-04 - val_mae: 0.0195\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0518\n",
      "Epoch 825: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0068 - mae: 0.0518 - val_loss: 6.1098e-04 - val_mae: 0.0195\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0068 - mae: 0.0520\n",
      "Epoch 826: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0068 - mae: 0.0520 - val_loss: 6.0441e-04 - val_mae: 0.0194\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 827: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 5.9758e-04 - val_mae: 0.0193\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0529\n",
      "Epoch 828: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0067 - mae: 0.0529 - val_loss: 5.9535e-04 - val_mae: 0.0192\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0068 - mae: 0.0534\n",
      "Epoch 829: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0068 - mae: 0.0534 - val_loss: 5.9613e-04 - val_mae: 0.0192\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 830: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 6.0033e-04 - val_mae: 0.0193\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0522\n",
      "Epoch 831: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0068 - mae: 0.0522 - val_loss: 6.0509e-04 - val_mae: 0.0194\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mae: 0.0515\n",
      "Epoch 832: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0066 - mae: 0.0515 - val_loss: 6.0558e-04 - val_mae: 0.0194\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0518\n",
      "Epoch 833: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0068 - mae: 0.0518 - val_loss: 5.9876e-04 - val_mae: 0.0193\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0525\n",
      "Epoch 834: val_loss improved from 0.00060 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0069 - mae: 0.0525 - val_loss: 5.9167e-04 - val_mae: 0.0191\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0531\n",
      "Epoch 835: val_loss improved from 0.00059 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0068 - mae: 0.0531 - val_loss: 5.8904e-04 - val_mae: 0.0191\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0531\n",
      "Epoch 836: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0067 - mae: 0.0531 - val_loss: 5.9024e-04 - val_mae: 0.0191\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 837: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 5.9558e-04 - val_mae: 0.0192\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0068 - mae: 0.0524\n",
      "Epoch 838: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 5.9898e-04 - val_mae: 0.0193\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0518\n",
      "Epoch 839: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0067 - mae: 0.0518 - val_loss: 5.9724e-04 - val_mae: 0.0192\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0068 - mae: 0.0518\n",
      "Epoch 840: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0068 - mae: 0.0518 - val_loss: 5.9088e-04 - val_mae: 0.0191\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0528\n",
      "Epoch 841: val_loss improved from 0.00059 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 5.8448e-04 - val_mae: 0.0190\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0532\n",
      "Epoch 842: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0068 - mae: 0.0532 - val_loss: 5.8198e-04 - val_mae: 0.0190\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0532\n",
      "Epoch 843: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0068 - mae: 0.0532 - val_loss: 5.8245e-04 - val_mae: 0.0190\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0530\n",
      "Epoch 844: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0068 - mae: 0.0530 - val_loss: 5.8549e-04 - val_mae: 0.0190\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0529\n",
      "Epoch 845: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0069 - mae: 0.0529 - val_loss: 5.8715e-04 - val_mae: 0.0190\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 846: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.8867e-04 - val_mae: 0.0191\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 847: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.8731e-04 - val_mae: 0.0190\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0521\n",
      "Epoch 848: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0068 - mae: 0.0521 - val_loss: 5.8229e-04 - val_mae: 0.0190\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0523\n",
      "Epoch 849: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0068 - mae: 0.0523 - val_loss: 5.7808e-04 - val_mae: 0.0189\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 850: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 5.7597e-04 - val_mae: 0.0189\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - mae: 0.0527\n",
      "Epoch 851: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0067 - mae: 0.0527 - val_loss: 5.7701e-04 - val_mae: 0.0189\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 852: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 5.8164e-04 - val_mae: 0.0189\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0519\n",
      "Epoch 853: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 5.8366e-04 - val_mae: 0.0190\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0515\n",
      "Epoch 854: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0066 - mae: 0.0515 - val_loss: 5.7980e-04 - val_mae: 0.0189\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 855: val_loss improved from 0.00058 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.7385e-04 - val_mae: 0.0188\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 856: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 5.7071e-04 - val_mae: 0.0187\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0527\n",
      "Epoch 857: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0068 - mae: 0.0527 - val_loss: 5.6855e-04 - val_mae: 0.0187\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - mae: 0.0526\n",
      "Epoch 858: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0067 - mae: 0.0526 - val_loss: 5.6912e-04 - val_mae: 0.0187\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0524\n",
      "Epoch 859: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0066 - mae: 0.0524 - val_loss: 5.7162e-04 - val_mae: 0.0188\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 860: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 5.7325e-04 - val_mae: 0.0188\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0521\n",
      "Epoch 861: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 5.7172e-04 - val_mae: 0.0188\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0521\n",
      "Epoch 862: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 5.6793e-04 - val_mae: 0.0187\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 863: val_loss improved from 0.00057 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.6500e-04 - val_mae: 0.0187\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0525\n",
      "Epoch 864: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0066 - mae: 0.0525 - val_loss: 5.6416e-04 - val_mae: 0.0186\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 865: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 5.6514e-04 - val_mae: 0.0186\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 866: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 5.6922e-04 - val_mae: 0.0187\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 867: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.7091e-04 - val_mae: 0.0187\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 868: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.6722e-04 - val_mae: 0.0187\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0517\n",
      "Epoch 869: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0066 - mae: 0.0517 - val_loss: 5.6259e-04 - val_mae: 0.0186\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0518\n",
      "Epoch 870: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0065 - mae: 0.0518 - val_loss: 5.6056e-04 - val_mae: 0.0186\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 871: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 5.5908e-04 - val_mae: 0.0185\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 872: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 5.6062e-04 - val_mae: 0.0186\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 873: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.6140e-04 - val_mae: 0.0186\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0521\n",
      "Epoch 874: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 5.5855e-04 - val_mae: 0.0185\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 875: val_loss improved from 0.00056 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.5426e-04 - val_mae: 0.0184\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 876: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.5144e-04 - val_mae: 0.0184\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0527\n",
      "Epoch 877: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 5.5051e-04 - val_mae: 0.0184\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 878: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 5.5036e-04 - val_mae: 0.0184\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 879: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.5187e-04 - val_mae: 0.0184\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 880: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.5481e-04 - val_mae: 0.0184\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0516\n",
      "Epoch 881: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0066 - mae: 0.0516 - val_loss: 5.5512e-04 - val_mae: 0.0184\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0519\n",
      "Epoch 882: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0068 - mae: 0.0519 - val_loss: 5.4961e-04 - val_mae: 0.0183\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 883: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.4519e-04 - val_mae: 0.0183\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 884: val_loss improved from 0.00055 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 5.4229e-04 - val_mae: 0.0182\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0528\n",
      "Epoch 885: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0066 - mae: 0.0528 - val_loss: 5.4265e-04 - val_mae: 0.0182\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0524\n",
      "Epoch 886: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0524 - val_loss: 5.4702e-04 - val_mae: 0.0183\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0515\n",
      "Epoch 887: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0065 - mae: 0.0515 - val_loss: 5.5270e-04 - val_mae: 0.0184\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0067 - mae: 0.0517\n",
      "Epoch 888: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0067 - mae: 0.0517 - val_loss: 5.4833e-04 - val_mae: 0.0183\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 889: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.4041e-04 - val_mae: 0.0182\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 890: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.3581e-04 - val_mae: 0.0181\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0528\n",
      "Epoch 891: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 123ms/step - loss: 0.0066 - mae: 0.0528 - val_loss: 5.3556e-04 - val_mae: 0.0181\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0527\n",
      "Epoch 892: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 5.3973e-04 - val_mae: 0.0182\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0521\n",
      "Epoch 893: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0065 - mae: 0.0521 - val_loss: 5.4573e-04 - val_mae: 0.0183\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0517\n",
      "Epoch 894: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0067 - mae: 0.0517 - val_loss: 5.4357e-04 - val_mae: 0.0182\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0520\n",
      "Epoch 895: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0067 - mae: 0.0520 - val_loss: 5.3546e-04 - val_mae: 0.0181\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 896: val_loss improved from 0.00054 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 5.3144e-04 - val_mae: 0.0180\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0526\n",
      "Epoch 897: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0066 - mae: 0.0526 - val_loss: 5.3094e-04 - val_mae: 0.0180\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 898: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 5.3608e-04 - val_mae: 0.0181\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0520\n",
      "Epoch 899: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0067 - mae: 0.0520 - val_loss: 5.3942e-04 - val_mae: 0.0181\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0515\n",
      "Epoch 900: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0067 - mae: 0.0515 - val_loss: 5.3555e-04 - val_mae: 0.0181\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0518\n",
      "Epoch 901: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0066 - mae: 0.0518 - val_loss: 5.2938e-04 - val_mae: 0.0180\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 902: val_loss improved from 0.00053 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 5.2441e-04 - val_mae: 0.0179\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0529\n",
      "Epoch 903: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0066 - mae: 0.0529 - val_loss: 5.2358e-04 - val_mae: 0.0179\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0530\n",
      "Epoch 904: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0067 - mae: 0.0530 - val_loss: 5.2578e-04 - val_mae: 0.0179\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 905: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.2987e-04 - val_mae: 0.0180\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0521\n",
      "Epoch 906: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0067 - mae: 0.0521 - val_loss: 5.2893e-04 - val_mae: 0.0180\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0519\n",
      "Epoch 907: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 5.2321e-04 - val_mae: 0.0179\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 908: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 5.1995e-04 - val_mae: 0.0178\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0525\n",
      "Epoch 909: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0065 - mae: 0.0525 - val_loss: 5.2100e-04 - val_mae: 0.0178\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 910: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.2244e-04 - val_mae: 0.0178\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0516\n",
      "Epoch 911: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0065 - mae: 0.0516 - val_loss: 5.2622e-04 - val_mae: 0.0179\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0517\n",
      "Epoch 912: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0067 - mae: 0.0517 - val_loss: 5.2429e-04 - val_mae: 0.0179\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0517\n",
      "Epoch 913: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0066 - mae: 0.0517 - val_loss: 5.1918e-04 - val_mae: 0.0178\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 914: val_loss improved from 0.00052 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 5.1449e-04 - val_mae: 0.0177\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0528\n",
      "Epoch 915: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0066 - mae: 0.0528 - val_loss: 5.1250e-04 - val_mae: 0.0177\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0529\n",
      "Epoch 916: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0066 - mae: 0.0529 - val_loss: 5.1400e-04 - val_mae: 0.0177\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0526\n",
      "Epoch 917: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0067 - mae: 0.0526 - val_loss: 5.1643e-04 - val_mae: 0.0177\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0519\n",
      "Epoch 918: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0065 - mae: 0.0519 - val_loss: 5.1913e-04 - val_mae: 0.0178\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0067 - mae: 0.0519\n",
      "Epoch 919: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 5.1438e-04 - val_mae: 0.0177\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 920: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.0941e-04 - val_mae: 0.0176\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0523\n",
      "Epoch 921: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 5.0800e-04 - val_mae: 0.0176\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 922: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.0947e-04 - val_mae: 0.0176\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 923: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.1158e-04 - val_mae: 0.0176\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0517\n",
      "Epoch 924: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 5.1252e-04 - val_mae: 0.0176\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0516\n",
      "Epoch 925: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0065 - mae: 0.0516 - val_loss: 5.1093e-04 - val_mae: 0.0176\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0513\n",
      "Epoch 926: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0065 - mae: 0.0513 - val_loss: 5.0921e-04 - val_mae: 0.0176\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 927: val_loss improved from 0.00051 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.0372e-04 - val_mae: 0.0175\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0519\n",
      "Epoch 928: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0065 - mae: 0.0519 - val_loss: 5.0144e-04 - val_mae: 0.0175\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0521\n",
      "Epoch 929: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0064 - mae: 0.0521 - val_loss: 5.0189e-04 - val_mae: 0.0175\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0065 - mae: 0.0518\n",
      "Epoch 930: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0065 - mae: 0.0518 - val_loss: 5.0407e-04 - val_mae: 0.0175\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0516\n",
      "Epoch 931: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0516 - val_loss: 5.0685e-04 - val_mae: 0.0175\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0065 - mae: 0.0511\n",
      "Epoch 932: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0065 - mae: 0.0511 - val_loss: 5.0589e-04 - val_mae: 0.0175\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0518\n",
      "Epoch 933: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0067 - mae: 0.0518 - val_loss: 4.9743e-04 - val_mae: 0.0174\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 934: val_loss improved from 0.00050 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 4.9345e-04 - val_mae: 0.0173\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0523\n",
      "Epoch 935: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0064 - mae: 0.0523 - val_loss: 4.9347e-04 - val_mae: 0.0173\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0518\n",
      "Epoch 936: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 5.0107e-04 - val_mae: 0.0174\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 937: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 5.0533e-04 - val_mae: 0.0175\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0509\n",
      "Epoch 938: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0064 - mae: 0.0509 - val_loss: 4.9968e-04 - val_mae: 0.0174\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 939: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 4.9165e-04 - val_mae: 0.0173\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 940: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 4.8786e-04 - val_mae: 0.0172\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0524\n",
      "Epoch 941: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0524 - val_loss: 4.8987e-04 - val_mae: 0.0172\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 942: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 4.9391e-04 - val_mae: 0.0173\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0514\n",
      "Epoch 943: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 4.9809e-04 - val_mae: 0.0173\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0512\n",
      "Epoch 944: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0065 - mae: 0.0512 - val_loss: 4.9475e-04 - val_mae: 0.0173\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0511\n",
      "Epoch 945: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0511 - val_loss: 4.8846e-04 - val_mae: 0.0172\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0519\n",
      "Epoch 946: val_loss improved from 0.00049 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0065 - mae: 0.0519 - val_loss: 4.8301e-04 - val_mae: 0.0171\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 947: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 4.8209e-04 - val_mae: 0.0171\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 948: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 4.8562e-04 - val_mae: 0.0171\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 949: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 4.9342e-04 - val_mae: 0.0172\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0510\n",
      "Epoch 950: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0065 - mae: 0.0510 - val_loss: 4.9195e-04 - val_mae: 0.0172\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0507\n",
      "Epoch 951: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0063 - mae: 0.0507 - val_loss: 4.8516e-04 - val_mae: 0.0171\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0516\n",
      "Epoch 952: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0065 - mae: 0.0516 - val_loss: 4.7843e-04 - val_mae: 0.0170\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 953: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 4.7617e-04 - val_mae: 0.0170\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0522\n",
      "Epoch 954: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0064 - mae: 0.0522 - val_loss: 4.7856e-04 - val_mae: 0.0170\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0064 - mae: 0.0517\n",
      "Epoch 955: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 4.8555e-04 - val_mae: 0.0171\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0508\n",
      "Epoch 956: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0064 - mae: 0.0508 - val_loss: 4.8945e-04 - val_mae: 0.0172\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0512\n",
      "Epoch 957: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0067 - mae: 0.0512 - val_loss: 4.7683e-04 - val_mae: 0.0170\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0514\n",
      "Epoch 958: val_loss improved from 0.00048 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 4.6975e-04 - val_mae: 0.0169\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0063 - mae: 0.0520\n",
      "Epoch 959: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0063 - mae: 0.0520 - val_loss: 4.7082e-04 - val_mae: 0.0169\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 960: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 4.7509e-04 - val_mae: 0.0169\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0513\n",
      "Epoch 961: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0064 - mae: 0.0513 - val_loss: 4.8143e-04 - val_mae: 0.0170\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0513\n",
      "Epoch 962: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0065 - mae: 0.0513 - val_loss: 4.7591e-04 - val_mae: 0.0169\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0065 - mae: 0.0513\n",
      "Epoch 963: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - loss: 0.0065 - mae: 0.0513 - val_loss: 4.6916e-04 - val_mae: 0.0168\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0515\n",
      "Epoch 964: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0063 - mae: 0.0515 - val_loss: 4.7002e-04 - val_mae: 0.0168\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0513\n",
      "Epoch 965: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0063 - mae: 0.0513 - val_loss: 4.7707e-04 - val_mae: 0.0169\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 966: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 4.7621e-04 - val_mae: 0.0169\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0508\n",
      "Epoch 967: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0508 - val_loss: 4.7157e-04 - val_mae: 0.0168\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 968: val_loss improved from 0.00047 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 4.6443e-04 - val_mae: 0.0167\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0519\n",
      "Epoch 969: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0064 - mae: 0.0519 - val_loss: 4.6288e-04 - val_mae: 0.0167\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0519\n",
      "Epoch 970: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0064 - mae: 0.0519 - val_loss: 4.6511e-04 - val_mae: 0.0167\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 971: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 4.6929e-04 - val_mae: 0.0168\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 972: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 4.7005e-04 - val_mae: 0.0168\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0065 - mae: 0.0512\n",
      "Epoch 973: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - loss: 0.0065 - mae: 0.0512 - val_loss: 4.6148e-04 - val_mae: 0.0167\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0063 - mae: 0.0514\n",
      "Epoch 974: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - loss: 0.0063 - mae: 0.0514 - val_loss: 4.5840e-04 - val_mae: 0.0166\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 975: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 4.5622e-04 - val_mae: 0.0166\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0518\n",
      "Epoch 976: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 4.5845e-04 - val_mae: 0.0166\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 977: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 4.5908e-04 - val_mae: 0.0166\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0515\n",
      "Epoch 978: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0064 - mae: 0.0515 - val_loss: 4.5902e-04 - val_mae: 0.0166\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0514\n",
      "Epoch 979: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 4.5931e-04 - val_mae: 0.0166\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 980: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 4.5836e-04 - val_mae: 0.0166\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0516\n",
      "Epoch 981: val_loss improved from 0.00046 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - loss: 0.0065 - mae: 0.0516 - val_loss: 4.5298e-04 - val_mae: 0.0165\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0518\n",
      "Epoch 982: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 4.5011e-04 - val_mae: 0.0165\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0064 - mae: 0.0520\n",
      "Epoch 983: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - loss: 0.0064 - mae: 0.0520 - val_loss: 4.5092e-04 - val_mae: 0.0165\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0065 - mae: 0.0519\n",
      "Epoch 984: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0065 - mae: 0.0519 - val_loss: 4.5304e-04 - val_mae: 0.0165\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 985: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 4.5178e-04 - val_mae: 0.0165\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0514\n",
      "Epoch 986: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 4.4980e-04 - val_mae: 0.0164\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0513\n",
      "Epoch 987: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0063 - mae: 0.0513 - val_loss: 4.5081e-04 - val_mae: 0.0164\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0517\n",
      "Epoch 988: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 125ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 4.4870e-04 - val_mae: 0.0164\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0517\n",
      "Epoch 989: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 4.4505e-04 - val_mae: 0.0163\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0518\n",
      "Epoch 990: val_loss improved from 0.00045 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 115ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 4.4485e-04 - val_mae: 0.0163\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0064 - mae: 0.0515\n",
      "Epoch 991: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0515 - val_loss: 4.4920e-04 - val_mae: 0.0164\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0510\n",
      "Epoch 992: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0510 - val_loss: 4.5104e-04 - val_mae: 0.0164\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0505\n",
      "Epoch 993: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0062 - mae: 0.0505 - val_loss: 4.4855e-04 - val_mae: 0.0164\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0506\n",
      "Epoch 994: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 116ms/step - loss: 0.0062 - mae: 0.0506 - val_loss: 4.4330e-04 - val_mae: 0.0163\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0512\n",
      "Epoch 995: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0063 - mae: 0.0512 - val_loss: 4.3909e-04 - val_mae: 0.0162\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0063 - mae: 0.0513\n",
      "Epoch 996: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0063 - mae: 0.0513 - val_loss: 4.4133e-04 - val_mae: 0.0162\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0517\n",
      "Epoch 997: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0065 - mae: 0.0517 - val_loss: 4.4022e-04 - val_mae: 0.0162\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0511\n",
      "Epoch 998: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0063 - mae: 0.0511 - val_loss: 4.4176e-04 - val_mae: 0.0162\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 999: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 4.3969e-04 - val_mae: 0.0162\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0509\n",
      "Epoch 1000: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0063 - mae: 0.0509 - val_loss: 4.3926e-04 - val_mae: 0.0162\n",
      "Restoring model weights from the end of the best epoch: 995.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_6\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_6\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,440</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m2,440\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,385</span> (28.85 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m7,385\u001b[0m (28.85 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,461</span> (9.61 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,461\u001b[0m (9.61 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,924</span> (19.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,924\u001b[0m (19.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "batch_size = len(X_train)\n",
    "val_batch_size = len(X_val)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose=1)\n",
    "\n",
    "file_name = 'nev_test.keras'\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "callbacks = [early_stopping, checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_batch_size=val_batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6272de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Loss:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 306ms/step - loss: 0.0014 - mae: 0.0304\n",
      "Loss: [0.0013901694910600781, 0.030365364626049995]\n",
      "\n",
      "Generating output predictions with model:\n",
      "WARNING:tensorflow:5 out of the last 2519 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x73689b257740> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 192ms/step\n",
      "\n",
      "Central Frequency Percentage 15cm: 99.99128713857183\n",
      "\n",
      "Central Frequency Percentage 5cm: 78.92234351078528\n",
      "\n",
      "Central Frequency Percentage 1cm: 21.26187127369587\n",
      "Mean Squared Error: 0.0013901694052775896\n",
      "Root Mean Squared Error: 0.03728497559711672\n",
      "Mean Absolute Error: 0.030365365031705043\n",
      "Median Absolute Error: 0.026439902305603002\n",
      "R-squared: 0.95084334623773\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1e6e9414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA+kAAAIjCAYAAAB/OVoZAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3Xd4FFXbwOHfZtNDCimQQiCh916kI72jqBQVsWAFkc/6ir4vYkNsqChYAQsqoCAgoICgVJEivYfee0J62fn+OJktyaaRzW4Snvu6cs3s1LM7u5t95pzzHIOmaRpCCCGEEEIIIYRwOTdXF0AIIYQQQgghhBCKBOlCCCGEEEIIIUQpIUG6EEIIIYQQQghRSkiQLoQQQgghhBBClBISpAshhBBCCCGEEKWEBOlCCCGEEEIIIUQpIUG6EEIIIYQQQghRSkiQLoQQQgghhBBClBISpAshhBBCCCGEEKWEBOlCiDLnlVdewWAwcOnSJVcXxekMBgOvvPKKq4vhcl26dKFLly7mx8eOHcNgMDBr1iyXlSmnnGUUpYujP0tvv/02devWxWQyFXofeY/cvEryu/zTTz+latWqpKWllcjxhRAlT4J0IUSpsGfPHu69916ioqLw8vIiMjKSe+65hz179ri6aCKHP//8E4PBYP7z8PCgevXq3HfffRw5csTVxSuSDRs28Morr3Dt2jWXnL9+/fo0adIk1/IFCxZgMBjo3LlzrnUzZszAYDCwfPnyQp9n7969vPLKKxw7dqw4xS2SWbNmYTAY2LJli9PO6SoJCQlMnjyZF154ATc3y08r68+J9V94eHiJlGPp0qVFCvz++ecfnnjiCVq0aIGHhwcGgyHf7b/66ivq1auHt7c3tWrVYurUqXa3O336NEOGDCEoKIiAgAAGDRqU53dDYY9pz65du7jzzjupVq0a3t7eREVF0aNHjyIdozy6//77SU9P57PPPnN1UYQQN0iCdCGEy82fP5/mzZvzxx9/8MADDzBt2jQeeughVq9eTfPmzVmwYIGriyjsGDt2LN9++y2ff/45/fr1Y86cObRq1YozZ844vSzVqlUjJSWFESNGFGm/DRs2MHHiRJcF6R06dGD37t3Ex8fbLF+/fj3u7u5s3ryZjIyMXOuMRiNt27Yt9Hn27t3LxIkTnRqk30xmzJhBZmYmw4cPz7WuR48efPvttzZ/n3zyCQDLly8v0s2WgixdupSJEycWafsvv/wSg8FA9erV8932s88+Y9SoUTRo0ICpU6fStm1bxo4dy+TJk222S0xM5NZbb+Wvv/5i/PjxTJw4kX///ZfOnTtz+fLlGzqmPRs2bKBly5bs2LGDhx9+mI8//phRo0bh5ubGhx9+WOjXoDzy9vZm5MiRvP/++2ia5uriCCFuhCaEEC50+PBhzdfXV6tbt6524cIFm3UXL17U6tatq/n5+WlxcXHm5RMmTNAA7eLFi84uro2srCwtJSXFqecEtAkTJjj1nDmtXr1aA7R58+bZLP/oo480QHvzzTfz3DcxMdEhZejcubPWuXPnYh/nnXfe0QDt6NGjxT5WToUp49dff60B2tKlS22W33LLLdrdd9+tAdrGjRtt1tWuXVtr1qxZkcoyb948DdBWr15dpP0Kkt/1nDlzpgZomzdvdug5HcWRn6XGjRtr9957r91zjB49uljHTklJ0bKysgq17ejRo7Wi/LQ7d+6clpycXOC+ycnJWkhIiNavXz+b5ffcc4/m5+enXblyxbxs8uTJGqD9888/5mX79u3TjEaj9uKLL97QMe3p27evFhYWpl29ejXXuvPnz+e7b2lQ0t/lW7Zs0QDtjz/+KLFzCCFKjtSkCyFc6p133iE5OZnPP/+csLAwm3WhoaF89tlnJCUl8fbbb+fa99KlSwwZMoSAgABCQkJ46qmnSE1NtdlmxYoVdOjQgaCgICpUqECdOnUYP368zTZpaWlMmDCBmjVr4uXlRXR0NM8//3yu/nwGg4ExY8Ywe/ZsGjRogJeXF4sXLyY4OJgHHnggV/kSEhLw9vbm2WefLfK50tLS+L//+z/CwsLw9/dn4MCBnDp1qsDX8/z587i7u9utTTtw4AAGg4GPP/4YgIyMDCZOnEitWrXw9vYmJCSEDh06sGLFigLPY0/Xrl0BOHr0KGDJHbB3717uvvtuKlasSIcOHczbf/fdd7Ro0QIfHx+Cg4MZNmwYJ0+ezHXczz//nBo1auDj40Pr1q1Zu3Ztrm3y6pO+f/9+hgwZQlhYGD4+PtSpU4eXXnrJXL7nnnsOgNjYWHNTZOvaZkeW0R799Vi/fr15WWpqKtu2bWPw4MFUr17dZt3Fixc5ePCgeb/jx4/zxBNPUKdOHXx8fAgJCeGuu+6yeQ6zZs3irrvuAuDWW281P88///zTvM2yZcvo2LEjfn5++Pv7069fv1xdTe6//34qVKhAXFwcffv2xd/fn3vuuadQzzM/p0+f5sEHH6Ry5cp4eXnRoEEDZsyYYV5flPc0wLVr1xg3bhzR0dF4eXlRs2ZNJk+eXGBf8evXrzNu3DhiYmLw8vKiUqVK9OjRg23btuW739GjR9m5cyfdu3cv4jPP3Sdd70ry448/8vLLLxMVFYWvry8JCQkFfl7vv/9+cw29ddP6/FSuXBkfH58Cy7l69WouX77ME088YbN89OjRJCUlsWTJEvOyn376iVatWtGqVSvzsrp169KtWzfmzp17Q8e0Jy4ujgYNGhAUFJRrXaVKlWwez5w5k65du1KpUiW8vLyoX78+06dPz7VfTEwM/fv3588//6Rly5b4+PjQqFEj82dl/vz5NGrUCG9vb1q0aMG///5rs7/+GTly5Ai9evXCz8+PyMhIXn311ULVaBf0WdBNnTqVBg0a4OvrS8WKFWnZsiXff/+9zTYtWrQgODiYhQsXFnheIUTp4+7qAgghbm6LFy8mJiaGjh072l3fqVMnYmJi7P5gGzJkCDExMUyaNIm///6bjz76iKtXr/LNN98Aqp97//79ady4Ma+++ipeXl4cPnzYJugxmUwMHDiQdevW8cgjj1CvXj127drFlClTOHjwIL/88ovNOVetWsXcuXMZM2YMoaGh1KpVi9tvv5358+fz2Wef4enpad72l19+IS0tjWHDhhX5XKNGjeK7777j7rvvpl27dqxatYp+/foV+HpWrlyZzp07M3fuXCZMmGCzbs6cORiNRnPA9sorrzBp0iRGjRpF69atSUhIYMuWLWzbto0ePXoUeK6c4uLiAAgJCbFZftddd1GrVi3efPNN8w/VN954g//+978MGTKEUaNGcfHiRaZOnUqnTp34999/zT+8v/rqKx599FHatWvHuHHjOHLkCAMHDiQ4OJjo6Oh8y7Nz5046duyIh4cHjzzyCDExMcTFxbF48WLeeOMNBg8ezMGDB/nhhx+YMmUKoaGhAOabRc4oY/Xq1YmMjGTdunXmZZs3byY9PZ127drRrl071q9fzzPPPAOoJr5gCe43b97Mhg0bGDZsGFWqVOHYsWNMnz6dLl26sHfvXnx9fenUqRNjx47lo48+Yvz48dSrVw/APP32228ZOXIkvXr1YvLkySQnJzN9+nQ6dOjAv//+S0xMjLlsmZmZ9OrViw4dOvDuu+/i6+ub7/MryPnz57nlllvMN8DCwsJYtmwZDz30EAkJCYwbN65I7+nk5GQ6d+7M6dOnefTRR6latSobNmzgxRdf5OzZs3zwwQd5luWxxx7jp59+YsyYMdSvX5/Lly+zbt069u3bR/PmzfPcT78meW2TmpqaK8mlv78/Xl5eeR7ztddew9PTk2effZa0tDQ8PT0L/Lw++uijnDlzhhUrVvDtt9/meewboQejLVu2tFneokUL3Nzc+Pfff7n33nsxmUzs3LmTBx98MNcxWrduzfLly7l+/Tr+/v6FPmZeqlWrxsaNG9m9ezcNGzbMt/zTp0+nQYMGDBw4EHd3dxYvXswTTzyByWRi9OjRNtsePnyYu+++m0cffZR7772Xd999lwEDBvDpp58yfvx4802FSZMmMWTIEA4cOGCThyArK4vevXtzyy238Pbbb/Pbb78xYcIEMjMzefXVV/MsY2E+CwBffPEFY8eO5c477zTfmN65cyebNm3i7rvvtjlm8+bNbf7fCSHKEFdX5Qshbl7Xrl3TAG3QoEH5bjdw4EAN0BISEjRNszR3HzhwoM12TzzxhAZoO3bs0DRN06ZMmVJgs/hvv/1Wc3Nz09auXWuz/NNPP9UAbf369eZlgObm5qbt2bPHZtvff/9dA7TFixfbLO/bt69WvXr1Ip9r+/btGqA98cQTNtvpzZ8LaiL52WefaYC2a9cum+X169fXunbtan7cpEmTXE1NC0Nv7j5jxgzt4sWL2pkzZ7QlS5ZoMTExmsFgMDdv1q/T8OHDbfY/duyYZjQatTfeeMNm+a5duzR3d3fz8vT0dK1SpUpa06ZNtbS0NPN2n3/+uQbYNCU/evSoBmgzZ840L+vUqZPm7++vHT9+3OY8JpPJPJ9Xc/eSKGNe7rrrLs3Hx0dLT0/XNE3TJk2apMXGxmqapmnTpk3TKlWqZN722Wef1QDt9OnTmqZp5qbK1jZu3KgB2jfffGNelldz9+vXr2tBQUHaww8/bLP83LlzWmBgoM3ykSNHaoD2n//8p8DnpGmFa+7+0EMPaREREdqlS5dslg8bNkwLDAw0P7/Cvqdfe+01zc/PTzt48KDNdv/5z380o9GonThxwrws52cpMDDwhpqmv/zyyxqgXb9+Pdc6wO6f/j7N2SVC/2xVr14917UtzOe1qM3dC7vv6NGjNaPRaHddWFiYNmzYME3TVBclQHv11VdzbffJJ59ogLZ///4iHTMvy5cv14xGo2Y0GrW2bdtqzz//vPb777+bP0fW7H1OevXqZfP9rGmaVq1aNQ3QNmzYYF6mf7/7+PjYfJfo70nrz5T+GXnyySfNy0wmk9avXz/N09PT5n9RzvdfYT8LgwYN0ho0aJDva6N75JFHNB8fn0JtK4QoXaS5uxDCZa5fvw6oWqX86OsTEhJsluesAXnyyScBlQwJMNd0Lly4MM+mrvPmzaNevXrUrVuXS5cumf/0pturV6+22b5z587Ur1/fZlnXrl0JDQ1lzpw55mVXr15lxYoVDB06tMjn0ss/duxYm/PoNSkFGTx4MO7u7jbl2b17N3v37rUpT1BQEHv27OHQoUOFOm5ODz74IGFhYURGRtKvXz+SkpL4+uuvc9WMPfbYYzaP58+fj8lkYsiQITavQ3h4OLVq1TK/Dlu2bOHChQs89thjNi0U7r//fgIDA/Mt28WLF1mzZg0PPvggVatWtVlXUBNgZ5VR16FDB1JSUti6dSugmr63a9cOgPbt23PhwgXzNVq/fj2xsbFERkYC2DRVzsjI4PLly9SsWZOgoKACm2mD6g5y7do1hg8fbvM8jUYjbdq0yfX+B3j88ccL9bwKomkaP//8MwMGDEDTNJvz9+rVi/j4ePNzKOx7et68eXTs2JGKFSvaHK979+5kZWWxZs2aPMsTFBTEpk2bipz48PLly7i7u1OhQgW76wcNGsSKFSts/nr16pXvMUeOHJmrGXpxP6/FkZKSYvP+tubt7U1KSop5O8BuKwFvb2+bbQp7zLz06NGDjRs3MnDgQHbs2MHbb79Nr169iIqKYtGiRTbbWr+W8fHxXLp0ic6dO3PkyJFcSRvr169vk5SxTZs2gPqet/4u0Zfby1o/ZswY87xeM56ens7KlSvtPpeifBaCgoI4deoUmzdvzvf1AahYsSIpKSkkJycXuK0QonSR5u5CCJfRg289WM9LXsF8rVq1bB7XqFEDNzc3c3/coUOH8uWXXzJq1Cj+85//0K1bNwYPHsydd95pbp546NAh9u3bl6s/vO7ChQs2j2NjY3Nt4+7uzh133MH3339PWloaXl5ezJ8/n4yMDJsAorDnOn78OG5ubtSoUcNmfZ06dezul1NoaKi5/+drr70GqGbB7u7uDB482Lzdq6++yqBBg6hduzYNGzakd+/ejBgxgsaNGxfqPP/73//o2LEjRqOR0NBQ6tWrh7t77n8rOV+zQ4cOoWlaruun8/DwANTrALmvsz7kW370H84FNYPNizPKqLPul96mTRs2bNjA66+/bi5/QEAA69evJzo6mq1bt9q8p1JSUpg0aRIzZ87k9OnTNv1ecwYfeT1PsOQTyCkgIMDmsbu7O1WqVCnU8yrIxYsXuXbtGp9//jmff/653W30z0Rh39OHDh1i586dhf48W3v77bcZOXIk0dHRtGjRgr59+3LfffcV+jrmpUqVKkXur27ve6a4n9fi8PHxIT093e661NRUcxCsT+2Nz63nC7HetjDHzE+rVq2YP38+6enp7NixgwULFjBlyhTuvPNOtm/fbr6hun79eiZMmMDGjRtzBazx8fE2N9Ry3tTT1+XsuqIvv3r1qs1yNze3XO+Z2rVrA+Q5ukJRPgsvvPACK1eupHXr1tSsWZOePXty99130759+1z76N8HhbkxKYQoXSRIF0K4TGBgIBEREezcuTPf7Xbu3ElUVFSugCGnnD9EfHx8WLNmDatXr2bJkiX89ttvzJkzh65du7J8+XKMRiMmk4lGjRrx/vvv2z1mzh9mef1wHDZsGJ999hnLli3jtttuY+7cudStW9dmDOyinqs4hg0bxgMPPMD27dtp2rQpc+fOpVu3buZ+16D6+8fFxbFw4UKWL1/Ol19+yZQpU/j0008ZNWpUgedo1KhRoYKPnK+ZyWTCYDCwbNkyjEZjru3zqpF0JmeWsUmTJvj7+7Nu3Tr69u3LlStXzDXpbm5utGnThnXr1lGjRg3S09Ntku89+eSTzJw5k3HjxtG2bVsCAwMxGAwMGzaswERp+vME1S/d3tjdOW+6eHl52fS/LQ793Pfeey8jR460u411AFqY97TJZKJHjx48//zzdo+nB0v2DBkyhI4dO7JgwQKWL1/OO++8w+TJk5k/fz59+vTJc7+QkBAyMzPNfa0dwd73THE/r8URERFBVlYWFy5csEnKlp6ezuXLl80tO4KDg/Hy8uLs2bO5jqEv07ct7DELw9PT05ysrnbt2jzwwAPMmzePCRMmEBcXR7du3ahbty7vv/8+0dHReHp6snTpUqZMmZLrc2Lv857fcs0BQ5wV5bNQr149Dhw4wK+//spvv/3Gzz//zLRp0/jf//6XK7ni1atX8fX1LdQNDyFE6SJBuhDCpfr3788XX3zBunXrbIIP3dq1azl27BiPPvpornWHDh2yqXE6fPgwJpPJJtGVm5sb3bp1o1u3brz//vu8+eabvPTSS6xevZru3btTo0YNduzYQbdu3YpV29CpUyciIiKYM2cOHTp0YNWqVeYs4rrCnqtatWqYTCbi4uJsas8PHDhQ6PLcdtttPProo+bmwQcPHuTFF1/MtZ2emf6BBx4gMTGRTp068corr5Toj/4aNWqgaRqxsbH5Bk3VqlUD1HW2runNyMjg6NGjNjdActJrsnbv3p1vWfK6Ds4oo85oNHLLLbewfv161q1bR0BAAI0aNTKvb9euHXPmzKFmzZoANp+Tn376iZEjR/Lee++Zl6WmpuYa9z2/5wkqG/aNZCcvDn3kgqysrEKduzDv6Ro1apCYmHjDzyUiIoInnniCJ554ggsXLtC8eXPeeOONfIP0unXrAirLe0nXahf0eS2pGtOmTZsCqntH3759zcu3bNmCyWQyr3dzc6NRo0Zs2bIl1zE2bdpE9erVzTcyCnvMotK72+g3BRYvXkxaWhqLFi2yqSW315XDEUwmE0eOHLH53jh48CCAzf8ma0X9LPj5+TF06FCGDh1Keno6gwcP5o033uDFF180dysA9Z7UE0QKIcoW6ZMuhHCp5557Dh8fHx599FEuX75ss+7KlSs89thj+Pr6mofKsqYPN6SbOnUqgPkH9ZUrV3Lto//w05tjDhkyhNOnT/PFF1/k2jYlJYWkpKRCPQ83NzfuvPNOFi9ezLfffktmZqZNs+SinEsv/0cffWSzTX6ZqXMKCgqiV69ezJ07lx9//BFPT09uu+02m21yvt4VKlSgZs2adpuqOtLgwYMxGo1MnDgxVy2UpmnmcrVs2ZKwsDA+/fRTm2axs2bNyhWE5hQWFkanTp2YMWMGJ06cyHUOnZ+fH0Cu4zmjjNY6dOjAxYsXmTlzJm3atLGprW7Xrh0HDhxg4cKFhISE2PzoNhqNuco3depUsrKybJbl9Tx79epFQEAAb775JhkZGbnKdfHixUI/h6IyGo3ccccd/Pzzz3ZvpuQ8d2He00OGDGHjxo38/vvvuY537do1MjMz7ZYlKysrV/eASpUqERkZWeDnQe+/bC8wdaTCfF7zus7F1bVrV4KDg3MNWzZ9+nR8fX1tRp6488472bx5s83rceDAAVatWmXOwl/UY9qzevVqu7XYek4P/QanXgOesyvIzJkz8z1+cVgPCahpGh9//DEeHh5069bN7vZF+SzkfB94enpSv359NE3L9Rnetm2buVWOEKJskZp0IYRL1apVi6+//pp77rmHRo0a8dBDDxEbG8uxY8f46quvuHTpEj/88EOu/tmgagkGDhxI79692bhxo3nIMr328tVXX2XNmjX069ePatWqceHCBaZNm0aVKlXMtZEjRoxg7ty5PPbYY6xevZr27duTlZXF/v37mTt3Lr///nuuRGh5GTp0KFOnTmXChAk0atQoVw1GYc/VtGlThg8fzrRp04iPj6ddu3b88ccfHD58uEiv7dChQ7n33nuZNm0avXr1yjWecP369enSpYt5PN0tW7aYh6AqSTVq1OD111/nxRdf5NixY9x22234+/tz9OhRFixYwCOPPMKzzz6Lh4cHr7/+Oo8++ihdu3Zl6NChHD16lJkzZxaqn/BHH31Ehw4daN68OY888oj5fbVkyRK2b98OqOGeAF566SWGDRuGh4cHAwYMcFoZdfr7cePGjbzyyis26/Rhmf7++28GDBhgU1vav39/vv32WwIDA6lfvz4bN25k5cqVuYbBa9q0KUajkcmTJxMfH4+Xl5d53Ojp06czYsQImjdvzrBhwwgLC+PEiRMsWbKE9u3b2wQcN2LGjBn89ttvuZY/9dRTvPXWW6xevZo2bdrw8MMPU79+fa5cucK2bdtYuXJlrhttBb2nn3vuORYtWkT//v25//77adGiBUlJSezatYuffvqJY8eO2TSP112/fp0qVapw55130qRJEypUqMDKlSvZvHmzTSsFe6pXr07Dhg1ZuXKl3aHHHKUwn1f9/Tx27Fh69eqF0Wg0DwFpz/Hjx83DtelBtZ4PoVq1aowYMQJQze9fe+01Ro8ezV133UWvXr1Yu3Yt3333HW+88QbBwcHmYz7xxBN88cUX9OvXz/wZef/996lcubJ5KMGiHtOeJ598kuTkZG6//Xbq1q1Leno6GzZsYM6cOcTExPDAAw8A0LNnTzw9PRkwYACPPvooiYmJfPHFF1SqVMlus/zi8vb25rfffmPkyJG0adOGZcuWsWTJEsaPH59nrgSg0J+Fnj17Eh4eTvv27alcuTL79u3j448/pl+/fjbdLbZu3cqVK1cYNGiQw5+jEMIJnJpLXggh8rBz505t+PDhWkREhObh4aGFh4drw4cPzzXkkqZZhvbau3evduedd2r+/v5axYoVtTFjxmgpKSnm7f744w9t0KBBWmRkpObp6alFRkZqw4cPzzU8U3p6ujZ58mStQYMGmpeXl1axYkWtRYsW2sSJE7X4+HjzdkC+QzSZTCYtOjpaA7TXX3/d7jaFPVdKSoo2duxYLSQkRPPz89MGDBignTx5slBDsOkSEhI0Hx8fDdC+++67XOtff/11rXXr1lpQUJDm4+Oj1a1bV3vjjTfsDmFkTR8mat68eflup1+nvIbA+/nnn7UOHTpofn5+mp+fn1a3bl1t9OjR2oEDB2y2mzZtmhYbG6t5eXlpLVu21NasWZNr6Cp7Q7Bpmqbt3r1bu/3227WgoCDN29tbq1Onjvbf//7XZpvXXntNi4qK0tzc3HINx+bIMuYnKSlJc3d31wBt+fLludY3btxYA7TJkyfbLL969ar2wAMPaKGhoVqFChW0Xr16afv379eqVaumjRw50mbbL774QqtevbpmNBpzDR21evVqrVevXlpgYKDm7e2t1ahRQ7v//vu1LVu2mLcZOXKk5ufnV6jno2mWIdjy+jt58qSmaZp2/vx5bfTo0Vp0dLT5s9+tWzft888/z3XMgt7TmqaGlXvxxRe1mjVrap6enlpoaKjWrl077d1337V5b1t/ltLS0rTnnntOa9Kkiebv76/5+flpTZo00aZNm1ao5/r+++9rFSpUyDXUV0HfGXkNwWbvs1WYz2tmZqb25JNPamFhYZrBYChwODb9fPb+7L13P//8c61OnTqap6enVqNGDW3KlCk2QxrqTp48qd15551aQECAVqFCBa1///7aoUOH7JahsMfMadmyZdqDDz6o1a1bV6tQoYLm6emp1axZU3vyySe18+fP22y7aNEirXHjxpq3t7cWExOjTZ48WZsxY0auz3u1atXsDnNn7zrq3znvvPOOeZn+GYmLi9N69uyp+fr6apUrV9YmTJigZWVl5Tpmzu/ywnwWPvvsM61Tp05aSEiI5uXlpdWoUUN77rnnbP5/aJqmvfDCC1rVqlUL9VoKIUofg6Y5IOOFEEIIIcRNKj4+nurVq/P222/z0EMPubo4wkXuv/9+fvrpJxITE11ajrS0NGJiYvjPf/7DU0895dKyCCFujPRJF0IIIYQohsDAQJ5//nneeeedQmXVF6IkzZw5Ew8PDx577DFXF0UIcYOkJl0IIYQQQohiKi016UKIsk9q0oUQQgghhBBCiFLCpUH6mjVrGDBgAJGRkRgMBn755ZcC95k9ezZNmjTB19eXiIgIHnzwwVzDUQghhBBCCOFMs2bNklp0IYRDuDRIT0pKokmTJrnGOs7L+vXrue+++3jooYfYs2cP8+bN459//uHhhx8u4ZIKIYQQQgghhBAlz6XjpPfp04c+ffoUevuNGzcSExPD2LFjAYiNjeXRRx9l8uTJJVVEIYQQQgghhBDCaVwapBdV27ZtGT9+PEuXLqVPnz5cuHCBn376ib59++a5T1paGmlpaebHJpOJK1euEBISgsFgcEaxhRBCCCGEEELcxDRN4/r160RGRuLmln+D9jIVpLdv357Zs2czdOhQUlNTyczMZMCAAfk2l580aRITJ050YimFEEIIIYQQQojcTp48SZUqVfLdptQMwWYwGFiwYAG33XZbntvs3buX7t2783//93/06tWLs2fP8txzz9GqVSu++uoru/vkrEmPj4+natWqHD16FH9/f7v7ZGRksHr1am699VY8PDyK9bxE6SDXtPyRa1r+yDUtf+Salj9yTcsfuablj1zT0un69evExsZy7do1AgMD8922TNWkT5o0ifbt2/Pcc88B0LhxY/z8/OjYsSOvv/46ERERufbx8vLCy8sr1/Lg4GACAgLsnicjIwNfX19CQkLkjV1OyDUtf+Salj9yTcsfuablj1zT8keuafkj17R00q9FYbpcl6lx0pOTk3O13zcajYBq4y+EEEIIIYQQQpRlLg3SExMT2b59O9u3bwfg6NGjbN++nRMnTgDw4osvct9995m3HzBgAPPnz2f69OkcOXKE9evXM3bsWFq3bk1kZKQrnoIQQgghhBBCCOEwLm3uvmXLFm699Vbz46effhqAkSNHMmvWLM6ePWsO2AHuv/9+rl+/zscff8wzzzxDUFAQXbt2lSHYhBBCCCGEEEKUCy4N0rt06ZJvM/VZs2blWvbkk0/y5JNPlmCphBBCCCGEEDcTTdPIzMwkKyvL1UUptoyMDNzd3UlNTS0Xz6cs8fDwMHfHLo4ylThOCCGEEEIIIRwpPT2ds2fPkpyc7OqiOISmaYSHh3Py5MlCJSkTjmMwGKhSpQoVKlQo1nEkSBdCCCGEEELclEwmE0ePHsVoNBIZGYmnp2eZD2xNJhOJiYlUqFAhV9JtUXI0TePixYucOnWKWrVqFatGXYJ0IYQQQgghxE0pPT0dk8lEdHQ0vr6+ri6OQ5hMJtLT0/H29pYg3cnCwsI4duwYGRkZxQrS5aoJIYQQQgghbmoSzApHcFQrDHk3CiGEEEIIIYQQpYQE6UIIIYQQQgghRCkhQboQQgghhBBCiBLx559/YjAYuHbtmquL4hDOeD4SpAshhBBCCCFEGWIwGPL8MxqNvPXWW8U69i+//FKobX/99Vc6d+6Mv78/vr6+tGrVilmzZt3wuYUiQboQQgghhBBClCFnz541/33wwQcEBASYH58+fZoxY8aUeBmmTp3KoEGDaN++PZs2bWLnzp0MGzaMxx57jGeffbbEz5+f9PR0l56/uCRIF0IIIYQQQohsmgZJSc7/07TClzE8PNz8FxgYiMFgsFk2f/58GjRogLe3N3Xr1mXatGnmfdPT0xkzZgwRERF4e3tTrVo1Jk2aBEBMTAwAt99+OwaDwfw4p5MnT/LMM88wbtw43nzzTerXr0/NmjV55plneOedd3jvvffYtGmTzT7r16+ncePGeHt7c8stt7B7927zuuPHjzNgwAAqVqyIn58fDRo0YOnSpeb1u3fvpk+fPlSoUIHKlSszYsQILl26ZF7fpUsXxowZw7hx4wgNDaVXr17cfffdDB061KYMGRkZhIaG8s033wBquLpJkyYRGxuLj48PTZo04aeffrLZZ+nSpdSuXRsfHx9uvfVWjh07VriLVAwyTroQQgghhBBCZEtOhgoVnH/exETw8yv+cWbPns2kSZOYOnUqLVq04N9//+Xhhx/Gz8+PkSNH8tFHH7Fo0SLmzp1L1apVOXnyJCdPngRg8+bNVKpUiZkzZ9K7d+88x/r+6aefyMjIsFtj/uijjzJ+/Hh++OEH2rRpY17+3HPP8eGHHxIeHs748eMZMGAABw8exMPDg9GjR5Oens6aNWvw8/Nj7969VMi+CNeuXaNr166MGjWKKVOmkJKSwgsvvMCQIUNYtWqV+fhff/01jz/+OOvXrwfg8OHD3HXXXSQmJpqP9fvvv5OcnMztt98OwKRJk/juu+/49NNPqVWrFmvWrOHee+8lLCyMzp07c/LkSQYPHszo0aN55JFH2LJlC88880zxL1IBJEgXQgghhBBCiHJi4sSJvPbaawwePBg3NzdiY2PZu3cvn332GSNHjuTEiRPUqlWLDh06YDAYqFatmnnfsLAwAIKCgggPD8/zHAcPHiQwMJCIiIhc6zw9PalevToHDx60WT5hwgR69OgBqIC6SpUqLFiwgCFDhnDixAnuuOMOGjVqBED16tXN+3388cc0a9aMN99807xsxowZREdHc/DgQWrXrg1ArVq1ePvtt83b1KhRAz8/PxYsWMCIESMA+P777xk4cCD+/v6kpaXx5ptvsnLlStq2bWs+77p16/jss8/o3Lkz06dPp0aNGrz33nsA1KlTh127djF58uSCLkOxSJAuhBBCCCHKhOPHVZPgPFrgCuEQvr6qVtsV5y2upKQk4uLiGDt2LOPGjTMvz8zMJDAwEID777+fHj16UKdOHXr37k3//v3p2bNn8U9eAD0QBggODqZOnTrs27cPgLFjx/L444+zfPlyunfvzh133EHjxo0B2LFjB6tXrzbXhluLi4szB+ktWrSwWefu7s6QIUOYPXs2I0aMICkpiYULF/Ljjz8CqqY9OTnZfONAl56eTrNmzQDYt2+fTWuAnM+jpEiQLoQQQgghSp1Tp6ByZfDwUI8TEqB5czV//LhqFrxnD4SFqe2EcBSDwTHNzl0hMfvuwgcffECXLl1wc7OkINObrjdv3pyjR4+ybNkyVq5cyZAhQ+jevXuuvtj5qV27NvHx8Zw5c4bIyEibdenp6cTFxXHrrbcW+nijRo2iV69eLFmyhOXLlzNp0iTee+89nnzySRITExkwYIDd2mvrmnw/OxftnnvuoXPnzly4cIEVK1bg4+ND7969ActrtWTJEqKiomz28/LyKnTZS4IkjhNCCCGEEKXK5s1QrRq0bAlnz0JGBixYAFeuqL81a+Cdd6BRI6hZU20jhIDKlSsTGRnJ8ePHqVmzps1fbGysebuAgACGDh3KF198wZw5c/j555+5cuUKAB4eHmRlZeV7njvuuAMPDw9zM3Brn376KUlJSQwfPtxm+d9//22ev3r1KgcPHqRevXrmZdHR0Tz22GPMnz+fZ555hi+++AJQNxX27NlDTExMrudkLzC31q5dO6Kjo5kzZw6zZ8/mrrvuwiP7zl/9+vXx8vLixIkTuY4bHR0NQL169fjnn3/yfB4lRWrShRBCCCFEqfLFF2Aywc6dEBmpaspbtrSsX7gQsluskpgI330Hzz3nmrIKUdpMmDCBcePGUalSJfr06UNaWhpbtmzh6tWrPP3007z//vtERETQrFkz3NzcmDdvHuHh4QQFBQEqw/sff/xB+/bt8fLyomLFirnOUbVqVd5++22eeeYZvL29GTFiBB4eHixcuJDx48fzzDPP5Gom/uqrrxISEkLlypV56aWXCA0N5bbbbgNg3Lhx9OnTh9q1a3P16lVWr15tDuBHjx7NF198wfDhw3n++ecJDg7m8OHD/Pjjj3z55Zd5JrfT3X333Xz66accPHiQ1atXm5f7+/vz7LPP8n//93+YTCY6dOhAfHw869evJyAggJEjR/LYY4/x3nvv8dxzzzFq1Ci2bt3qlHHgpSZdCCGEEEKUGrNmwVdf2S47fx6WLLE8/vxz1fxdN3GiagIvhFBNxz/88ENmzZpFo0aN6Ny5M7NmzTLXpPv7+/P222/TsmVLWrVqxbFjx1i6dKm5afx7773HihUriI6ONvfNtmfcuHEsWLCAtWvX0rJlSxo2bMj333/P9OnTeffdd3Nt/9Zbb/HUU0/RokULzp07x+LFi/H09AQgKyuL0aNHU69ePXr37k3t2rXNw8ZFRkayfv16srKy6NmzJ40aNWLcuHEEBQXZNOfPyz333MPevXuJioqiffv2Nutee+01/vvf/zJp0iTzuZcsWWJ+rapWrcrPP//ML7/8QpMmTfj0009tEtiVFIOmFWVEvrIvISGBwMBA4uPjCQgIsLtNRkYGS5cupW/fvubmEKJsk2ta/sg1LX/kmpY/ck3Ln5K+pnPngj6s8ahRKvjO0VXURpcucOIEHDmiAvsHH3R4kcq9m/1zmpqaytGjR4mNjcXb29vVxXEIk8lEQkICAQEBhQpihePk934qTByqk6smhBBCCCFKhY8+UtNHH1W15ZGRqi+6LiAA+vWzPG7ZEnr1UvNHjjivnEIIUZIkSBdCCCGEEC53/Tps2qTmX3hBZdgGyE7EDED37tC0qeVxy5ag58KSIF0IUV5IkC6EEEIIIVzu998hMxOqV7cE3gDe3vDJJ9CtG3z8MejDOVeoALffrrYHCdKFEOWHZHcXQgghhBAup2drv+uu3OueeEL9AUREqCRyjRqBpyfUqKGW798PWVlQQKJnIYQo9aQmXQghhBBCuNy//6ppnz4Fb9u3L2QPY0zDhuDvD/HxlmMIIURZJkG6EEIIIYRwKU2D06fVfNWqRdvX3R1uvVXN//67Y8slhBCuIEG6EEIIIYRwqStXIC1NzUdGFn3/gQPVdM4cx5VJCCFcRYJ0IYQQQgjhUnotemgoeHkVff/Bg8HDA3btgrg4x5ZNCCGcTYJ0IYQQQgjhUnqQHhV1Y/tXrAi33KLm//jDMWUSQghXkSBdCCGEEEK4zJEjsG6dmq9S5caP062bmv75Z7GLJIQoZQwGA7/88gsAx44dw2AwsH37dqeX4/777+e2224r8fNIkC6EEEIIIVziu+/UEGpvvqke64H2jWjVSk137ix+uYQo7QwGQ55/RqORt956q1jH1gPiwpYhMDCQ9u3bs2rVqhs+b2FFR0dz9uxZGjZsWKjtnRVYO5IE6UIIIYQQwumuXYOxY22XDRt248dr1EhNDxyA9PQbP44QZcHZs2fNfx988AEBAQHmx6dPn2bMmDFOKcfMmTM5e/Ys69evJzQ0lP79+3PkyBG722ZkZDjknEajkfDwcNzd3R1yvNJIgnQhhBBCCOF0ixbB1atqvn17WLgQIiJu/HhVqkBgIGRmwv79jimjuElpGmQmOf9P0wpdxPDwcPNfYGAgBoPBZtn8+fNp0KAB3t7e1K1bl2nTppn3TU9PZ8yYMURERODt7U21atWYNGkSADExMQDcfvvtGAwG8+O8BAUFER4eTsOGDZk+fTopKSmsWLECUDXt06dPZ+DAgfj5+fHGG28AsHDhQpo3b463tzfVq1dn4sSJZGZmmo956NAhOnXqhLe3N/Xr1zcfT2evufuePXvo378/AQEB+Pv707FjR+Li4njllVf4+uuvWbhwobnW/8/sPjEnT55kyJAhBAUFERwczKBBgzh27Jj5mFlZWTz99NMEBQUREhLC888/j1aEa1Qc5ff2gxBCCCGEKLX++UdNn34a3nuv+MczGKBWLdiyBY4ehcaNi39McZPKSoa5FZx/3iGJ4O5X7MPMnj2bSZMmMXXqVFq0aMG///7Lww8/jJ+fHyNHjuSjjz5i0aJFzJ07l6pVq3Ly5ElOnjwJwObNm6lUqRIzZ86kd+/eGI3GQp/Xx8cHUDcBdK+88gpvvfUWH3zwAe7u7qxdu5b77ruPjz76yBxIP/LIIwBMmDABk8nE4MGDqVy5Mps2bSI+Pp5x48ble97Tp0/TqVMnunTpwqpVqwgICGD9+vVkZmby7LPPsm/fPhISEpg5cyYAwcHBZGRk0KtXL9q2bcvatWtxd3fn9ddfp3fv3uzcuRNPT0/ee+89Zs2axYwZM6hXrx7vvfceCxYsoGvXrkW5HDdEgnQhhBBCCOF0epDeurXjjhkVpYJ0PVu8EDejiRMn8tprrzF48GDc3NyIjY1l7969fPbZZ4wcOZITJ05Qq1YtOnTogMFgoFq1auZ9w8LCAEsNeWElJyfz8ssvYzQa6dy5s3n53XffzQMPPGB+/OCDD/Kf//yHkSNHAlC9enVee+01nn/+eSZMmMDKlSvZv38/v//+O5GRkQC8+eab9OnTJ89zf/LJJwQGBvLjjz/i4eEBQO3atc3rfXx8SEtLs3k+3333HSaTiS+//BKDwQCopvtBQUH8+eef9OzZkw8++IAXX3yRwYMHA/Dpp5/y+++/F/o1KQ4J0oUQQgghhFOZTLB7t5pv3txxx9WHcJMgXRSL0VfVarvivMWUlJREXFwcY8eOtamBzszMJDAwEFCJ1Hr06EGdOnXo3bs3/fv3p2fPnjd0vuHDh2M0GklJSSEsLIyvvvqKxlbNWFq2bGmz/Y4dO1i/fr256TuoZuWpqakkJyezb98+oqOjzQE6QNu2bfMtw/bt2+nYsaM5QC+MHTt2cPjwYfz9/W2Wp6amEhcXR3x8PGfPnqVNmzbmde7u7rRs2dIpTd4lSBdCCCGEEE516hSkpICHB8TGOu64EqQLhzAYHNLs3BUSE9XNhQ8++IAuXbrg5mZJQaY3XW/evDlHjx5l2bJlrFy5kiFDhtC9e3d++umnIp9vypQpdO/encDAQHMtvDU/P9vXMTExkYkTJ5prp615e3sX+fxgaWZfFImJibRo0YLZs2fnWmfveTibBOlCCCGEEMKpDhxQ0xo1wJEJmvUg/cwZxx1TiLKkcuXKREZGcvz4cWrWrGkTpFsLCAhg6NChDB06lDvvvJPevXtz5coVgoOD8fDwICsrq1DnCw8Pp2bNmoUuX/PmzTlw4ECe+9SrV4+TJ09y9uxZIrIzSf7999/5HrNx48Z8/fXXZGRk2K1N9/T0zPV8mjdvzpw5c6hUqRIBAQF2jxsREcGmTZvo1KkToFojbN26leaObP6TB8nuLoQQQgghnEoP0uvUcexxo6PV9OhRxx7XWQ4dgmXLXF0KUdZNmDCBKVOmMHXqVA4ePMiuXbuYOXMm77//PgDvv/8+P/zwA/v37+fgwYPMmzeP8PBwgoKCAJXh/Y8//uDcuXNc1YdgcJD//e9/fPPNN0ycOJE9e/awb98+fvzxR15++WUAunfvTu3atRk5ciQ7duxg7dq1vPTSS/kec8yYMSQkJDBs2DC2bNnCoUOH+PbbbzmQ/UUTExPDzp07OXDgAJcuXSIjI4N77rmH0NBQBg0axNq1azl69Ch//vknY8eO5dSpUwA89dRTvPXWW/zyyy/s37+fJ554gmvXrjn09ciLBOlCCCGEEMKp9EDU0RVSTZqo6eHDluHdypLataFvX1i3ztUlEWXZqFGj+PDDD5k1axaNGjWic+fOzJo1i9jsviX+/v68/fbbtGzZklatWnHs2DGWLl1qrnV/7733WLFiBdHR0TRr1syhZevVqxe//vory5cvp1WrVtxyyy1MmTLFnLzOzc2NBQsWkJKSQuvWrRk1apRN/3V7QkJCWLVqFYmJiXTu3JkWLVrwxRdfmGvVH374YerUqUPLli0JCwtj/fr1+Pr6smbNGqpWrcrgwYOpV68eDz30EKmpqeaa9WeeeYYRI0YwcuRI2rZti7+/P7fffrtDX4+8GDRnDfZWSiQkJBAYGEh8fHyeTRsyMjJYunQpffv2LVICAlF6yTUtf+Salj9yTcsfuabljyOuaXw8hIRAVpYaz9zRtek1a0JcHPz+O9xgLiyXyU4yzRtvwPjxzjnnzf45TU1N5ejRo8TGxt5wn+jSxmQykZCQQEBAQJ7N3UXJyO/9VJg4VCdXTQghhBBCOM2WLSpAj4kpQoBuyoTDn0PcDNj/ASSfynPTDh3U9Msvi1tS10lOdnUJhBCuJEG6EEIIIYRwGn18dKuRjfKXdBxWdYd/HoVND8G2/4Pl7eDiBrubP/OMmv70E1y+XPzyuoIE6ULc3CRIF0IIIYQQTrN6tZq2bp3PRllpsONlWDMYljSAC3+p5X4xapp8ElZ2hosbc+3aqBHUrw+aZjlXWWCdfDolxXXlEEK4ngTpQgghhBDCKc6fhz/+UPODBuWz4YEPYM8bcGoBZCZBaFsYcBgGHYXBF6BCTdAyYVU3SDmba/du3dR07VqHP4USk5pqmZeadCFubhKkCyGEEEIIp9i8GUwmaNhQjZFu14GPVC06QEBdaPkxdF8D/tk7eIdB9z/BKwSyUmDPW7kOUbeump444fCnUGKsA/OkJNeV42Z1k+XSFiXEUe8jCdKFEEIIIYRTHDmipnkmjLuyFbY+pWrJK3eFvruh9mhwc7fdzjcK2s9R84c/g9SLNqujotT09GnHlb2kWTdxv3LFdeW42egZ7ZOl+YJwgPT0dACMRmOxjuNe8CYlZ82aNbzzzjts3bqVs2fPsmDBAm677bY8t7///vv5+uuvcy2vX78+e/bsKcGSCiGEEEKI4tKD9OrV7axMOACre6v5oCbQZQm45fNDt3JXqNgUrm6H04ugxkPmVWU9SD950nXluNkYjUaCgoK4cOECAL6+vhj0sfDKKJPJRHp6OqmpqTIEmxOZTCYuXryIr68v7u7FC7NdGqQnJSXRpEkTHnzwQQYPHlzg9h9++CFvvWVp0pSZmUmTJk246667SrKYQgghhBDCAY4eVdNcQXrKeVjdC9IuqeRwHX8GYwFjVhsMUOV2FaT/+zy4+0O1IYAlSD93TiVkK2alllNYB+mHD8PVq1CxouvKUx5oGvTrB2lpsGIF5BWvhoeHA5gD9bJO0zRSUlLw8fEp8zccyho3NzeqVq1a7NfdpUF6nz596NOnT6G3DwwMJDAw0Pz4l19+4erVqzzwwAMlUTwhhBBCiFIlIQGGDYO2beG//3V1aYpOD9JjY60WaibYOlYNteZfC3qsV/3OC6Pmw3Bkhtp3w91QoTqEtKRSJRWYZ2WpZHWRkQ5/Kg6Xs7X15s3Qs6drylJeXL0Ky5ap+YMHLbkKcjIYDERERFCpUiUyMjKcV8ASkpGRwZo1a+jUqZO5Ob9wDk9PT4e0XnBpkF5cX331Fd27d6datWp5bpOWlkZaWpr5cUJCAqDevHl9CPXl5eFDKhS5puWPXNPyR65p+SPX1LESE2HcOCPLlrmxbBn06ZNBkybOLUNxr+mpU+6AgfDwDPRDuO19A+OJuQBktp6FZgyCwh7fPRR6bMO4cShu51diOvgpWS2nAxAW5s65cwZOn84grJAxvytdv27A+qd5XFwmGRkln8ysPH9Oz5wBUEHqoUOZ1KhR8OtZ3L7EpYHJZCIzMxOj0Vgunk9ZkpWVRZb1eIpWivIZK7NB+pkzZ1i2bBnff/99vttNmjSJiRMn5lq+fPlyfH198913xYoVxSqjKH3kmpY/ck3LH7mm5Y9c0+LTNBgzpiunT/ublz3++GVefnmTS8pzI9c0Lc2Nq1cHALBnz3KOHcvEXUuhZ/I7GIFdng9y5O+LwNIiHzsssz3tWEnasV9Yfr4/GAwYjV0Bf1as2MSZM5eLfExn27y5MnCL+fH27XtZuvSo085fHj+n+/YFAx0B+OWXfZhMR1xbICcrj9e0LCtKcsIyG6R//fXXBAUF5ZtoDuDFF1/k6aefNj9OSEggOjqanj17EhAQYHefjIwMVqxYQY8ePaSJSDkh17T8kWta/sg1LX/kmjrG9etQpYo7KSmqj2NAgEZCgoEtW8Jp3bovoaHOK0txrunhw2rq66tx5509MRjAcOIH3Dclo1WoSd3e06hruMFmolld0Ra+g0/WZfq2rwJBTYiIMHL6NNSvfwt9+5b+4bWSkmz7sNaq1YC+feuV+HnL8+c0I8Pymrq716dv3zzau5cz5fmalmV6i+7CKJNBuqZpzJgxgxEjRuDp6Znvtl5eXnh5eeVa7uHhUeCbtjDbiLJFrmn5I9e0/JFrWv7INS2etWstScX8/SE+3kDdunDgAGzf7kER0vs4zI1cUz0nV1SUAU/P7H1PzwfAUG0YHp65f68VoUAQ3g1OL8bjwnIIa4mexig52Z2y8PbL2RI2K8uIh4fzmiqXx8/p1auW+UuXnPt6lgbl8ZqWZUW5FmUyJ/9ff/3F4cOHeeihhwreWAghhBCiDDt40DJ//bqatm6tpv/84/zy3Ch9ODQ98zoZCXDmNzVf1QEj9UT1V9Oj34JmQm8wmZAAJ07ArbfCr78W/zQlxTq7O0D2cMuiGC5etMxfu+ayYghRZC4N0hMTE9m+fTvbt28H4OjRo2zfvp0TJ04Aqqn6fffdl2u/r776ijZt2tCwYUNnFlcIIYQQwul27LDMt2yppnqQvmkT/Oc/8OGHzi9XUa1Zo6Z16mQvOPodmNLAvzYENSr+CaoNB48ASNgP5/80B+nr1kG1avDnnzBgQPFPU1JyBunlMI+b0126ZJmPj3ddOYQoKpcG6Vu2bKFZs2Y0a9YMgKeffppmzZrxv//9D4CzZ8+aA3ZdfHw8P//8s9SiCyGEEOKmkF2Xgb8/zFVJ0M1B+rJlMHkyjBtnqakubdLS4OWX4bPP1OO77gKuH4adL6sFtZ9UY54Xl4c/VB2q5o//YG7uPnt28Q/tDDmDSKlJt3X2rHqfHzhQ+H0uW+ULlJp0UZa4tE96ly5d0LS8E3nMmjUr17LAwMAiZcYTQgghhCirUlNh/341v2+fpal4kyaqG7Z1beu336pa9cWL1fjgBeTWdZqnn4Zp09R8u3bQpQuw7X1IvwoVm6mxzh2l2lCI+wJOLyIg4HPAAcG/k+QMIiVItzV6NCxYoG5UqaHVCmb9mkpNuihLymSfdCGEEEKIm8GePSrgDgmByEjLci8v6N7ddtv33oMrV2DgQLj9dtukWa6k9wN/4glYvhyMbiY4tUgtbPw6GIuRMC6nsA5g9IHUC1QP3mN3k5zNyksLPYjU8x1LkG7rr7/U9OzZwu+TM0jPp25QiFJFgnQhhBBCiFJK74/etGnuFuGvv277+NIl1f9ad/JkiRatUK5eVUnbQJXXzw849weknAZ3fwjv6tgTGr0gTI2LXTvwD7ublNZuAXpAGRamptIn3ZbefQEgM7Nw+1gH6RkZpfcGjRA5SZAuhBBCCFFK6f3RmzTJva55c5UM7emnITxcLbNOMlcagvSdO9W0alWoWDF7YdwXalp9JBi9HX/S8G4AVPMum0F6pUpqKjXptqxvUh0+XLh9cjZxlybvoqyQIF0IIYQQopT6+281bdrU/vrOnVUz95gY9XjzZsu6HLl3XUIP0s03GTKT4PQSNR+bewQfh8gO0sMNf2F0s1S56v35S3uQrtekS5BuYTLZXrdTpwq3X85+/pI8TpQVEqQLIYQQQpQimgYzZqgkcHrQrWdzz0tIiJouXmxZVhqCdL1m3xyk//MYZCWDTyQEtyiZkwY1Bc+KuGsJtKy+xbxYH7m3tAfpUpOe2+XLapQAXWH6pZtMkJCg5n191VRq0kVZIUG6EEIIIUQpsm4dPPSQGloN4MknrcYWz4MepFsrDc3dbYL0zBQ4MU8taD4FDCX0M9TNCJW6ANCtgaXJe4MGavr889CjhwriSpOcQbr0Sbe4eNH2cWGyuyckWBLFVaumphKki7JCgnQhhBBCiFLkn39sHz/zTMH7+PjkXlaULNglITMTdu9W802aABf+BFMa+ERA1btK9uQRPQHo13SJeVHVqpbVK1fChg0lW4SiMJksAWRJNHf/7Tdo21Y977IoZ5BemPe2ftPD29ty40Oau4uyQoJ0IYQQQohSZO9ey/znn1tqAfNjPdza0qVqeu6cY8tVVIcOqXHefX2herV02DpOrYjslztVvaNF9Qfgllp/UyngPB99pII1az/9VLJFKIqkJEutb2iomjoySJ82TeU36NFDnausKU6QHhgIQUFqXmrSRVkhQboQQgghRCmiNxGfOxcefrhw+/j7W+b1oN4VNemXL6ts85s2WZ5Ho0ZgPP4VXD8I3uHQZFLJF8S3CgS3wM2gcWDVrzz5JHTNMdrbtm0lX4zCSk5WU4MBAgLUvCOD9MREy7z1MH1lxY00dz9/Xk0rVbIM3yY16aKskCBdCCGEEKKUiI+Hf/9V823aFH6/CROgfXv4/nvLcGxXr9om23KGWbNgyhS45RZLjX6TJhocmKoeNHgRvEOdU5ioQQAEJf0KQK1asG8f/JHdTX33bkvttavptdu+vuDlpeYd2SddvwkAludflly6pKb16qlpYW5A6S1JIiIsQbrUpIuyQoJ0IYQQQohS4q+/VP/kWrVs+1AXJDpa1ZAOH241HjkqAZ0zHThgmf/2WzXt2mwnJOwDow/EjnReYcKzq84vWzr5162rbmYYjeomRmFqZJ1BD9L9/MDDQ807sibdOjg9etRxx3UWvSa9USM1PXu24BsseiAfHi7N3UXZI0G6EEIIIUQpoQ+51rHjjR/DYLAkkps9G44dK3axCu348dzLWlVbrWYq3wqegc4rTFATwAApZyD1gnmxl5e6qQGlIwM+WGq6fX3B01PNOzJIt27mffmy447rLHpNuh6kJyfD9ev576MH6dY16dLcXZQVEqQLIYQQQpQSu3apaePGxTvO3LmW+dhY2Lq1eMcrrCNHci+Ldl+uZrKHRXMajwoQUFvNX/nXZlVpq1m1rkkv6SBdD3jLEj0gr1zZEnAX1ApCb+4uNemiLJIgXQghhBDCxbKy4M03YeFC9VivMbxR/fvDSKuW5Z9+WrzjFUZWVu6a9AcH/YPHxd/Ug6gBJV+InCo2U9Or9oP00lKzqtekWwfpjuqTnpqq/nRlsSZdv4lRoYKqGYeC+6VbB+lSky7KGgnShRBCCCFc7Jtv4KWXLI+LW5MO8PHHMHasmrfuK15STp9WgaWHB3z3HXTukMyn9wwGNIgeDIF1S74QOZWRIN06cZyj+6TnrD2+fLn0JMwrLOuWBoUN0vV+7JUqQXCwmi+LrQjEzUmCdCGEEEIIF4qLg9GjLY/vuccyVnZxVKgA992n5ksqSN+wQWVJB0tT95gYuOdujT/fGYNHxmnwrQptZpRMAQpSxoJ0e83dV6xQWelvlP4cjUY1TUuzzfZeFli/PpGRar6g5u56QB4aahmW8NixsneDQtycJEgXQgghhHChFSsgJUVlZX/tNfjkE8cdu3Z2l+wLFxwfkJ49qxLcNWqkxqTWg/Tq1YGzv8ORmWBwg5YfOTdhnLWg7CYJ1w9DZoplcZCalpYgPa/EcdOmQc+eUL/+jR9br0mPirIcu6zVKBe1Jl3T4MoVNR8SokZKcHNTzf6dlZ9BiOKQIF0IIYQQwoX04Pa+++Dlly39Zx3B399Si7h5s6r1HjIE1q698WOeP+/LsGFGpk1Tw8UBTJ+eI0jf86Z6UPspqDLoxk9WXN6VwLMioMH1g+bFpa2Psr2a9Ph42xYWN0p/jhUrqoAVyl6/9KL2SY+PVzkSQD1nDw/Le7VVK8u8EKWVBOlCCCGEEC5kE9yWgFtvVdMFC1St97x58PbbN368119vw/z5brz+umXZli2W8bdb19oJF9eCwR3qPXvjJ3IEgwEC6qn5eEub8dJck+7ldePH+eQT+Oor22X6cwwMhIAANZ+YeOPncAW9vNY16fk1d9dvQvj5gbe3ZV53+rTjyyiEI0mQLoQQQgjhAkeOqGRxP/+sHsfGlsx5undX0+nTLcv0fuRFdfIknDwZkGv5rl2Wmw1dIj5QM9G3g2/kjZ3IkQKz24pf3mReVNqG5LKuSbcOJovi3DkYMwZGjVLdJ3R6kB4UZDm2fr6ywGSyPB/rPun51aS3bq2mej98gG+/tcwfPIgQpZoE6UIIIYQQLvDSS2rYNV3NmiVznv79c9fOJiSoPs8//aTmFy5Utaxt2qjEYnlZvdpgd/mJE/Dvv9Cr8W/EmGaqhbWfdNAzKCZ96Le4LyBBZdArzTXpNxqkW/czv3DBMm8dpPv6qvmyFKRbJ7mzDtJPnbKfBC4ry9IfPSHBsvz229VnAZwz2oEQxSFBuhBCCCGECxw7Zplv1AjqltAIZYGB0Lu37bIrV+Cuu9Tf66+r2vzr1+Gff2DpUnjwQVUjm7Pv7rp1uX866gFvWhrc1/Eb9aD6A1Cpo+OfzI2I7Av+tSEzCTY9BJS+IN26Jt1otDTRtlZQP2rrwFwfIxwsrQWsa9LLUnZ3/bUxGMDHR+VYMBrVc7BXm64H6KCGX7NWp46aHjpUMmUVwlEkSBdCCCGEcIHz59W0eXOYP18FIUWiaervzG+wug98b4BfomHHy7k2nTxZJd1q29aSNG3RIjWdMkXVhOv++1+YOVP1bZ4/3/Y4+/er6fjxWXh6wrBh0KCBWuZhTKdv02XqQY2HivhkSpCbO3RZovrIX1wP8XtLdZAO6lrllJGR/zH091PO+bLe3N16DHk3N5VYT+8aYq9GXB8fHWDZMtt1ei289esjRGkkQboQQgghhAvogcKcOTfQ1P34XJgXCL9UgT/7wNnf1PLkU7DnDfijOyQeMW9ep45K7LZyJdSqZXuoChXg+HHL4z17LPN6kJ6VpWpyDx5UdxJuv93EqVMwa5YKmIIrXOaDEeMI8r0G3uEQcksRn1AJ868JYe3V/OUtpS67u3Vzd7ixIN26Jr08BunW3QD0oQXt9S3Xm/3Xrq1ugFmrXFlNJUgXpZ0E6UIIIYQQTpaYaAnM9MCh0E4thL9HQuZ1SDkDbh4QUAf8YiC4JWCA83/AohpwcBqYMgEIDVVB4ODBtoe7ds226b21AwdUcNiuneqzfuWKCtJr1YKwMNXXvXqsiZUvdueJHtmZ6WLuATej/QO6kp5ALmGfuSY9JUX1zXe1nIGovX7pRalJt27uXtb7pFtndtfpN5ri4nJvr9ekh4XlXqc3f7e+oSFEaeTu6gIIIYQQQtxs9IDKx8d+rWmeLqyDNbcDmupn3fBlCOsIFWIs21w/DH/2heuHYMtolSyt5Yfm1fffr5qy33IL7N2rEr6B6udbpYptrfrBg/DNN6qvui4sLBlfXw/z4971fqCZth2ANL8WeDV4sQhPyIn0odgS9pmHIgPVZ9teQOdMhalJL+hmgr3m7nv2qBwDUHb7pOvJ36yvWXi4mtqrEc8vSJeadFFWSE26EEIIIYST6UFC5cpF6IueHg+bHwM0CGkNvbdA7AjbAB1U0+6OP1seH/wI9n9gfhgRAYcPw3ffwciRls06dVLJ4nRubqoWc+pU28P37GkVxadf4xaPcQBcCH8Vr4GbwSukkE/IyQKyM/Nd24PRaAn6SkOT95w16fayludXk/7hhzBjhuWxXpOu5x0A1fS7LDZ3v3pVTStWtCzTg217NeKFqUm/dEl14RCitJKadCGEEEIIJ7MO0gvtwAcQvweMvtBuNnj4571tUCMYboJtz8CBKbDt/+DiOhXUVxlk3uzhh9X45kYjjB+vksppmhpn+okn1LodO9S27dtDixZZtG9/GKipauwX18IA4F2ZSp2evoHsd04UnN1BOfEwpF0hKCiYhITSFaTrNenW47f7+qqa7/yC9GeesX2sv7/27lXTl19WWdHLYnN3e0G6HmzbqxHfsEFN9eRy1kJD1VtU01SgXuSuJkI4idSkCyGEEEI4mV4DWOggQdPg2Gw13/IjVVteEIMBmr8LDV5Sj0/+DGtug33vmatqfX1VLez776sAxsNDZXfv1QuqVrUcKjQU1qyBd9814eVlUoHuqu6WDZq9C+43OMC3s3iFgH92Z+bL/5SqDO9683O9ptu6TB7ZPQvyau6uaZZa4S5d1FSvSd+3T01btLA9flkP0vOqSb92DVasUPN33pn7WO7uqiUJ2O/PLkRpIUG6EEIIIYSTFbkm/eJa1cfc3Q+qDin8iQxu0Pg16LwEqtymlv37rBqq7eR8yLie567WQXrXrqr5O4C/6Rjuq7tC0nEV9N52GmLvLXyZXCm0rZpe+NOc4V0PAl0pv5p0T081zasm/fJly/xHH6np+fMqG78epNfL7o6vB+nz5qlx7cuC/GrSL1yw7Rpw8qS6YREamnsUA52e8X3zZseXVQhHkSBdCCGEEMLJihykH/pMTavdnX8zd3sMBojqCx3nQ+2xalnKaVh7ByyMgT1vQcIhtTw7EzzYBundu6t1boc+oUPKSxhSz0FQY+i+Fnwji1YeV4roraanlxATo2b1QNZVTCaVZR4sQXRqqmW9XpOeV5B++rSahoZartn16yozf3Ky2r9GDbXc29uyX+fOarvSzjo7vU4P0jMybFsd6DcsQkPzPl7r1mq6aZODCihECZAgXQghhBDCyYoUpCefgZM/qfmaj9z4SQ0GleX9zqtQ9S61LP0K7HgRVrSFreNgXoCarhvCiKr9iQ07gp9XIoP6XIW/H8S4/f/wJAlTcBvo/if4lLFOvRG9AAPE76ZLm7OA64M1PUAHS5D+888quP7224Kbu585o6ZRUSoZnh6I//mnmtaurZp5A+bWA6Ce9wcfOOIZlCx7Nene3pZA3Ho0An2M9JB8chc2baqmrr45I0R+JEgXQgghhHCyIgXpO18GUzqEtoOQlsU/uWcQdJgLPdZDSBu1LO0yHPgQslLU9MQ8avst4cC7dUic4U+lNcFw7FsA9nncTVbn38CzYt7nKK28gqFiEwA61V0LwN9/Q2ZmfjuVLOvh0Hx81HTwYFXLfe+9BTd3tw7SDQZLVvM1a9RUb+oOKtfASy9ZHh85UvzylzR7QTqomw+gWgzoClOTXr26mh45Yj+LvhClgQTpQgghhBBOVuggPT0ejv+g5pu949hChLWDXn9D311g9AaDUY25bsXD3TZ6NVUdxkHPIaU/SVx+wjoBUN1/DWFhKghcudJ1xfn9d8u8m9Uvcy8vNS2oJl2vPdaDc722fNs2NdWDWVA16q+/Dp9l956w7s9eWuUVpNepo6YHD1qW6c8nv5p0Pet7QkLpyEcghD0SpAshhBBCOFmhg/QT8yArFQLqWZKeOVpQQ+h/UCWA6/YHNJ+iEs0NPAI1HoawDtD8A2j9OVktPy+ZMjhTJRWku11ay5DsHHxTpriuOCNG5L++oJr0nH229SBdD16jonLvowexZSFIP3FCTSNzpD7IryY9vyDd1xfCw9X80aOOKaMQjibjpAshhBBCOFFqqqrFg0IE6Ue/VtPqI0t2DHK/aMt83XGW+TY5gvL8BusuK8I6qOm1XTw79iqff16R5cth1y5o1Mi1RbOnoMRxOWuarfudgyUgtVZWgvSEBEsZc457rj8+edKyTG9VkF9zd1CZ38+dg5YtVbeAjh3z314IZ5OadCGEEEIIJ9Jr0T09cwdUNq7HwcV1ahi1mDIyxFlZ4FMZ/GIBjZjAHfTvrxZ//71rihMcrKazZtlfX1Bz94KCdH1ccGtlJUjXa7pDQ1VSPGv6zQd9THjII3Fc2hX49zm4ut286KGHLKsXLnRYcYVwGAnShRBCCCGcyLqpe76V48eyo8bK3cHXTptlceMCsttKJ8bRr5+a3brV+cXQNMuY6D162N+moObuNxKk6zXNV66oIeBKKz2xnZ7szZr+vM6etSw7dkxNrYcP5PCnsO9dWNYMTi0CVEI+/+yRDMvCMHTi5iNBuhBCCCFKTEaG5afGnj3w1FO2QybdjPQgXR/rOU+nVUBBtSElWp6bUoXsgcOvx5mvgyuSiCUlQVaWms+rVUVhm7vn7JOuy6+5u8lkO854aXPqlJraBN3Z9Od1/bp6HTUtj6D+4nrL/NrBcOlvjEZ480216MoVhxdbiGKTIF0IIYQQDrd1K/TsaWT48L5MnerG1avQsCF89BG8+66rS+dahUoal3gErmwBDBDZzxnFurn411TTxMPmGmhXBKv6Od3dVUIze/Sa9Btp7h4SYhk3Pecx9THZS3OQqpfNXh9zf3/La3buHCxYoPI9QHZQf3wu/NENzixVCz0CQcuCo2ooQb2bgX6O5GSYOhUuXCiZ5yJEUUiQLoQQQgiHu/9++PNPNzIzjTzzjJGJEy3r/vrLZcUqFfQgIN8gff+HahrRC3zsVIWK4vGvpabx+8zBrStq0q0zs+fV9aE4ieM6dMj73HqQnpRUmJK6hh5A5xx+DdTrZd0v/Y47LOs8PIAd4+H8quwFQdA6Owni6cVwbiWVgy7bnGPoUBg7Fh55xOFPQ4gikyBdCCGEEA4VHw+7d6t5NzfV4fXDDy3r9++31HjdjAqsSU88Aoc+UfN1n3ZKmW46QY3VNGE/QQFpgAqYNc25xcg5fJo9+SWOs26ubi9I79497+PqQXpKSgmOGlBMegCt13rnpPdLP33asmzgQCDtMiTGqQUhbaDzIojqD16hkHwSVvWgefoD5nMsWgS//qo2X7hQdUHYtMnSFUEIZ5MgXQghhBAOtWWLmsbGanz44WoMBtvIJyMD9u51QcFKiQKD9NNLVLPcSp0gIo9sYqJ4fKPBsyJomQQb1ZsxK8v5ScQKE6TnlzjuwgUVqLu5WXIcNG6sapkbNYL77sv7uGWpJj2vIF2vSd+xw7Ls55+By/+oB/61odffUKkjuPtCy4/N21VMXoyfVyJXrsAHH1j2j42FZ5+FW26Bz3OMQCiEs0iQLoQQQgiH+u03NW3TRiM6OpH69S3r2rVTU72m/WZUYJB+frWaRvR2SnluSgYDBDUBwDtlpzkQdnaTdz1Iz28ovvyau+s1yJUrq37toILz06dh27bcw5ZZKw9Bul6Trmfmj4jIfh1OL1YLKuUYAL3aUOhjiej7Nl1KYmLufuh60P7SSzdcdCGKxaVB+po1axgwYACRkZEYDAZ++eWXAvdJS0vjpZdeolq1anh5eRETE8OMGTNKvrBCCCGEKJCmwZw5an7wYNXU/fnnVZvR1q2heXO1btcuV5SudMg3SNdMcCG7037lW51WpptSQF0ADImH7PZL//FHWLmyZIugd/vw8cl7Gy8v222t6UF6VI4R+szBaj7KQ5Cu16TrQXpUFOpL6OQCtSD6ztw7VWwM9V8E4NMHH+PO1vM4fNiyWh+bHSA6+sbLLkRxuDRIT0pKokmTJnzyySeF3mfIkCH88ccffPXVVxw4cIAffviBOnXqlGAphRBCCFFYx4/DyZOq9q9XL9XMffhwjWXLVDPUxtldgV0xJnVpkW+Qfm0npF8Bd38IbunUct109LHSrx/MFaQfPAjDh+c9drmj6LXjem25PXptuL2m+HkF6YWhZ0ZPTi76vs5S2Jr0S5fUNCoKuH4YUs+Bm2feN7pqjgI3L4IrXOXHJ4cR6HXe7mbHjjk/T4EQAAXcYytZffr0oU+fPoXe/rfffuOvv/7iyJEjBGd/WmNiYkqodEIIIYQoqn+yu4I2aWJbO9g7u+V2p05quno1zJ+vgvaaNZ1bRldKTrYEHvbGr+bMMjWt1BHcXPozrfzzzw7SEw4SE6MSGi5apMbYtq5ZLUmZmWqaX623HqQnJOReV5wgXa9JT062JI67fBlGjVLN76dNy3tYuOLYtEllUX/vvfyzz6enWz4r+rjuOeX8DNWoAZxepB4EtwSjl/0dK1SHbqthRTuMbiYaVNnDhb2575olJKim8PmOxCBECShT3/6LFi2iZcuWvP3223z77bf4+fkxcOBAXnvtNXzyaCeUlpZGWlqa+XFC9jdcRkYGGXmMZaEvz2u9KHvkmpY/ck3LH7mmZV9CAkyZYgTcaNEiy+41jY2FKlXcOXXKwB13QFCQxrFjmSUSDJRGmzcbAHciIjT8/TNt+xlrGu5HZ2MAMiMHoZXCz0K5+pz6VscD0BIOcGvnVH77zZsPPoDZszUmT85C/5mcnp6R5/BoxZWa6gYYMRpNZGTYTyXu56e2uXYt9zbnz6t1oaFZZGSYinRuHx/1Wb1+XR0zIyOD8ePd+OUXIwA1a2bxwgtFO2Zh3HKLajZw330aBw5k5rndtm0GTCZ3QkI0QkIy7fbJj4wEsDRDuKX5ebRdr2AAssK6YMrvfRrUkoPX+tEgaAl1I/ez5sCtVKkCx4/bXuwjRzIJDi5b1enl6nNajhTlepSpIP3IkSOsW7cOb29vFixYwKVLl3jiiSe4fPkyM2fOtLvPpEmTmGg9OGu25cuX41vAL4IVK1Y4pNyi9JBrWv7INS1/5JqWTSkpRv773/YcPlwRX98M6tdfy4oVqn1uzms6YEA1pk9vCsC1awamT/+bevWuOLvILrFoUXWgEdHR51i27B+bdaFZO2mfuodMPFm+14+MfUtdU8hCKBefU02jN/54ma4TEzgDeAKAixcNLFsWB6julIsXL8PdvWSCtN27awINOH/+FEuX/mt3m6NHo4HmxMVdZOnSv23WHTjQAqjCqVN7Wbr0SJHOffFiI6A6u3cfo2lTdU3XrWsPhAKwevVpGjWyX6biGQRAQkIqS5cuz3OrpUtjgCZUq3aBZcv+truNGiJtkPlxYOo0DIZEUg0VWXm8MVkn8v8M+SaG0iAI+jf7le83P4ifXyL6869S5TqnTvnzyy/buHDhbOGfXilSLj6n5UhyEfqWlKkg3WQyYTAYmD17NoHZaTDff/997rzzTqZNm2a3Nv3FF1/k6actY4wmJCQQHR1Nz549Ccgj5WVGRgYrVqygR48eeOTXSUiUGXJNyx+5puWPXNOy7eOP3Th82EhIiMbSpdCsWcc8r2nfvjBqVAZPPmlkwwY33N3b0bev42vsSqNZs1QtZf/+lejbt6/NOuPf38NJMNR4kB7Nh7iieAUqb59T47pOcHYJd3RK4osvMnn4YfXT2GSqZd6me/c+JdbSY8cOlR4qJqYKfftG2N0mLc3A1KmwbVtl6tfvi3VPz88/V++n1q3r0bdv3XzPZTi9CEPiIUwx94NXCOvXu7FkCVSqFAvso0ePHjz3nOW3tJ9f3mW6UXrfcYBWrbxyfQas/fabem26dw/NvZ0pE8Ol9Wih7alQQSMxUdV+d2t0DQ6DR/Uh9Go+uMDy7HL3gPiv6dt0Gf1v2cYF0y3m4SHbtvVj3jwIC2tR5r6fytvntLxIsNdnJQ9lKkiPiIggKirKHKAD1KtXD03TOHXqFLVq1cq1j5eXF15eufujeHh4FPimLcw2omy5Ga7pnDnwzDMweDDUqwdGo+rrlnPq6GXWUzcnpqS8Ga7pzUauadk0d66a/u9/Blq3tr1+9q5p8+YqWN+wAbZuNeLhYXRWUV0mKwv+yk7c3r17jueclQ7nfgfAWP0+jKX8M1BuPqdht8DZJRjjdzFqlDtffw3r1sGhQ9b/yDzyTexWHHpSMi8vNzw87P/ztO6P3aePh01/eT0ze1CQe/5lTDkLG1Smc2PSYWjzpbmve1qaeh96eHhw8aKlqXd8fN5lulFTp1rmK1bM//iJiWoaFpbjs2LKhI13w6lfoOlkPv90LONf8uCbb40YL64CwFi5S6E+Q+HN+vLbh73o3eR3BrT+k5/2tTOvi41VZTt9uux+P5Wbz2k5UZRrUaaC9Pbt2zNv3jwSExOpUKECAAcPHsTNzY0qVaq4uHRClA7Tp6tEMtb/CJ3NYCheoF+YZW5uRs6da8Yvvxjx9CyZGw4lcQw3N0qsb6MQrnLpkkoGBXCnnRGP8tK6tZpu3uz4MpVGu3ap7OH+/tCqVY6VF9dCRjx4V4KQ1i4p300pqJGaxu8GQP85eeCAZZPMvLtNF5veRbUwieMA4uJs1+mBrL9/ASc6/atl/uxy0DR8fdU/o6QkOHHCnxYt3M3jtkPJjBm/1Kr1uVXKKLvyfG7/PKoCdIDtLzDc8w2Gf9kMmn4Ji3eDwQ0iehaqPBERMHlHH3o3+Z2GldfTeDgsWQKPPw5Vq6ptTpwo1KGEcCiXBumJiYkctrodePToUbZv305wcDBVq1blxRdf5PTp03zzzTcA3H333bz22ms88MADTJw4kUuXLvHcc8/x4IMP5pk4ToibzZHsLmkREdCunfpxkZVlOy3ssoK2z4umqR8eJZuvxA2oWpInKDGl4WZBSR3D1xcaNVLz4uaxerX63DdooCdyKpyW2SOMxcXB5MnwwgslU77SQs9836aNnaDs1EI1jewPbvIBcprABmoavxdMWURFqdfeOoAsyf9l+v/SwgzBZo8+LFt23VVumgaXNsLxHyzLkk9C4hH8/GoAKkhfsKAmu3bZ3kF2dJCelAS7d1seFzZINz83UwasHwYn59tumJEAF/6CX7Ob+4d1AK88xmzLwWAA7yrtAagbuhFjXRNXr7rh5QWLF6ttJEgXruDSIH3Lli3ceqtl/EK97/jIkSOZNWsWZ8+e5YTVJ6NChQqsWLGCJ598kpYtWxISEsKQIUN4/fXXnV52IUqj+Hg1PjHAnj2Yx30tKSZT8W4C3MiNAX0+PT2L3bv3U6tWXTTN6JRzFmV7Uz7d1/TtCvqBUla9+CK8+aarSyGcaeNGNe3SpWj7VawILVqoMdP/8x8V5Pfv7/DilRp6kN46Z0W5plmGjaoyCOFEfrFg9IGsFEiMo0qV2rk2Kckgvag16TnpQXqeNemnF8Maq/eUwR20TLi20xykX78O//yTu++5o4P07dv1RG9KQf8Dc92A2DPJEqCHtFHBecI+yw5a9sFjRhSpXBM/aoK22Bdj1lVI2I9XYH1AatKFa7k0SO/SpQualne2zFmzZuVaVrduXclUKG46mqb6bS5dqn7E3n23/e127FDTKlVKPkAH1XTb07Pkz2NPRoaJpUsP07dv7VLZV0zTnH9jwFU3TPRpSor6MTNjBrz6av4/OkX5smuXmjZtWvR9ly6FkSPht9/Ue6c8B+k7d6pp8+Y5VlzbBUnHwegN4d2dXq6bmpsRAuvDla0Qv4fYWOcG6YWpSc8ZgCcmWgLXAoP0i+st8xWqQ2hbODYbEvbh53c7AHv3GkhOthQgOlrd8E9KUs/dUV2aczbVL1JNeso52P9edgHvgBYfqdrzDdk/iIJbwpUtENoOYoYXqVzevh6qi8mFP2H/+9B8Cnj4m4P0CxfU/zdptCucSX5CCVGKXbkC334Ln3+OOdsowAMPwMMPw8cfw9GjKklcjRrQtq1an6uvo3A6vV/+zRSoZmRAeDicP6/6GOvvR1H+6UF6o0ZF37dSJdXU/bffVF/Qa9cgKMiRpSs9zmaP4lQ1Z0+dC9nZ5Cp1AfebZMD40iSwoQrSr+2mevXbc612dZ90Pz8YMMDS/PrcOahZU7XYKrBPevweNQ1tB7fMgJM/Zy/fh5+fmr1wQTVzb9hQY8oUA9Wrq98UoD6PYWE39NRy0Wukw8Lg4sUi9knf84aqOQ9uAR3mqn7nMcPBOwzSrkDVuyD1gnpsuIFkd3WeUkF63Ffq7/ZzBAVVpkIFVY7Vq1WiSyGcxYk5mIUQhaFpsHYtjBih+naOG6cCdOs7uOnp8Mknavrss6oJ2c8/w7x5ar0E6cIVPDxUX1tQ70lxc7hwQd2YAdXS50Y0aqT2TU+Hn35yXNlKE5NJBVegbmbZuLJVTUPaOLVMIpu5X/puYmNzr3ZGc/f8aqsNBli0yBI4nzmjpnpmdyhEkN50EgTUUTckAM4uI8jzlM2mtWtrdO8O1atbmtg7ssm7HqTXrKmmRapJ11sE1H/RNggP7w7VhqgXyafyjQXoANG3QY2HLY9PL8ZgsHxWH3vsxg4rxI2SIF2IUuLyZZgyBerXh06d4Lvv1D+wJk1g2jRVA9MzR7LSdetUX06dnl05V39HIZxEb+4sQfrNQ8/MXq9ePsmrCmAwwH33qfm337btt1peXLliqZGtXDnnyi1qGtzCqWUS2YKyA9f43Xbfw65u7q7Tg/RDh9RUD2Ld3Ow0xdZMcHUnJB1T/dD1LPYRvaBiU0i7TL1r99rsUrOmpQuq3mXOkUH6KjU6GvqIyYUO0n0zLDcbgps5rkA5tZxquYlxZgmghrQF9RstZw/dtDTbcd+FcCQJ0oVwIU1TY+bec4+qNX/6adi/XzVtGzVKJRn69181FEhgIIwda7t/t25w/Hju4+oZk4VwtiZN1FSC9JtDZibcdZeaL+7NwccfV7WBhw7ZZoAuL/Sm7qGhOXJ5JJ3MDkAMECo16S6hB2YJByErne++U/9v9ZEKXJ04Tlc7u7u8PjxcQoKaVqiQY2jPxKMwPxyWZX8hVxkIntlRt9ELOv4MBjf8k/8iIuiMeTfrFh6ODtIXLLD0SS9MkJ6RYVkfaNgPpnRw9we/GMcUyB6jF7T9Ws2fWwlZaeabh8nJKjmvtYcegqgolahXCEeTIF0IF7h4Ed59F+rWVdmQv/9eNfNs1gw+/VQ1ZfviC9Vs3fofb79+sGULzJ1rezwvL8t8SIgK6IVwBb0mfdeu8lkbKmz9/rtKqATQsWPxjuXvDw2zYyXrMarLizybuuvjPYe1V2OkC+fzrQIeASrrecJ+7rkHPvwQvL3V6pLsk16UmvQ6ddT04EE11WvUq1XLseHJBZB20fLYuhk3qARyQU0B6Fh3rXlxQEDJ1aSvW2eZ79pVTdPT895er0UH8Ev6U82EtL7x5uyFVbEpeIdDZiJsfgJfr1RzjozTpy2bZWXB7NnqObz/fskWSdycJEgXwklMJtXUa9gwdef1uefUP9oKFeCRR1TwvW0bPPpo/sOttGihaq70Pl2gAv1ly1QyopdeKvGnIkSeatZUY6WnpFh+QIry5c03VbCwerWli01AgKW5enHoNYV6EFKenMru/ptrHHl9SKnowU4tj7BiMKgAEODQJ+bFeuBcWmrS9f/7eo10ngkbL22wzAc1gvAeuQ9WqRMAnev+ZV5kfYPfOkgfMEDdhCvOjdejR9V06lTLefKrSdeDdE9PcL+YPapThJ3n4WgGN6iX3cb9yAzYP4WoKPXQOkjfv98yf+1ayRdL3HwkSBfCQdauVTXfP/9suzw5WfWxrFNHNU+fM0f9U27ZUmVtP3MGPvtMBd9FYZ0duFEj6N1bNX3/v/8r/nMR4kYZjZYfjPqQgKL8OHxY3Qg8eBDuvdcSpL/1Vh41gZqGn+ksbv+Og6sFvyH0msLyWJO+L3s459rWI3ylXYaLa9R8ldxZxYUTNci+w33sezCpaNQZQXpRatJDQ9VUDwrtBumpF1RTbYCOC6DHBjXMXE7ZQXqnumvMi+wF6Tt2wK+/qprw4tx4PXJETatXt7T+K0yQHhSQAedXqwfhPfPewZHqPQtN3lTzF9baDdL1TPsg/+tEyZAgXQgHmTBB1YbfeaflxxiofpYvvKB+3Pr7qwyhW7eqZEsPP5xPRtYCREdb5m9k2CMhSookjyu/9MRPoG4wLl+u5tu3z7GhpsGGEbjP96dryhiMh6fBsqaw8xXISs3z+OW5Jl3/v1C/vtXC86tVgq/A+lAhxhXFErqwjqrJe2YixKvoVw+cXT0Em04PovUg/d9/1VTPBQLA/g8gIx6CmkBUf/DII5tjWAcAGkbvIbjC5ezjW5q76028f//dsou9HDiFkZ5uuaFQ2CBdH/+9U4O/1TXxCoOKTfLewdEq36qmV7cSFaVeFz1I1zT44APLpqdO5U4qJ0RxSZAuhAOcP6+afupef11Nv/lG/YHq33bmDEyfDs2bF/+cVapY5m+5pfjHE8JR9B+MUrtQ/hw7lntZnTo5bhQe+wF+9IBj32EwpeOGVRvZ3RNhcW1IPp3rOPqxQNWkl7cfvXv3qmm9elYL9RpPe82RhXO5GSEk+5/pRdVcXA+cS0tNuh44Jyaq0QL0JtfmYVdTL8LBj9V8gxfBLZ/I3zsMKqh08Y2r7gRsu9rpNenWgbleG15UEyeqLn9BQRATYwnS09Pz/pzrNelta2Y33a/cpeT7o1sLagwGI6ReoHl1dYdBD9LPn7cMOwnqZoMjs+ALARKkC+EQeiI3PcnbggWqJkgfV7NhQ3jyyRsfnsieu+9WwflXX+VoPimEi+k16Vu2lOyPW+F89oL0l16ySnAZvx82jQJNBeamqNv422s8GYPjoenbapvkk7CoOlzbletYNWqoY8XHqwSb5UVKiqVPrk1N+uV/1DS76bFwseDsO+jXbGvSXT1Ous66ObpeMRAba2kGz7anIfM6eAarWvQCD6jGh29YZXeu4+tBurUbDdIXLFDTSZNUMj7rZLd5JY/Tg/S6Edmp04Ma39jJb5S7r7kLSvcqHwCWIF1v6VO9ukrWC5bRG4RwFAnShXCARYvU9L33VMCckqJqhFJS1D+khQtzDI/iAPXrw8aN8OCDjj2uEMXVrJn60XjxIsya5erSCEey19x1xIjsGVMWbLwXspKhQk24/QxZ7eZy3r01GH2g/nPQ9Q9w81TDKa27CzKu2xzLx8eSqbo89UvXWwYEB0NYWPbCrDSIzx5rTsZHLx2yg1YSVLMHZ/ZJL0xzd09Py3joevNx8016TYOz2W3TW04Fd7+CD5g9Pry9IF0PPq3prUGK4uxZ1dXDYIAhQ9Qy6yA9rybvepBeMyw7SNevjTPVUePe1vD8GS+PVM5kj1anfzfVqQMREWpeXyeEo0iQLkQxmUxqPHNQw4r07Wu7ftkydbdViJuFtzeMH6/mJ0ywbRYoyja9Jn30aBXAmJMnaRr81R+ubFUBeffV4BOR+wDhXeG20+ATBQkH4J9HcrV3bZD9W7w85TSYn53AvX5961YHe8CUocav9q2a577CifRAMH4PaJpT+6QXpiYdLIG0/lk013gn7FPDrhl9IPqOwh0s++bQ4FbzCfK9alMGe79b1qwp+g0LvUl+rVrqJhWomw26vIL069fBYDBRLSg7mUNgffsblqSw9uAThQcJdKyz1lyT/ld2Qvw6dSyjNUiQLhxNgnQhiungQUhIUHe3GzSwjP8Jqhloly4uK5oQLvP446oZ5tmzMuJAeXDmjPqe03+ITpgAqanQX29Re/Y39QfQ8mM17nRevEOhw1wwuMPxHyHuC5vVrbNHwtJvfpZ1Fy/Ca6+peZv+6Fe2qWnF5o5vaiVuTEBd1Q857TIkn3Bqn3SbmnRTBqy9A7Y8mWv7PIP0C9mRY2hbMHrl3M2+qIEcu1qPsIBLfP7wYzar7HWjS0y0JKsrLL0ZuPXQg25ulpsS+dWkh/lfxMs9BTCAX2zRTuwIBjcIawdAk6o7OH9etZycPVutHj5cgnRRciRIF6KYfsv+Xdq6tfon26ePClA+/dSSQK5YNE0lsfn7IZVw6ei3cHoJXN6i/pELUQp5e8Mn2cMNr1pV/pKA3SwuXYKhQyEqypKg0sdHdWdw039BZCarGnGAOuOgRiH64IS1g6aT1PzWcZBuybqkB+kbNpSP983GjZb5MWOsVlzNjnaCHZBJVDiGu4+6aQJwYa3r+qRfWAMn56skcNcP22yvJ4/TcxyYg/Tz2UF6pS6FP7mbO8F9vgJgcMv5Nt1PAgOhcmXLpvqIMkXN8H7unJpG5GhYozd5T062Xa7ftEhMhKqhJ9QDnwgweuIS2X3hW9XaiabBoEFq8e23q+8q/XlJn3ThaBKkC1FMP/6opnfeqabu7jBtGjz6aDEPnHIe9r4DS+rDivZwZAZcPwQb71PNSn9vBb/WhZSz6pfsqUWw7304u0L9s9ZMxSyAEMXTpYsaN/38eTh50tWlETfiu+8siTH1IcRiYqwqfjUNdv4Xkk+BXww0fq3wB6/7NAQ2hKwUODHPvLhdO3WT58iR8tHkXW8R8OCD0Ng695V1TbooPfQkfhddFKSbMuDscssGi2tB6iXzQ70m/UR2/GoO0q9sVdOwnOMh5i+gels0vxoY3TIxXPzTZp31UK/6qB1FrTHWg9fwcNvltWqp6ebNlmXvvacyzK9cmR2kh2Q/SVd2BwlSQ1e0qW3bhODt7DyYUpMuSooE6UIUICkJvv5a1ZjnrNVJSlIZrAEGDnTAyUyZcGoxrLkdfqkC25+HhP1g9IWYEeoOucGqTVziEVgQCT+4wZpB8O8zsLon/NEFVveB43Ph9K9wbhVc+ltlrL0epwL79HipiRclysdHJZEDGDwY1q51bXluVrNmqR/b8+YVuGku9n54xsRYPdjxEux/X803/G/eYzLbY3CD6iPV/NFvzIsDAqBfPzW/cGGRilsq6TXp5mGyQH3XX8seo1Bq0kuXSh3V9MJacxP0kuyTnqu5+7q7YN/bthtdtHx56jXpuooVUTflk7OruP1rFrkMpoheALjtfVO9N7N16GDZpoYara3AYPTwYdWtY1J2Qxk9SM9Zk969u5r+8Ydl2fPPq4S7PXqoPunmIN2vWlGejmNlD8sXE7SbyoGqWcC990LN7JdZgnRRUgqRS1KIm5fJpBLBrVmjHr/9Njz3nGX9v/9CVpb652N9x7nIEg7CkZlw9GsVQOtC2kCNh6DaUPDIHsD06g7151EBNo6EzETbY3kEQEYCnFuu/gpicFdDjRh9VTZY87ydqbtf3uvy29/NS/pc3qSmTFFdQLZuhW7dVFPJnD/WRMn65BM4dUplVk5PL3yCKlDN3XPSs68TNwP2Zv8Sb/YuVH+g6IWrdjdsfwEuroeLGyGsLQC33go//1z2+6WnpMD69WreJj9JwgHVgsC9wg0FVaIEhWVHpgn7CPa7CIQ5ryY9Kw1O2bkzdWULRKvhwKwzsEN20J5yVt10N7iDT2Su3QtiqvsCpsOz8Li6VbXc86wIrT9j/Phq/PyzatatB6MFNevu3Rvi4lTy0BdftDR3z1mTrg/VaT2sY3i4Jdi9fBnah2bfePArzg+sYvKprBLsXdnK7S0X8Okfj1OpkmW1NHcXJUWCdCHysX27JUAH+PBDePZZS7y5PDsGbtXqBmLQzCQ48RPEfWVzlxyvUIi9D6o/CEF2hhyp2ET9AYR1Ullos1LUDwu9FmvvZNXkPStZ9Re1mSapqd4cXstUQX1GQhGfQBEY3AoI7n3BmCPAt3cDwHqd5oGP6YLKZmsIVBltDdI4qLTp0EF9hpo3Vz9G586Fp55ydaluLpcvW+ZPnLDUiBWGPlZ5nTqWYYeaNgWSTqi+5KCauNd75sYK5xsJVYfC8R9g86PQZwcYDDbJ4zSt7N7jW7NGJcaKilKvoZneNLliM/neKm28QlQT52u7aFp5OXCP8xLHxe+xXVl1KJyYo7qxBbeCyN4EBnrbbFKxIpB0TD3wjQa3G/hp7xPBbs8HaJb+CVzOvjO2MIawW77m6NH7MBpV1xdQQfTJk1Cliv3PZVycZV7TLN8bNi1wsGR4t35trVsrnjoF9Tpn97Hxt/7wuEDMPXBlK/+9/TV+3DiMypUtg8hb16SX5e8qUfpIkC5EPlauVNPu3VVT3dOnVTb3OnXUD98PP1Trhw8v5AE1Tf0DjPtKZTXOzE7SYnCDiN6q1jyyf+ETpHiHgnfn3Mvrv6D+8iuHKd0SvOcM4DPtBffJkJVk+zivGwD6Y705vWZSNf45a/2LwQPoCbDIaqHRJ/9a/htpIWBzA8Hnxn4A3eSaNYN331U3uFatkiDdmbKybPMBHDlyY0F6ly6WH9sdmxyEP/qo76/QdlD/xeIVsuVUOLVAdce5vBlCW9O4sfqxe/myymmQsxaurNBzlgwYkOPH+6lf1DSsQ85dRGkQNQCu7aJF5YWUdJBuU5N+5GvLilafqv7xJ+bAlc2w9naI6E1Q0FLA8maqWBFIzM4iVyHmhstxwr07TUKO4nZ2qWXh9ucxVr8PsNQY//EHVK0KL79sGbVAl5DjXv+BAyrYdnOzdH3S5QzSNQ2uXLGsP3nSMn67S8ZIt1brcTL2Tiey4iFeuu0NQsLeNa/Sv5vS09X3pXUtuxDFIb82hcjHr7+q6YAB6h/JX3+pjMN16sAHH6h/SE2bqmak+Uq9CMe+U8G59Z3yCjVUJuTY+/IfssjRDAY1RIvRSzVrKymmDFXLbx3E2w3+C1qX+waAlpmMKT0RI+mW82WlqD8u51mkYnPzLGKQfwNdBNw8yt3teD1h1sGDri3HzcJkUtmf16617U975EjRjqMH6T16wGefgZdHKvUuDFD5MPxiod234GYsXmG9QqDKberG5cmfIbQ1Xl4QFgYXLqjmsmUxSM/KsvSpt7mRm34NzixR8zGFvcMrnCq8B+x5k5gAldXMGX3SPQyJcGiaetDmK/XbQNPAK0y1GAM4+xvVKh4ELDXLsbHAsb3qgX+tGy+IwUBW+wW4uWXA1qfU75XU83BhLVTqaDOEGqjRa8aNg5AQy7KcCUIXLFDT+vWhQo50FXq3m/Tsf+GJibbDsSVevUZUcHbbd1eMkW7N6I2hyWuwaRi9G//GNqMlSPfyUvlXUlJUNvxLl2xfEyFulATpQuTh5En1A9dgUEmvDh5UQboeZOg/vp57zmooImvp1+DYbPVPN2G/pXm50Qei71T/gCt1Kt9NHd081J/en96BMjMyWLp0KX379MLDLavIQX6h1+lTstvhmdLVX8Y1hz8nM4Ox+HkAClpn9HbqjQB9zN24OPWj1F3++zhMSgrs3q265+zYoaY7d6rESzk99phKeuTnV7hj633SGzVSTc+rJH2B4cxBNSRSr7/B20HVRlEDVZB+ejE0fQsMBiIiVJB+9qyl/2pZsn07XL2qEuG1a2e14uR89R0S2MCcOVqUMtk1t8Fex/HxTGbFCl9eeaVkTqXXJPuajqnuZx4BlmEMDQZo8BJsG2fePjbgH/QgPTY2u0+6noSwYtPiFcZgUP832nyp+rcf/gx2TYRuK3MF6QCHDtkGpHrGed1f2aPC1bcTY+esSddvCOra1lIZF1PdY/D2zNER3wXco7oB0DB6D8lVLgCW776KFdX3MMD8+fDwwy4ooCh35GeSEHnQxz9v1071vdL7Ex44AG+8Abt2qcc9euTYMfEIHPpMDZmWZpV1KbhldhK44VAK/uGUGwYjuHurHxYlRdMgK7UYQX5hWhAkWeUJyFJNiTPtRFkOYyggR0BBNwDyuIHgEagSF+W4ARAdbaltOHbMkhlXFM25c7bB+I4d6jvJZGfERS8vaNBADZ0UFaVqvgC2bYOOHW231TSV3K9GDcuQTpcvW5qvVq5wnNrp38Kxd9SCBi87LkAHiOytbmAm7IOzv0Nkb8LD1fPTE0+VNatXq2nnzjluSunDa1W9y+llEoXkFQqewbilX6FW+CE2bGhSYi069CDVK1Nvsp7jy7HuUypp3K4JcGQWkV7/ACMAqybkV7eraVBTxxWs/n/g8Odw/g9IPEpAQGyuTa5etX2cM0jXR7+xlyw0Z016ziC9V6PfAUgN6oFtL3wX8Q4lybMpfunbaV1lKXC/eVVgoCXhXc7s+0LcKAnShciD3h9dD8L1msADByxD6tStq5pkmqVegOXtITX7V6V/LahQXfVvqz3aKeUWJcBgAHcf9edVQu3YNC27e4AjbwDYyxOgdw/QsvdNgrR8S1Z0DSdA41dsFrm5QfXqsGePanItQXr+MjPVd411ML59u6pZticsTNU2N2limdapY5vJffFidZzTp3Pv/+qr8MorajSLJdktsX/6SU2bNYPAvSPhQna1mE+U6qLjSJ4VoeajcOADOPwpRPYu81mTN21S0w45u53HZ/ezDW6FKKUMBgioC5c20KDKHnaeaMLhw44P0jXN0sTbx3RMzdjrV+5XFULbw5FZBBotfVaaNUP97kg5Axgc2zKjQgxUvhXOr4ITP2Go/1yuTXIG6TlvqOlJK+29bjlr0vXEdLpejVWQ7hbVq4gFLzl+dW6DXdth+38grCP4qwQf1jdJc2bfF+JGSZAuhB0ffKCyUAP0yv7/0LChmu7da9lOH1oHULWgG0aoAD2gDtR9RmUEdfd1RpFFWWcwqISBRk/wDCq585gyrfIEJOWTJLAQNwByJRJMgvQrsPct1dc2wDYjb1SUCtJlPFlb8fGqebp1ML57t23/TJ2bm7phmDMgDw/Pp/dCRiIkHaVevUbs2JH79U9Px9yUd+lSS4ZiffziB4acsATovlWh409FGw+9sGo8qIL0M8sgPZ7wcPVrt6zWpOvDx+mZ6gHISlfDr4E0dS/tQlrDpQ0MbP0nP2y42+7NreLKzLQEeF4Zx9SMX+4aa0B1MQG8sXwgmjdHDckKaig/R38uowerIH3781CxCWEBTbmYYGlBY53oDdR3mT0F1aQvWwYff2x12pAT1IvaT2aWEd/YbsV8Eg5U/QE4+Inqq7+qG/T8G3zCbXIW2O3+KMQNkCBdiBwuX4ZnskcT6twZ2rRR81FRcMst8Pff6nHTphAcbLXjgalqXHKjD3Sc7/pEJ0LY4+YObv7g4e/4Y2sarOqhmkduHAk9N9pEjlFRaloSP3bLAk1T48TnbK5+9Kj97StUUAn3mja1BOMNG4JvYe77aSYVWB+ZpYZ6zErm896V2LhyE6dPx5CQADNmqDGNczYzPXlS3aicN0897lvzY0hH1ap1W3VjT74wAhuq7834vXDqF6KiRprLU9ZcvWpp+tu8udWKhP3Z/Y4DnZssVBRdeHc48AHdGiwHNE6fdnwOD+sbcR5J29VMQG37G3tXBsAzyxKkN2uGyvwOxe+Pbk+VQbBljJpf3YsL0+HWN1bx595bgdw16XqQXru2bZLQgmrS9e6DAI88At7HVca5TXFtaO8b5IAn4iB+VaHvDljRQXVtXNEB+u4kK8vypVySSQbFzUWCdCFyWL3acmd7zhzb2qn/+z8YOlTN33OP1U7x+2H3RDXf/H0J0MXNyWCAtt/A4lpweROcWwkRlqQNN1OQnpqqWt1s324JxnfsyLumKTo6d+149eo3UCuTeEQN43T0a0g6brPK3+MCbw4dz6LT33PHHapLzyuvwB132B6iWjXLfPva64jNyB5rss7/FbEwRWQwQNVhsOt/cPxHatZUQfqhQyV72pKgZ9EPD1eJ48z0pu5BDcvdCA7lTuUu4O5HmO9xOtZdy+nTnRx+itRUNXU3ZuB2JbsGIK9h+XxUpGvMvECH9iZCQt2IOD8e9k5S60ui+4RvFWj4P9j9qnnR/Jee4bUt25gyJe8gvUED2yC9oJr0pCQ1/8QTarQc/3VqKLrZ6++hvaOei6P4REDnxbCkASTGweV/yMzsYl6dleW6oonyRYJ0IXLQm3iOHauG07A2ZIiq3bp6Fe6+O3th4hFY2RHSr0LFZlBjlFPLK0Sp4hupmi0f/BiOzLwpgvQLF2xrxnfsgH377P9Y8/BQP2CtA/LGjXO0yimqjOuqtvzoLLiwxupkgVBtGMSOhD2vw5ml3N3uB/749l7mrOwLqB/VM2bYP+xtLRfw45hhuGnpENkfovoXo5CFVG2oCtLPraBei0tAKIcPq9fSWMyR3pxJbx0Rm7Pl8rXsKsNAaepe6rn7qUSvcV8y9JY5jHm/E8HB8NJLjjuFHqS3rLEdQ1YyeAarvvD2eKlm5gYtk7Urr4B3KHw/ybI+5m77+xVX44lQ6wk4vRD+eZSK/EvV8CtAcJ7N3Rs1sgy/BuqGI6C6W8V9Bf418fRUzdgzMixBuq8vdG53HU7/C8DP/9zBtJJ5VsUTWF91BTg5Hy5vtgnSpSZdOIoE6ULkoAfp3bvbX9+3r9UDTYNNo1QW94rN4dbfVXNiIW5msfepIP3kz3BtDwSp4YzKepCelaVqdXMmc8srsVlIiCUQ14PyunUtzTyLxU5zdsUAET0h9n7VVNXdRy3u+DPMUfNfjejHxQsLWbxtoM0hH34YvvgC2tbawOPdpzO87Q+4G7Ogyu2qhYQzan4DaqubnVf/JVr7GS+vR0lLU90EzD/0ywC9Jj1XmfUgXfqjlw0RPSHuS9rV2gDAyy+XTJDepf46NRPWPu9hWY2eKnFp2mWV+8Y71DKGerXh4BvluILl5FMZaj4C+9+HhAM0CFkF3JlnTXqLFuDvr4aBbNfOaoz07S+oYwD+DX8DepGUBO+9p1b7+WHuY3/ychUG3JWjpqQ0CW6lgvQrW3j/fUvFjdSkC0eRaEKIbJqmhgs5dEjV2HTuXIidjsyC86tVP/QOc9U/TSFudsEtVc3rmV9hx3jovBAoW0F6crJtU/Xt21W/SX0sXGsGg8pWn7O5elRUCcS11+Pg6De5m7MH1FGBeey99vs6G72h6WT1IxlY9MwgHvxmGbOW90bTYMQIuK3PBQYEPMSA5r+ad8sKH4ixwzxwc2I1drVhcPVf3E7+SKNGj7JlC8yeDf/9r/OKUFx2a9I1Da5kj0lVEv2HheOFtgWgcdWd+HklkpTm2MRsepDevrZVkJ4fv1gVpK/qDgOPWIbpbPKGQ8uVp8h+kHCANj7/Be7g6lXbLzg9SA8KgnXrYOJEeO217JXn/lCJIbMFHXseg6EHmma5KeHnB1xSN0RCazXj08dL7JkUX0h294IrWxg+XH0/xcVJTbpwHAnShUAlTurVC/5VLazo2DFHP0J7MhJgx3/UfKOJ5qE4hLjpGQzQ/F04swROL1I3sirfag7Sz59XTRythwcrTa5dUzXe58/nXufrq5qnWwfjjRpZ1RSVhIzrcGKeuil4ca1lud6cvfr9ENKm4DsC9Z/n1S/78r+WqhZ3xn19mP5QLKd8nqC632oMZ5dCdpKzX7YMwr/+YLp1Ge7cAB2g6hB1M+HCX7z8zFluGx7Bu++q/qohJTQCoqPpQ0/ZdJlKOq6yQrt5qNYCovTzrUKGezgemeeoF7WPLUdakZmZY9z7YtATx9UJ36dmglvkv0ONB9WNntTzqkY6KzvK9wrLfz9HafgyHPyEANN+akcc5MoV2xE89CA9MFB9T/78c/aKS3/Dn31VCyDvypB6Ho/EnSx8ehAjpn9LfHIQAP6+qbB3MgA+1XuX7ihFv1aJRyDtMtWqhRAXJzXpwnFkoAAhgKlTLQE65EgKl5fdr6vxSf1rQ52nSqxsQpRJAXWg5sNqfsMISLtCWJj6catppXtYrZUrVYDu56e6t4wfr5JIHjgACQmwcSN8+ik89hi0bVtCAbpmgnOrYMN9MD8cNj2UHaAbIKIXtPsBbj8LrT+F0FsKXWVfp01DGv1nJ6v3dgHAK+MoNRKeUwE6kOoeyx9ua/Hv9wvdRt2nAkpnqxCTXYOpMaDpzzRtql73L75wflFulHWwYnYxu7Y0qImlG4Io/SrUAqBWuMpgqPefdgS9Jj08MLt5kU8BGf+rPwSG7Mj1ZHanb6OP6j/vDJ4VIVQNedOp7po8m7vnGit872QwpUPlbtB/H9Qei4aBAc1/ZcH/3Q5oAERW2K+G8fSsqJrXl2aeQeCv3hvs/J85Z8aCBTByJLRsqZLiCXGjJEgXAti2TU0feADefx/uv7+AHU7/CvunqPnmU1RfMSGErebvq5tYKadhyxjc3CxZfqtWhVUlOJpXceh5KR56CJYsgTfeUEkja9d2QvKy63Gw83+wMFaNw3vsW9XfPKAONJkEt52AW3+DmGE3FOj17g0Jhka8vnE12oCjUHsMVO4Koe2g2nC8B2yk27AOdHP10MRRAwBwu/gXo0erRd9/78LyFFFCgpratMg6vUhNI3o6vTzixrlXtA3Sr1933LFTU8HPKxF/7+w3TEH9yo2e0C37C+pq9g8XrzDnjhRQqQsAz/V7h6SEVPPi9HTLTQebIF3TLDeoGr+qAvCWH5LReQ3JaT7cWv9Pejf5DYAw7+yhHPzrlI38PvVfVNO4r/DzUnlB5s2Db76BrVthzZp89hWiABKkC4FljM7771fDrOXblG3v2/DXADXWbfQdENU3n42FuIm5+0G779T8ibmQdsXc5B2gWzfV7L202ZLdbbhjRyedMOM6xM2AFZ1gcU3Y/Rokn1DN2Ws+qsab77cPGvyn2GNrBwbCsWOwYgUY/GOg5VT1o7/nemj/vUoQVRrow1BdXMftt6latl27cg/5VFrlCtJNmXBGBSJEDXJJmcSNMQSoIL1m5cOA44P0yIpn1AP3CuDhX/BOwS0ttekA3k5q6q6r/SQmz0rUjjhElzq/mQPza9csm9jcnLp+SCXXNXqrsmdzj+jAzDUPAHB3O3UHLthDD9JrleATcKDq96vvZFMaTSNX51qtac4vkig/JEgXN72EBDhxQs03Kijh7tkV5sRL1BoN7WaXaNmEKPNCWqlM1loWHP6Uxo1tVy9f7ppi5UXTLOP71qtXkifKozm7wa1YzdkLw2C4gfHXnS2kFbh5Quo5QryOULWqWqzfUC3tcgXpV7apJF+eFSGkZZ77iVLI37Ym/fHHbccAL47UVIgK1pu6RxZuJ3dfqNgkV/mcxjsUQ/Zwb4NaLOTiRbVYH44tKChHi6P4PWoa2NCm1aGbGyzadjsAIzp8x+0t5xNk2K1WBtQuwSfgQAaDSpIK3NfkJQwGk81qae4uiqO0/5sWosQdO6amoaFQsWI+G6bHw9/qri+1HodWH4PRq6SLJ0TZVyO7b+GOl3h3zGwGDLCs+vFH1xQpL+fPqwBLz9jucNcPw47/2mnOXheavgWDitecvdywrnW7uM58A7XMBukX/lTTSp3yHmJLlE7+6ougVmUVpP/1F9Spk98OhZeaCpFB2TXphQ3SQXVP0VXu6pjCFIEhWrUGGdB8MbExmcyebQnSg4NzbHxdrx3PHXiv2tuNOX8PAWD26HuonPKDWlGpMMPrlBKNJoDBSGzQDqqFHrdZZd26QIiikv8U4qan16LrNTV52vGS6lvrXwuavVPi5RKi3Kg9GuqMA8D/+BssWqjx++9q1ebNriuWPXoNWUwMeDnqHlxGAsR9BSs6wuJasOd1q+bsj0HPv6HfXqj/QsmOdVzW6E3eL6wxB+l79riuOIVlMlmaRJuD9PN/qmlZCj6Ekh2kh/hfoaLfFfPiuLjiHzotDUL9L6kH3pUKv2Pt0WrMdDcviOhd/IIUVVgHriYHE+p/mXa1N3DvvWqYSrAXpGd/qdqpHc/MNPDwl19wJbEiPp56Fr0eUMlZfY0cwCdctRIAGkXb3kWUIF0UhwTp4qZXqCD90j9waJqab/2Z8zKpClEeGAzQ6BVVO5qwD65uo359terw4dLVJPDAATUtdk2ZZlLjAm8Ykd2cfZRKnmRwUz+q2/8Ig89B6+kqW7IzEz+VFXoN4dnfqVlTde48csSF5SmkxERLX9SAAFR/dH3ovOykW6IMcfcz13LrTd5BNXsvbp/j1FQIqZA9Xp9XEcYXDKgD/fZDv93gF128QtwIN3c2HusHqCbvAE8+qVbZBOlZ6XBRjXueV7P86ykBjJj+LclpPpgMXqpFUVkTpO4iSpAuHEmCdHHTKzBIN2XC5kcBDWJGQOVbnVU0IcoPz0CIGqjmj35LVBT4+6sxZQ8dyn9XZ9Jr0mvfaJdIc3P2GFjVHY59B1kpOZqzL4NqQ9VNC5G3yp3V8FIpp2lYRfVV/ftvyMx0cbkKoDd19/AAb2/UjanMRHD3h6DG+e4rSqmKTQEYcstc86IVK2DWrOIdNjUVgitk18575qyCLoB3qLmW3xV2XVNN3gc2V6MWmLK7Y9sE6TteVO9/jyA1/Foelm7vR8Tos1xoexyCm5dQiUtQkKpJ17+ndC+/DMnJriiQKA8kSBc3vb171TQ6r5vRcV/C1e0q4U/zd51VLCHKn9gRanr8Bwxapjkx24YNaizyf/5xfW3yDdWk223OflKasxeX0RvCVLPXmgF/AWocZn1IttLKuj+6wQBcy26jH9QQ3Ep6DD9RImo9AcDdbVUW8ltuUYuffhrOnr3xw95wTXop0Pv+HmSZ3KgVfpgIvV89Vrl9zvwG+99X821nFThyxOhxgYTHlJLRJYoq0H5NOsCUKc4ujCgvJEgXN7VDh+DXX9V89+52NtBMsO89Nd/olaL1GRNC2Iropcb0Tb0AZ5ebm7w/8ghMmgQdOrhz9qyvS4tY6Jp0zQTnVsKGe+00Z+8D7edIc3ZHyO6bWjFzrXnR55+7qjCFozdxNY8Vbc5u3cAVxRGOENYegIiK5/DzSmTSJGjRQl3r4jR7t61JL1tBepOWAWT4qZYh7WuvNy8316Tvfk1Na4+BKvkPO1ipErz5ZkmU0kn0mvToPTTMEajv3++KAonyQIJ0cVNbtUr9c731Vmja1M4GZ5ZC4mHVVKv6g04unRDljJsHVBum5o99a3eIs9WrC8rgWLJOnVLTatXy2CDhEOx4Obs5ew84NtuqOftkGHQSbl0K1YZIc3ZHyE4e53b5b5pnt4L1K+UpQS5cUNNK+j3d+OwmsBKkl12eQaQbVPQZW+ko4eEwYwa4u8PChTB3bgH75yEtzbomvYjN3UsB7yrq5sXH94+hSbXtANQP3wL/PAaXNqjx3BuML/A4IWXr/kRuvtGkZ6nv+1Xju/LAA5a7NmUh2aUonSRIFzclTYMnnoDHHlOP27XLY8ODH6tpzVHgUcEpZROiXNObvJ9aSMN6qblW//13hJMLZJGUpP4AKlu3ukyPh8NfwooO8Gtt2PNGdnP2IDUcY89N2c3ZnwffIgyjJApWsZmaJp9gwY8qC3ZWVvETdpWk8+fVtFIlVEEvb1ILglu4rEyi+Az+1QGoUSmOSpWgcWPVTQdU0rRLl4p+zLJckw6Yb6JVDrzA9jebETelOncHt4LDn6n1jSaAT8Hf6WU+SDcYWHN+DABhAZcYe99uxqiHHDxYur+vROklQbq4KR0+DNOnWx63amVno6QTcHa5mq/5mFPKJUS5F9xS/WjLSqFtrQ34Zrduf/11NT150t/cp9fZ9BpQb2/w98uyNGdfEAH/PAwX1+dozn4WWk2D0NbSnL2keAaas0KHGf8FVGCj30wpjWxq0pNPQcpZMBglSC/jPIJqAPDcYwfNTbpfegkaNICLF+Gpp4p+zNRUzTIEWxmsSde7AeiqVzqKhgGqDoHOi6HBS4U6TJkP0oFfT73D0u19AAgzread7JF6k5Lg6lUXFkyUWRKki5vSypWW+WbNoFcvOxsdmQloahgg/xrOKpoQ5ZvBAJVVAoiKKb9x5IhK3jh+PFSrpqFpBrZtc03AqwdXVaOSMfzWOEdz9nrSnN1VglsC4H19jcqWjgqKSiu9Jr1yZSxDrwU1BnfX5lsQxRSi3ofta6w2L/L0VM3e3dzg++8tOW4KK9DtMAE+18nUvMAvxoGFdRK/aKg6lO0nmrNo6wCW7+6Noftf0GEORPUv8OZl4+zBDh5+2AllLWHu7rDjRBMAfDIP4O1t6fKijyIkRFFIkC5uOpoGX32l5u+6CzZuxPzDz8ax2Wpa4yGnlU2Im0KVAWp6Yh6VK2nUq6d+y7VoodoEbt3qmiBdD676Nl8N8XvB6GvVnH2PNGd3lYieABjOLiMsTC0qC0F6pUqoDNcA4T1cVh7hIBHZd/Mv/AlZlq46rVurLO+gutDFxxf+kLEV1qlDZrYCo5eDCupkHX5kvf9W3t+6iGojl5mTPRbG2rWweTP061eC5XMSoxH2n6kLgHeayhanD+37wQcuKlQBtm2DTz6B9HRXl0TY49Igfc2aNQwYMIDIyEgMBgO//PJLvtv/+eefGAyGXH/nzp1zToFFubBtG2zdqpIPffIJeNn7v5h0Aq4fUk0UI8vBfw8hSpPIfuBeAZKOweV/zIsbNVJB+u7drq1J71RnlZqJuVuas5cGEb3V9MpWaldVEXCHDtCxY+kcM/3/27vv+Kqr+4/jr3uz956QhL1XEAciewlKHf1pVayj2mrrQuqiViutu1q1lro6cM+6xYGyUUBGkKHMsANhhSxIbpLv74+Te5OQBJKQ3Htz834+Hnmc77rf+7mcm3A/9yzn+ygp0YJ9ld22Us/1XEDSPKL6mNUpyo/BoVU1Tk2fDl26wO7dcOedDb9lWri5z37rrOaM1O1uugnmzWvk0pWYZQoHDWqRkNzO378qSQ86tg6sCtdydC+/DIcOeTC4elxxBdx8s+lNeqz2FDHiYR5N0ouKiujfvz8zZsxo1OM2bNhATk6O6ycxUctiScMtX27KIUNwtcrUsvsTU8adYcZEikjz8Q+tWpLH2WMF6NPHs0n6qsrP3YPaf2M2kkZ7JA45TkgyxJip3SdmfgmAwwGLFpmhEt7GOYFY+9gdlePR/SHuTM8GJafOZoP4wWb7wLc1ToWGVvXQe+kls3JMQ8QHbwPgqL+G1LV2fn6wdlcf8o9G4OfYB9vf4pJLqs5v2eK52OqyYwds2GC2582D117zaDhSB48m6RMmTODBBx/koosuatTjEhMTSU5Odv3Y7eq1Lw3n/CCemVnPBZYFG54x2+m/cEtMIm1OhytNueXfJpGhKkn/6Sf3t5AWF5sP2XHhB0iLWG0OJo10bxBSv9SJAAzvOqvG4d27PRHMiTkniUoNXGI2YvprPLqvcE6UlvNFrVPDhpk10wGuv75hkxvGh24HwBFQ35qP0lr4+UFxSRj/+KpyWvecL/n1r6smJt661XOx1WXBgpr7a9d6Jg6pn7+nA2iKAQMGUFJSQp8+fXjggQcYMmRIvdeWlJRQUlLi2s+vnDbY4XDgcDjqfIzzeH3npfWpXqcrV/oBdvr2LcPhqL0uhu3QCvwLNmH5hVGWcZVpshGvo9/TVi5+FH4xg7AfXk75tnep6PJb2rd3EBxs49gxf3780UGPHu4LZ/NmKCkJ4JKz5gNgRfamzD9Wv/+nqLl+T22JY/Ff9yC9Yr/Cz15GeYX5+LJpUzljxlSccpzN6fBhf8BGVIXptlUefRoVPvQ+atN/e1MvxD/rHmx7v8aalUlF/BCsyh9CUvjLX+DTT/3Jzrbxhz+U88QTJ35vJoWbJL3Ev51H/z3bdJ02k/JyO+DHym2m10/FkZ8odzjo1s2P77+3s3lzOQ6H+/5WnaxON2408Tpt3lyBw1HujtDatMb8jrWqJD0lJYXnn3+eQYMGUVJSwr/+9S9GjBjB0qVLGThwYJ2PeeSRR5g+fXqt41999RWhoSf+Znv27NnNErd4jyeeWMX335svdY4cmcesWbW/6u5d8h+6AHvoz/KvFtQ6L95Fv6etV7fSbvRkOXt/eJvlG01LUlraMDZtiuHVV7MYMmSP22JZvToBOJvB3cxETtuL27F61qwTP0ga7JR/T61yJhBBiP0wZ3ZZyrcbzd/xOXOyychY1wwRNo/SUjvHjpmJEYtzFhBrg3W7IHuf772X2urf3gH+o8go+wZbXhZ+eVmw2QzZLLQlU+TXk2ennMldT1zDs892JTX1O3r0qHv9LX+riPOCzCxzS9fup8g/210voV5ttU6bw8aN3YEebMzpBkDZoXV8/tlnlJX1AHowf/5O+vRZzbp1ceTmhjJy5E63xFVfnX777QAgg969D7BuXTxr1hQya9bcOq+V5lNcXNzga1tVkt69e3e6V5uV4uyzz2bLli089dRTvPrqq3U+Ztq0aUx1TruJaUlPS0tj3LhxREZG1vkYh8PB7NmzGTt2LAEBAc37IsQjHA4HH388lz/9qarXxXXXDafWSInSPPw/M91wkwbfxcSUiW6MUhpDv6etn+1AFMx9g1RrJROHdsER3JGMjP1s2hRDQMBAJk4c4LZYDhww4+AHdzNd3dsP+DntOur3/1Q15++p35IJsPMdJvT/3JWkHznSiYkTvaersHMeW5vNol34ASiCXoMvoWficM8G1oz0t3cijuJd2A5+i23/YuwHFsORNYRbewkv20t68lwueOJR9ufHk7XnHIZmnI1/yhCs6AFgr/r3sh1cBnMg53Ayg4cOZ+jQ2j373EV1euq+/958oNy0tysWNgIpYuLIfuw/kM7bb4Pdns7Eie248ELz73vZZf1cK5q0hJPV6d//blrRL7gghnXr4MCBCCZMmKg5UluYs0d3Q7SqJL0uZ5xxBosWLar3fFBQEEF1TN8dEBBw0j9EDblGWo+lS5Nd2126QFBQHXW7Zw6UFUJkd/zTfqYZnVsB/Z62YsnDIGEotv0LCdj0FAx8jowM8x/Y+vV+BAT4neQGzeeLLyA44Ci9kpYC4J84GPS+ajbN8nva/nzY+Q7XjJ3Ffe8+CMCCBXYOHLCTktIMQTaDwkJTpiQcxVZkWkb94/r55HupTf/tjepofjpNNvulR8xkcvsXwf5FWAeWkhB5gLGRH8L6D2E9ZknH+LMg4RyzTNlh84Vg1o4BxJ3u7xVvkTZdp6fI+XHxmCME4s6Cg98R8ONDpKebGQX37LHj71/VMrRhgz9ntdCk/vn58PXXNvLzg+qt052VDfnDh/vx8MNQXGyjoCCAuLiWiUmMxvx+tfoZ17Kyskjxlv+dxatt3Bjj2n7jjXou2vO5KdtNUoIu0tJsduj3F7O9410oOUB6uknS16xxXxjr1sF778GYPl8T5FcMoWlmuSXxLpXrVLcPW8Wxwzn07w8VFbB0qYfjqsY5adzArhsAC4LizLJd4tsCoyB1AvR/CMbMx3bJEeYFLuauNx/jk5WTKLPHQHkx7JsDa/8Mc8bCqjsAyNo+gOBgD8cvp8yq1ihuG/iE2dj6XzrFmhnZdu2qucxZI3o9N9q118LPf+7PfffVPWeXZZnZ3QG6dq1a6cgbJ+JsyzyapBcWFpKVlUVWVhYA2dnZZGVlsaPynTNt2jSuuuoq1/VPP/00H330EZs3b2bt2rVMmTKFOXPmcNNNN3kifGllDhwIAeC556pm26zBqqiasTVFa9qKuEXiUIjqDY587GsfcLWkb93asNmRm4OzM9avhv/HbLS/SF/SeaPgRIg1iyoHHZpNNzP0k2zPD+V1cSbp/TtUjpOP6q33UlvkF8SI/zub7OC7+NmTH3PGYwdwjFsLpz8PHSZDWNUQja/XjlGS7gMqqs8Jl3B25edIi1S7GRN++DDs21d1SUFBy8Xi/D9t166IOuc+3b8fSkrMn6Z27cwP1E7S16+HKVO8629sW+LRJH358uVkZmaSWbkW1tSpU8nMzOT+++8HICcnx5WwA5SWlvL73/+evn37Mnz4cFavXs3XX3/N6NFay1ZObv9+k6Snp9dzQd4PcGwf+IeZ7mgi0vJsdsj8KwD2PZ8QHVVCQoJlVkLc4J4QVq+G+Ij9XDDoI3Og643ueWJpvKRRpsydT6dOZtObljZyJum92lUu4B7Zy3PBiMf94x8QGwursuz89cXe0PUGOPs1uGAbXLCD0+5fw5x1o5Wk+wDr+OHllcv1hRxdToj5+MmPP1adrp6wN7fAwKrtPXXMv+pMrVJSzLX1Jel/+AM88wz06QPlmvjd7TyapI8YMQLLsmr9zJw5E4CZM2cyb9481/V33XUXmzdv5ujRoxw8eJC5c+cycqTWsZWG2b/fzOZfb5Lu7OqeNAr8as9jICItJGkU+IViO5ZDdMUWMjLMp52d7pn8lqwsGNp9IXabZVo+o3q654ml8ZwTsOUucCXp3tTKs74yN++fZpZfI6af54IRj0tKMkkOwPTpNZM0KzSNlVvMsJo6pk6SVqZWkl7Z68d2aLkrCf7pp6rTr71W9feiueXlVW3v3Fm7J48zSXd+Hq4rSS8rg48qv7cuLoacnOaPU06s1Y9JF2mIggIoLDRfLZ40SU+d4J6gRMTwC4L2PwOgk+Nj0tLM4WodqVpMRQX88AMM72nWR8eHZuH2SQlDTO+Lws30SDdNRN7Ukr5sGfjZy+ga8505EF/3mFBpOyZPhokTobQUrruuqkWyejdktaS3fvUl6RRspFOaWWpv06aq07m50Lt388fhcFRNYAl1/z9aX5LubHW3LDM0tDqNV3c/JenSJji/AQwPt6hz5b2CzWZWVoAUJekibtfzLgDaly8is+sWwD1J+pYtZuz72L5fmwNK0r1bYBREDwCge4z5YiU7u44PyB6wahV88w30S/+BQFshBESZnhnSptls8PzzEBEB330Hzz5rjlefRExJeutXY0w6QHA8hHUA4KxuK4CaSXpLqd6KDrBjR+2WdGcvNecX4s4Z3Q8dMuXs2XDrrTUfoyTd/ZSkS5uwf7/5I5WUVM8FW18GLJOgh3dwV1gi4hSbSUXSOGxUcGHXRwD3JOlZWdAudlflGGIbJI9p+SeVU1P5RUq8NR+73SQ7zvXJPenFF0151fiFZiNhCNjdt4ygeK+0NPirmXqDe+81vT+qJ+nVxxBL61TnF4WVrenO4S9ff93ycRyfpG/eXDtJP3DAlImJpoyONqVzTo1vvql9XyXp7qckXdqE/ftNGR9fT3NL7jxTpv/cLfGISG0Vve8DoHfoKyRG7mPLlpZ/zqwsGNvHzL5L3OkQFNvyTyqnJskk6X4H5rtagryhy7szhguGVPbK0gSkUs2vfw0jRpjxvb/+NRw9ao4HBWkBAF9QZ5IeZ5L07vHL631cWVnzxuFMtJ02bqx9jTORdybnMTE1H1t9KMYvf2lKJenu59/YB+Tl5fHBBx+wcOFCtm/fTnFxMQkJCWRmZjJ+/HjOPvvslohT5JQ4W9IT6lqutuwoHFxmttXVVcRjrLgzOWzvSkzFJi4b/BYvzr+N8nLwa8HGyNWrYXLfr8xO5Trc4uUShgI2yP+Jwf22s317Bhs3whAPD/82SbpFasAiqEBJutRgt8O//gV9+8KcOfDAA+a4szVTWrcTtaSnhX5f7+OOHYPw8OaL4/gkfdOm2t8AOa9xJufHJ+nOIaJ/+5uZS6H6MXGfBrek79mzh+uvv56UlBQefPBBjh49yoABAxg9ejTt27dn7ty5jB07ll69evH222+3ZMwijeZsSa/zP8Pc+VBRCiHtILyzW+MSkZp2+o8A4Ophr3LsGC3emr7pxwLOz/zU7KSc27JPJs0jKNb1heqvRr4C1J7kyN3Ky2H7duictIWgir1gDzQ9M0Sq6dwZHnrIbFcuZET37h4LR5pRrTHpALGnATYi/bbRKbHu/8yqD3toDgcPmvL00ysq922uY04nS9Kdw4dSUiAqymy35LruUrcGJ+mZmZnExsayYsUKtmzZwptvvsmTTz7Jgw8+yD//+U8WLFjAgQMHuO+++3j66ad54oknWjJukUY5YXf36rO6q8+ZiEft9h+KZfNnYIcVdEnaxFdfmdmRFyyAzZvh5z83ky81h+3bYUjau0SEFFIe3gPiBzfPjaXldZgMwPDuX2Ozwfffm9mSPWXLFtNFdFiPb82B2EHgp9nApLZbb4Wzzqra79bNc7FI80lOruNgYLTry9+bxppvEj/5pOYlzmEPzcU5OV3v3hAXZ25+fJf345N0Z7f3I0fMlw3OVvPk5KpW/uozxot7NDhJX79+PY8//ji9evWq95qQkBAuv/xyvvvuO6699tpmCVCkOTi7u9fZkp6jpddEvEWpLRIrYSgA4/p9xS23wBtvwPDhcNll8P77MHZs84zj++YbOG/AZwD4dbxMX9K1JvFnAhBYuIouXUyL0Zo1ngvnf/8z5cSzs8yGc/klkeP4+cG//101WZySdN9w221m/PZ77x13osv1ANz684/ZvBnOP79mot7cLenOhLxbN4vUVJNZb9hQ85r6WtItC/btg127zP7JknRvWFXDlzU4SY9zzs/fQteLtKR6W9ILtkDBJrD5a1ZnES9hJY4CYEzvmlPhrjCr2FBUBJ9/furPs3RxIWP7Vk4alzrx1G8o7hPZ07RUlxUw9qzNgGeT9A8+MOXgnj+YjZj+ngtGvF6vXmY1gCFD4JJLPB2NNIeQEHjlFdPbq4bkMWDzx//oJjpXdnk///yq1YaauyXdmZB37WrRrp3JrKu3pJeWmskLoaoFPSjIxA/w5JPm/9j0dOjSpSpJP767e3k5nH66mWPBOW5dmlejJ45z2rNnD4sWLSI3N5eK4wZi3Hr84noiHpabW09LurOre8IQCKhrAXURcTcraTSsvY/RfefiZy+jvKL2f1VvvQWTJp3a82SU/YfIkAIK7V0Jjz3t1G4m7mX3h+j+cHApI/qt5J9081iSfuiQ8wski+Tg1eAAovt5JhhpNa6+2vyIjwuIhLgz4MC3cOA7iDBzHwVXjoZp7pZ05zwuXbpUtaRXX5+9+sRyzvHmALGxZgb32ZXfW//qV+DvX39L+qpVVV+cr15tEnZpXk1K0mfOnMkNN9xAYGAgcXFx2Kp1EbTZbErSxes414Ss1ZKuru4iXseKyYSAaCLJ4/RO37Nkc9VY8U6dzCzaK1c27d5Ll5oPH+Hh8MiYD83zdbkJbFqRtNWJHQgHl9Kv/UrgMo8l6XfeacZxDh20Fz/HAfNeiurtmWBExPvEDjJJ+qEV0PFKoGWS9GPHqpZXS02F+HjTTF99+TRnkh4VVXPllKQkc90PlZ2BMjJMGRFhyuOT9OprqX//vZL0ltCkTyX33Xcf999/P0eOHGHbtm1kZ2e7frZ6w2KlItVUVFQl6TVa0ksOwV5nV9fz3B6XiNTD5gepZrKdef96kdJS+PFHmDoV3nnHXLJjR9PGwz3yCKxfD2uyihnSbTEAEd30JV2rFDMQgPahZg3idevqmWG5BW3aBP/9r9l+7J7VZiOiG/iHuDcQEfFezp5a++aAZf5IObuXN2d3d+fQzoAA05U9NtZ8A1A9SXde41qS+Mh6KDlYa+K71FRTnqgl3WnZslMOXerQpCS9uLiYyy67DLtdLQ/i/Q4fhvJy09sjPr7aiV0fQIXDdJmM7uOZ4ESkbt2nABCU8zoBjt306GHGyvWubKAsLjbdjOtjWTXHyZWVmVmVP/rI7F846EOCAkoppCNEdG2Z1yAtK8EsjB5atJAOSXsoLnauVe4+zzxj3mvnnVdtPHq0xqOLSDXJY8AvFPJ+gKy7gZZpSd+3z5SJiWYe1Lg4c/M9e6q+wHRek5QE7PgffNYb5k8iJaXmvdq1M6UzST92rOaErdX/1ipJbxlNyrKvu+463n333eaORaRFOJflCQsrdc2mak4sNGW7UxzYKiLNL/5MSBhqvkjb8i/X4eDgqgl3duyo/+FjxkBaGiw3jazMmgXPPmu2L/hZBS9MeQqA8L7XaFb31iqqJ8Sfjc0q46bzTRcLd3Z5P3y4qhX99tuB/YvMTuxA9wUhIt4vNBVOn2G2f3wCCre1SEu68/Ous9doTMwxbDaLsrKqFvQa13x/o9k58B23nXYpvdqtc93r+CQdaramV0/Sf/rJLN8mzatJSfojjzzC/PnzGTFiBLfccgtTp06t8SPiTZx/mKKijpt+8kDlYstaG1nEO3X8pSn31pzlPS3NlPUl6Xl5MGeO+TDinCJl6VJTxsXBe3/6ExGO5eAfAV1uaP64xX0qZ+U/p+cSwL1J+ksvmR4d/frBqBFlsG+eOaGVQkTkeJ2ugaSRZnv9o66W9Hnzmu8pnAm484tsf3/LlbA7u7w7W9J7pO+AkgOux/aNepfXb5qMzVZBeHjVpHJBQab7PFQl6fn5cPCg2Y6NNb2JnGPZpfk0OUn/8ssv2bdvH2vWrGHVqlWun6ysrGYOUeTUbNtmytjYal9XlhyEgso1KeLPcntMItIAyaNNeXCpmUOiUnq6KetL0teurdreuNF8gHB2x/vrQ3n4b3zM7Jz2DIQkNXPQ4laV66X3SDAVXL3uW5LDUdUzY8oUsB36HsoKIDAWYga4JwgRaV16VDZkbn6BgalmTqQXXjCzozeH6t3dnZzd2PfuNaUzkT8749Najx+QsZpfnPU2AwbU7GB2/Lh05+fquDjIzKx5TJpPk5L0J598kv/85z/8+OOPzJs3j7lz57p+5syZ09wxipwS5/qQzvUiAThgWl2I7AFBse4PSkROLqyjSXgqHLD+UdfhkyXp1VtTDx6EnJyqbu+jun1s7hfVCzpf2zJxi/vEmimFo/2ziY/Y77aW9P/9D3btMh+GL7+cqt4eyaO1UoCI1K3d+dDtFgB+0f0PgJn99O9/P7XbvvwyXHtt1VJr7dtXnUtKMs/hTM737YOQwGKGxj9hDgx8Gi7cxdGM2wF48JI/kpRQs+epM0nPz6+6B5jJ5ZyzwG/ffmqvQWpr0v8kQUFBDBkypLljEWkRdSfp35pSXd1FvJfNBn2nm+0t/wJHAVB/km5ZUFICr7xS8/g775gu8MHBkMZ75mDaJS0Xt7hPYJT5shU4o/MyNm1q/nWHj2dZ8JSZ0oDf/a5yAqjcueZA0uiWfXIRad363Ad+wfRtt5yfn/E/ALKzT+2W11wDM2fCv/9d+RTV5kJ2zuLuTKxzcuD2CU8R5ZcNIanQ5XoIbUfImX/h8NEkOidt5Y1L2kP2q66Z6KOjzWOdy7tVb7F3JulqSW9+TUrSb7vtNp519vMS8XIbNpgyNbWo6qDGo4u0DqnnQWgalB6GxVcA9Sfpl11mEqYlSyAwECZVzgl5u2kgYNzQ3dj3fWl20pWk+4w40+V9RJ+llJeb5fpa0nffmeETQUHw298CFeVwsLKrRsLZLfvkItK6BSe4WtNnXHMTdlu5a5ngpqhr4rm+fau2ExNrtqTv3AkXDfqg8sLp4B9mtv3DCB76DwACrf3w3VUw73zY/SkJcWZad+eKKtVniFdLestpUpK+bNkyXn75ZTp16sSkSZO4+OKLa/yIeIuKiqruP66W9IoyOFg5QFVJuoh3s/vB4JdNF+I9n8KBZa4kvfqHgrKyqjXUAbp3r0rOAcKCCnnu8guhohTizzbd3cU3VI5LH97HzA7Y0l3ena3okydXjv0s2GDGo/uHQaTeVyJyEv3+guUfSVJULoO7fuea4Lgp6mrB7t69ats5Pn3fPjOXRkVxDoM6rTAH251f43Eh3f4PRs+DnneAPRByPof5k7jqzKeBqiS9+gzxStJbTpOS9OjoaC6++GKGDx9OfHw8UVFRNX5EvMWuXeZbxoAAi8TEYnMwbw2UFUFApD6oi7QGSSOhQ+VM7+sfpUsXs5mTUzXD7ObNNR/SvTsMHVq1f9f5j5MatBwCY+CMF7Xsmi+pbEnvk7IUm62CmTNrrufbnLZtg/ffN9tTplQe3Fs5F0/s6eZLJRGRE/ELwpY6HoB//fp6jhwuxbKadqvqS6EBvPGGmY3dtusDzi26iqvajSLAr5TcXDPD+/UjXgLAij8bQpJr3zBpOGT+FQZXjRs7r+s/sNkqarWkV0/Sd+yoWotdmod/Ux70X+fCoCJezjkevVMn8POr/AuYO9+UCedogh+R1qLXXZD9Muz6gJgO79K16yVs2mQmhBs/vnbraffu4O9vlmsrzd/LnZOeNCfOeAmie7s/fmk50X3BL4RQjtA/fTVz52Zy0UXw8cfN/13Ms8+aD6JjxlTrUrr7Y1NWLgcnInJSfR/A2v0ZPVI3MLrXlxw5Msk19rsxtmypuX/ZZYBl4bf+L/iTT4p9AfueS+Lq1xayY0cfrjj7DQBsXX934htn/AKiesOsfsSHbGdUrzkcOmSWl6y+1Fv79mC3m/lgcnMhuY68X5pGGYr4NGeS3rVrta8oc+eZMnG42+MRkSaK6gU97zTbS67lvOGm+eDbyjkgj0/SzzjDlB9/cJTZ0ycTElBsWlzTNCTL59gDzNwFwK9HmlaiTz+t3cJ0qgoK4F//MtuuoRQHl8Nes5QS7S9o3icUEd8V1Qtbl98AcMmZ7za5y/u6dVXb3btXfjF5eCW2I1XrUcaE5fHedQPpnp1Jj9QNlFf41erqXqfoPlCZzN8w+gUOHzYt9Z9/bk5nZJhW+9RUs68u782rwUn6ueeey5IlS056XUFBAY899hgzZsw4pcBEmsOuXabMyKhM0q0KyF1gthNHeCQmEWmi/g9D4jAoK2LqsFsBiz//GZ58ErKyqi774x/h/PMBRz4DDk+gb8Ic8AuFM19SN3df1fk6AP7v7M9dh5r7A+N//mOWIOreHc49FzPN+6o7zMkOV0Jkt+Z9QhHxbe3Ml4tDuy9k7tym3cL5BfWdd1Z9ac0W0+N5j99gygf8jY25fQn0d5AUkAXA5vxhZmWMhuh6AwCXnPkewxMeZ/LkqlPDhplS49JbRoOT9EsuuYSf//zn9OrVi7vvvpt3332XxYsXs2LFCr7++mv+/ve/c+mll5KSksLKlSuZ5JxWV8SDcnJM6ep+c+QHM0u0fzjEDvRYXCLSBHZ/OP0FsAeQ5vcZ/3eW6WZ8xx3wySfmkm++gb/8BeyUwdwJZnhLQCSM/MJ0ixbflHA2YCMxbBu/+NleoPbs/6eivByeecZsT5liuney+xPz/rIHQf+Hmu/JRKRtiDuDCstOx8RtvPfKnkY/3LJgbWWD+VVXQWws4MiHbDOefFvAeCq63syne/5W43ELyt5s+JNE9+WQbRAAk7o+gXNt97/8xbSig5L0ltLgJP26665j69at/OEPf2D9+vX85je/YejQoZx++umMHz+el156ifT0dL7//nvefvtt0p3T74p40F7zWY3kZPNHxe5sRU8Yaj7wi0jrEtUDevwegJdvu53+/cprnO7bF7OCw+eZcOBbM0Pt6DmQOLSOm4nPCIg0XTOBob1Mr7/mTNI//tisZRwbaz4MU+GArLvMyR63Q5g+84hIIwVEcizYfHncPvi7Rj9882YzDCcoqNqM7ltnQlkBVkR39tv7A+CIGc63GwdTcDScXzz7Fu27JjXqeX5qZz47x4Xtp2e7H0lJMT3WnDp0MKWS9ObVqDHpQUFBXHnllXzyySccPnyYw4cPs2fPHo4dO8aaNWt44okn6NmzZ0vFKtJox7ek2/ZXThqXNMIj8YhIM+jzRwiIJrQim+WffsN5pscgv/89JMRbsOoucI7H6/8IxJ7muVjFfeLOAmBAe5Okf/GFmcyoOTiXXbvhBggNBTa/BPkbICgeet3TPE8iIm1ORdzZAPRLXdzoGd6dPcgGDoQAfwtW/t78ABVdb3YN7+rQKYAh078l8voC3lnyC/r0adzzdOgSwjdrRwEwvu+XHN8Oq5b0lnFKE8dFRUWRnJxMgLO/g4iXcbakJyVZYFnYDiw2BzRpnEjr5R8GHczAOP+10/jkza3s2gVP3PcjrP0zbKjMqM76L/Sc6sFAxa3iBwPQPc60SH33HfzsZ6d+2xUrYOFCs1rATTcBpUdgzZ/Myb7TGz62U0TkOIEpJkn/vzPeoeBQXoMft3ev+WIaKidKPbwSfvobWGUQ3Y+KjCtd13bqVPW4zp3NqieNkZwMH2eZSVevGvoKGek111pTkt4yNLu7+KyyMlyzZaakQKi1D1vpIdP9NSbTs8GJyKnpdTf4hZhZbD/tSrtVPeGzXrDmgcrz06DTNZ6MUNwt3rSkx9m+56ILzULpq1ef+m2drei/+AW0awesfxRKDkBkd+jy61N/AhFpswI7TCA3P4H2sbspX/9Mgx9X/W/btdcCe7+uvGEsjFtivsyu1LWr+ZIRYMKExsdot8P3+y6luCSEzA5ZTBt+pRlWVsmZpG/b1vh7S/2UpIvP2rvXrGfr7w/x8RBdUbmYZHRf8Av0bHAicmrC0mDkVxAz0KzakP+TOR7SDjKfhH5/8Wx84n6R3SEgGlv5UWY8+AMAeXmndsvdu+Htt8327bcDRTvgp8qsfcDjZvk3EZGmCorjkc8fAyB437s0tM/77t2mPPdc6N/Pgh3vmgN9p4N/SI1ro6Nh7lx48UUz4VtTJKYl8Nv/PgfAgJg3YfOLrnPt2pmyoACKipp2f6lNSbr4LGe3m7Q08PODqIrKRXM1PlXENySeA+OXQZ/7ze/1WS/DRbtMF3e7n6ejE3ez2SH+TACiHWZoU0kJHDvW9FvOmGF6ZZ1zDpx2GrD6XqgoMUOm2mkVGxE5dUt3X8TR0mBCSte5Zma//Xbo1g3efbfuxziT9NO7rYWPO8OhFeAXDBmX1Xn9OefAr39tEvam+POf4atNV/PkvKfNgeU3Qc5sAMLDIaTye4Hc3KbdX2pTki4+yzmzr3OCC1eSHqOl10R8ht0P+k2Hc5dDp6s8HY14WtJoAIJ3v4TNZlqkjhxp2q2Ki+GFF8z27bdjPgRve80cyHzCNSmTiMipCAiL5rmvf2t2llyL44cnefppi02b4B//qPsx339vymv73gJF2aZ7+8CnITi+RWLs1880ft0+47cQkmoOLrwISo9gs0Fiojm0b1+LPH2bpCTdS5WXmzf6nsYvmyiVaiTplkV0uTNJ13h0ERGf1OV68AvFdmQN5/TOApre5f3VV+HQIejYES74mQUr7zAnOlwJcYOaJVwRkdhY+MM7D/P64isAi4C1d3DVUNOiXlf38cWLzczuI3vNoWPoPDPX0nnroOsNLRpnYCDYAwLhnHfMgbIi2PISAEmVq7opSW8+DU7SY2JiiI2NbdCPnLoXXzSzKd58s6cjaV3ee890bf/ww+OS9GN7COIIls3PjEkXERHfExjjWmJzfP9vgKYl6RUV8PTTZvvWW8Fv7yeQOw/sQdD/oeaIVEQEgKuvhhJHMFc//zJHEy4BYOqEv2GzVbBiBSxdWvP6lSvBz17G45ffZQ50uQHCMtwXcMIQOPNfZnvDM1DhcLWkq7t78/Fv6IVPO/+3ErdQt5GmucT8beOii2DkSLPduTPYDmeZnYgetSbUEBERH5I8BvbMYniPb4A7mpSkf/kl/PQTRETAr65xwKLKD8M9boew9BM/WESkES680MyftHOnP+vCnqdf7hf0z/iB2feMZfI/X+ess5JrzCd38CD889rfMajTCiy/EGy9p7k/6A6TzRwdxbtg+zskJpplUZW3NJ8GJ+lXX311S8Yhx9E3UqduzRpT9u0LtrxVAFgxA9AoQhERH5Y8BoDT0hYQ6F9CXl5Qo2/hXHbt+ushMvclyN8AQfHQ657mjFREBDC9PnfuhNOHxDLl3Ok89cupjO4zh79fdSu/ePadGtcWHC7il+e8CoDttGcgJMX9AfsFQ7eb4Yf7YM0DtEv5PyCInBz3h+KrmjwmfcuWLfzxj3/k8ssvJ7cyk/z8889Zt25dswXXlmlsR+MdPFhz/8ABM69Pr15VLelWtMaji4j4tKg+EJxESEAxZ3VZwt13N+7ha9fC7NlmbeDbfncE1vzJnOj7AARGNXu4IiIB1VZz/MfsmzlaGgzA6N5m2E71lvR2fl8REniMvLJO0Pl6d4ZZU/fbIDgRCjdzTpe5AGzYYE4VFJg5PaTpmpSkz58/n759+7J06VLef/99CgsLAVi9ejV/+tOfmjXAtsrZkl5QAEePejaW1uK++2of69kTQkPBlrcaMC3pIiLiw2w2V2v6mD5fs3174z4sOkf3XXQRZBQ+BiUHzBrsXX7T/LGKiGA+qzqVlQcQd8NBysr9iIs4RNfkjRQXV53vG/0hALvtF3p2lYmACEgeC0DPpGUArF9v5vQYMAAyMuDbbz0XXmvXpCT9nnvu4cEHH2T27NkEBga6jo8aNYolS5Y0W3BtWVSUmUUR1OW9oVauNOVvf1t17PzzgZKD2IrNoulWdH/3ByYiIu5VmaSP6/sVANnZDXtYbi68VrnK2t237IANlf3eBzwO9oD6HygicgqeeAKGDDHzYVx6Kdx+Rygrt5klg5//1Y1VS0mWl3BGu08AOBJxoWeCrS72dACSA8yacDk5sHo1bN0KhYVw772eDK51a1KSvmbNGi666KJaxxMTEzlw4MApByXUWHOwQwdYtsyj4bQKzi8zrrwS7r4bunWrnB2/sqt7oS0ZAtRVUUTE56WMB2yc2WUZHRKy2bq1YQ97/nkoKYHTT4dBAfdC+TFIHA7tJrVouCLStvXsCYsWwbhx8Pbb8NBDsDrALJI+qvdcivabxiZ2f0xUyGF2HWqHPfFsD0ZcKf4sAAIOLyStfRkA71QbQv/dd+oR3FRNStKjo6PJqWNmgFWrVtGuXbtTDkqMlGrzQNxxh+fiaC327zdlYiI8+qgZF5OWBhw2k8YdsXfyXHAiIuI+ISmQPBqAK85+o0FJekkJ/POfZvvPU1Zg21bZpJ75hGe7lIpIm/Tre85gafYwAAL2fgAV5Vhr/gLAzAXXEJ/g58nwjNhBEBgLjiP8apxp4a+epJeUwPffeyi2Vq5JSfpll13G3Xffzd69e7HZbFRUVLB48WLuuOMOrrrqquaOsc2q3lmhqMhzcbQGR4+abjUACQnHnTxk+sEfsXd0b1AiIuI5HcySQFcOeY0tW6yTXAxvvmkma23f3mJcwh1V94gb1JJRiojUa96WiwGIOvI/yJ6J7cgaDhXG8MK8qXT0ho+1dj9IMzHeOfw6YsIO1fpSdPNmD8TlA5qUpD/88MP06NGDtLQ0CgsL6dWrF8OGDePss8/mj3/8Y3PH2GbdfjsMqvxssGNHzZkdpSZnK3pgIERGHnfS1ZLe2b1BiYiI56RdTDkB9Gz3E4d3nnhQumVVLbv21B2fYt8/D+xB0P/hlo9TRKQe3+eYBDimbBEsNTO5/+WD++jUMxY/L2hIB2Dg3yCqF2H+h7ll/LOA6Xw0qXKUUEOHG0lNTUrSAwMDeemll9iyZQuffvopr732Gj/99BOvvvoqfl7zjmn9goNh/nzw8zPLiU2f7umIvJdzPHpi4nG9EsuKzPq2wBE/dXcXEWkzAiI5FmomNUq05p3wi+65c+GHHyAywsFFHe40B3vcDmHpbghURKRuJf5pLN18hmv/YElH/vn178j0phWFAyKg+xQAJp0xn4wMuPNOGDrUnFaS3jRNStIXLVoEQHp6OhMnTuTSSy+la9eujb7PggULmDRpEqmpqdhsNj788MMGP3bx4sX4+/szYMCARj9vaxIaaiZAA5OkaymDujlb0mt1dT+8GrCwglMosUW7OSoREfGk4PThAJzRYT7bt9d/nbMV/YU7X8KvaAMExUOve9wQoYhI/eLi4N/zrjM7MQN5bOksSsuCSE31bFy1VE4gN6jjcrZtLeexx6BTZdtYQ1fXkJqalKSPGjWKjh078oc//IH169c3+cmLioro378/M2bMaNTj8vLyuOqqqxg9enSTn7s1mTixaluzvNetekt6DZVd3a0Yb/rKUURE3MEvZQQAw3vO57PP6r5m40b49FOIDDnC/3X/kznY9wEI1GogIuJZZ50F/5p3PTd+sAzGfcua7T2AOhqlPC2yF/iHQVkBHFkL4Bozr5b0pmlSkr5nzx5+//vfM3/+fPr06cOAAQP461//yq5duxp1nwkTJvDggw/WuZzbidx4441cccUVDB48uFGPa62qrzG4dq3n4vBm9bekVybpWh9dRKTtiT+bCsuPDgnb+eydbCoqal/yzDOmfOn2x/AvOwCR3aHLb9wbp4hIHUaPBsuy85+PTicnN6j+z7ueZveDxBFmO+cLoKolPTe3anJnaTj/pjwoPj6em2++mZtvvpns7GzeeOMNXn75ZaZNm8awYcOYM2dOc8fp8t///petW7fy2muv8eCDD570+pKSEkpKSlz7+fn5ADgcDhwOR52PcR6v77y7hYfDm2/auPxyf7KyKnA4yj0dktfJybEDfsTHl+NwVH0K8z+4AhtQFtEX8J46lVPnbb+ncupUp77H83UaREXMUILy5jEo7lVmzfoD48dbOBxmvpe8PJg505+0uJ38vLfp817W92GscqBc78O6eL5OpbmpTr1XRgacdZYfS5bYeeKJcvbvtwM2YmLKcDjqn2jDE3VqTxqP357PsDb/m7JONxEWFkRMjD+HD9vYtMlBnz5uC8VrNaY+mpSkV9exY0fuuece+vfvz3333cf8+fNP9Zb12rRpE/fccw8LFy7E379hoT/yyCNMr2PGta+++orQ0NATPnb27NlNirMlHD4cBoxhzRqLTz75HD8/TfVe3apVmUA6Bw9uYNasTQDYLAfnF6/FBsxfUwD2UK+qU2keqlPfozr1PZ6s0/ZlmZzGPK465xX+/M7P2bNnN3feOZxOnY7Qt+8Biot78erv7sKPYxyw92bxKjtkzfJYvK2Ffk99j+rUOw0dmsqSJafz7rtF5OaGAv6sWTOXAweKT/pYd9apvxXLaFs0wYWb2PLJr9kQeBmxscM5fDia995byY4de90Wi7cqLj55nTmdUpK+ePFiXn/9dd577z2OHTvGBRdcwCOPPHIqt6xXeXk5V1xxBdOnT6ebcya1Bpg2bRpTp0517efn55OWlsa4ceOIrLVWl+FwOJg9ezZjx44lICDglGNvDhUVcOedFkVFfjgcEwkNhdGjlag7vfCCWVVg6NBuTJxYOYlhXhb22WVYATGcM24ys7/+2qvqVE6NN/6eyqlRnfoer6jTsmE4/vdPuiRvoVNsKYsWjSE/305WViJZWYlkdljJxZlvAxA98l9MjD3NM3G2El5Rp9KsVKfe7cwz4YknLHburMpbLrlkRO0lh6vxVJ3adgJLrqS7NYvO5/6HV14JYssWiIsbxMSJdYw3amOcPboboklJ+rRp03jrrbfYs2cPY8eO5ZlnnuGCCy44acv0qSgoKGD58uWsWrWKm2++GYCKigosy8Lf35+vvvqKUaNG1XpcUFAQQUFBtY4HBASc9E3bkGvcqW9fWLIELrvMVNsTT8Dvf+/hoLyEc4xOSoo/rirLXwOALXYAAYGBgPfVqZw61anvUZ36Ho/WaUAMO5hAOh+SXPACD735fLWTFs9eW/kfaYfJ+Ced5ZEQWyP9nvoe1al3Sk6G3r2r5qUKDobY2ICaSw7Xw+112uEyWHETNscRAorW0769+dJz/34/AgK0THdj6qJJE8ctWLCAO++8k927d/Ppp59y+eWXt2iCDhAZGcmaNWvIyspy/dx44410796drKwszjzzzBZ9fm/Qr1/N/eefr/u6tsg5u3uNiTQqJ40jZqDb4xEREe+RlzQFgF+PfIkxvT93HT8/81OGdJkH9iDo/7BnghMROYnqOcCll9KgBN0j7H6QULlA+t45JCebzZwcz4XUWjWpJX3x4sXN8uSFhYVs3rzZtZ+dnU1WVhaxsbGkp6czbdo0du/ezSuvvILdbqfPcTMOJCYmEhwcXOu4r+p/3ATl1ebDa9PKy2HPHrPdvn21E64kXcuviYi0Ze0GDudf91zH9SP/zdu3/IKXti3miRd78OSVd5oLetwOYemeDVJEpB7t2lVt33WX5+JokNRzYc+nsPN/pKSYv7F7NRy90ZrUkg7w6quvMmTIEFJTU9m+fTsATz/9NB999FGD77F8+XIyMzPJzDRJ1NSpU8nMzOT+++8HICcnhx07djQ1RJ9zfJK+dy9YGpbO3r1QVgb+/ri+saOiHA5nme1YJekiIm1ZXBwM+u0/mbNuJJEhBUzpM4Lsf4+mW/IGCIqHXvd4OkQRkXpNmGDKuDjT9d2rpf0cbHY4uJTOCT8BaklviiYl6c899xxTp05l4sSJ5OXlUV5ulgSLjo7m6aefbvB9RowYgWVZtX5mzpwJwMyZM5k3b169j3/ggQfIyspqyktolY7v7u5wwMGDnonFmzi/x2nXziypA0DhZigrAr8QiOjusdhERMQ7DBgYSOql71EQeCZ+5YcIzl9oTvR9AAKjPBqbiMiJjBwJn38Oq1d7OpIGCEmG1PMB6Ok3A1CS3hRNStKfffZZXnrpJe699178/KomARg0aBBr1qxptuCkpoiI2sf0pq9K0tOr91Q8VNnVPbq/GR8jIiJtXo/+sURcOAd63glRvSH1POjyG0+HJSJyUueeW7Pbu1frcgMAMUXvY7NVcOAAlJZ6OKZWpklJenZ2tquLenVBQUEUFRWdclDScM6x2G3Zzp2mTEurdvDwSlOqq7uIiFTnHwqZj8N5a2HEp2DXbNYiIs0qeTT4h+NXsoeze6zEsmDbNk8H1bo0KUnv2LFjnd3Mv/jiC3r27HmqMckJTJtWc19JOhw4YMrExGoHNbO7iIiIiIj7+QVByngArhpl5iurNle4NECTkvSpU6dy00038fbbb2NZFsuWLeOhhx5i2rRp3OX1Uw62btOnw+LFMHmy2Vd3dzh82JQxMZUHLKsqSVdLuoiIiIiIe7W/AIDz+76N3VauJL2RmrQE2/XXX09ISAh//OMfKS4u5oorriA1NZVnnnmGyy67rLljlGoCAuDss+Gzz8y+WtLrSNKLd0LJQbD5Q1TbWJ5PRERERMRrtL8AAqJJjdjEz077mM2bL/J0RK1Kk5dgmzx5Mps2baKwsJC9e/eya9cuLr/8cr799tvmjE/qkZpqSrWkw6FDpnQl6c5W9KjepruNiIiIiIi4T0AkdLoWgIkDZrVoS/p778HcuVC54JhPaHKS7hQaGkpi5WDgTZs2MXTo0FMOSk7OmaSrJb2qJT02tvLAIXV1FxERERHxqOTRAIzoOY8NG+C3vzVrvn/3XfM9RXk53HYbjBoFs2Y133097ZSTdPGMlBRTKkmvo7u7c2b3GCXpIiIiIiIekXAOFna6Jm+mJG8Xzz8PX3xhhu5efTXk55/6UyxcCP0TZjGs70rGjbVO/YZeQkl6K5WcbMp9+8w8aW1Z7SRdM7uLiIiIiHhUYBTEngaY1vTqXnkFRo+GI0dO7Sk++8zin9f+jvn3nEbQwc9O7WZeREl6K+VcbqykBAoKPBuLJ5WXV/1yx8QAx/ZD8S7ABjH9PRmaiIiIiEibZksaCcD4fl8CcNNNEBpqzi1fDi++eGr3L9q+hA4J23FY4ZA0+tRu5kUaNbv7xx9/fMLz2dnZpxSMVLP7M9jwDMSdDv0fqnU6NBTCw6Gw0LSmR0Z6IEYvcORIVU+CmBjgYGUrekQXCIjwWFwiIiIiIm1e+5/Bj49zwWkfERRwjEceCeYf/4Ann4Q77mj6+PS//hU++QQmpJr8tDj2Z0T5hzRj4J7VqCT9wgsvPOk1NputqbFIdY4jsHc2lBXWe0lSkknSc3Oha1c3xuZFnF3dw8IgMBB1dRcRERER8Rbxg7FC0olkB+s+mEFExO8BOOMMc3rZsroflp8P27ZBnz5gP67vt8MBd91lth+6bxEAEV3HtkDwntOo7u4VFRUn/Sn3pbnvPcmZZB5eDRV1/5s6u7zv2+emmLxQrfHomtldRERERMQ72OzY+t0PQOeyZ11dYAcOBJsNdu+GvXtrPmTVKujQAfr3h+nTa9/y++9NGRRwjNM7mR174pCWegUeoTHp3iqiK/iFQnkxFGys85KkJFPm5roxLi+jmd1FRERERLxYxhXgHwZF2+GgaToPC6vqCbx6dc3Lp02r+oy/ZEnt2/3rX6Yc22c2wYElFFa0M0NdfYiSdG9l94OYAWbb2YX7OM5l2H780T0heaNDh0wZEwM4CqBgU+UBJekiIiIiIh7nHwLtLzLb6x91He5fOcfzDz9UXbp/P3z9ddX+jh01b3X0KLz6qtl+YdrrAIR1v9g0y/sQJeneLLayy/uhlXWenjDBlO++a2Y5b4uc37LFxgJHKr+tCEmB4ASPxSQiIiIiItX0ngY2O+z6ENb8BSzLlaRXb0lfutTkNYGBZn/HjprLTW/cCGVlcFq3zaQ43gHA1vla97wGN1KS7s2crcEH655RYfx4CAmBnBxoqxPr1+junv+T2Yns6bF4RERERETkOFG9oNcfzPaa+2Hba3Um6WvWmPL8801ZXFzVcxZg/XpTXj/uPWxYkDzWJ+eianSSXl5ezoIFC8jLy2uBcKSG+LNMuX8hbH251unAwKqxHBvrHrbu8+pO0nt4LB4REREREalDvz9Dr2lm+4f76N+vDICffoKSEnPYmaQPGlQ1/9a2bVW3MMN8LSb0edccSLuopaP2iEYn6X5+fowbN47DzuxIWk5UL+h+m9le9ms4VnuGuG7dTKkkHSXpIiIiIiLeymaDPvdBUDwUbae9/XNiYkz3dWcL+dq1puzbt6oxsvr8W+vXw92THiMjYqWZZLv9xe59DW7SpO7uffr0YevWrc0di9Rl4N9Msl7hgD2zap12JukbNrg5Li9RY+I4JekiIiIiIt7LPwQ6TAbAtuOdGl3eHQ7Tqg4mSe/b12w7E3eA3B37eOjSe81Ov+kQkuSmwN2rSUn6gw8+yB133MGnn35KTk4O+fn5NX6kGdnskHaJ2d79Sa3THTuacudON8bkRZwt6XExDijcbHaUpIuIiIiIeKd0Z27zMQP7HwPMDO8bNphEPTIS0tOrknRnF3iHA7qHf4afvYLSsH7Q8w4PBO8e/k150MSJEwH42c9+hq3adPeWZWGz2Shvq1ONt5T2k2DtdMj5EsqPgV+w61RC5STmBw54KDYPcybpqVHZcMRh1mAMbefZoEREREREpG7xgyGkHRzdzR2DxvO0bQ6rV/vx9NPmdJ8+pmf88Ul6ztL3eOn66wAI6PR/7o/bjZqUpM+dO7e545ATiRkIIalwdA/smwep57pOxcebcv9+z4Tmac4kPSnkJzgCRHQ3vQ9ERERERMT72OzQ5Tew5k+k2Bdw07gZ/PPrW5k3z5y+/XZT9uljyr17Sila/z/Sd1wBQGlZEIFdfu3+uN2oSUn68OHDmzsOORGbDdpNgs0vmC7v1ZJ0Z0t6W03SnWPSY/00Hl1EREREpFXocx9gwZoHmDrhb7yx+ApKyoJolxHB/1U2kkeHF7No+iSGdJkDWebY0dJgZuW9wc9Dkj0VuVs0uclx4cKFXHnllZx99tns3r0bgFdffZVFixY1W3BSTbtJptz9CViW67AzSS8oqFq6oK0oKzOvGyDcUpIuIiIiItIq2GzQ8y4IjKVDwnYOvJDAigdP4+KJ+2D5LbD6XvjhfpOgV1q88RzCflVE5xG+uexadU1K0v/3v/8xfvx4QkJCWLlyJSWV2eGRI0d4+OGHmzVAqZQ0CvxCoHgn5K12HY6OBv/K/hBtbVx6Xl7VdnBJZZIepSRdRERERMTr+YdAWtUSat1SNvHwoGTY+A9Y9zD89KTr3Macrlz7wr/p0cPumhHelzV5dvfnn3+el156iYCAANfxIUOGsHLlymYLTqrxD4GUym7uG2e4DttsbXdcunM8ekSEhS2/cgHFiO6eC0hERERERBquyw1g86t93B4EQJk9lo5TttL9jg1sP9SNp54y+Y+va9KY9A0bNjBs2LBax6Oiosir3rwpzavn72HXB5D9CgyaAX6BACQlwd695qctcSbp3dNzwJFnfsEjlaSLiIiIiLQKcYPggm0QFA9LfgVF2+Cc9yA0FcpL8MOfi5b5UVEB06aZvKctaFKSnpyczObNm+nQoUON44sWLaJTp07NEZfUJf5sCIgERz4UbIRoM+VhWhqsXt321kp3du8f1HWd2YjoAn5BngtIREREREQaJ7S9KYe8UfO4XxA24G9/c3tEHtek7u6//vWvue2221i6dCk2m409e/bw+uuvc8cdd/Db3/62uWMUJ5sNInuZ7SPrXIfT0025Y4cHYvIgZ/f+/hmV/xZRvT0XjIiIiIiISDNoUkv6PffcQ0VFBaNHj6a4uJhhw4YRFBTEHXfcwS233NLcMUp10X3g4BLIWwsZvwBMSzq03SS9e7KSdBERERER8Q1NStJtNhv33nsvd955J5s3b6awsJBevXoRHh7e3PHJ8ZyJqFrSXd3dO8QqSRcREREREd/QpO7uv/rVrygoKCAwMJBevXpxxhlnEB4eTlFREb/61a+aO0aprnIcevUkvX3lMI7K5erbDNOSbpESqiRdRERERER8Q5OS9JdffpmjR4/WOn706FFeeeWVUw5KTsCZiBZuhvJjAMTFmUPO2c7biv37ISlqH8H2fLDZIaKbp0MSERERERE5JY3q7p6fn49lWViWRUFBAcHBwa5z5eXlzJo1i8TExGYPUqoJTobAWCg9BPk/QcwAYmPNqUOHoKIC7E366qX1OXAAOiVuNTuhaa4l6URERERERFqrRiXp0dHR2Gw2bDYb3brVbrW02WxMnz692YKTOthspjV9/0IzeVzMAGJizKmKCigogKgoz4boLnv2wJB22WYnrKNngxEREREREWkGjUrS586di2VZjBo1iv/973/EOptwgcDAQDIyMkhNTW32IOU4ziS9clx6cDCEhkJxsWlNbwtJenk57NoFnTIrW9LDO3k2IBERERERkWbQqCR9+PDhAGRnZ5OWloa9rfSr9jZ1TB4XG1uVpHdsA43KOTkmUe+cVNmSHt4GXrSIiIiIiPi8Ji3BlpGRAUBxcTE7duygtLS0xvl+/fqdemRSP+fkcXlrXYdiY03L8qFDHorJzZzLzXVvr+7uIiIiIiLiO5qUpO/fv59rr72Wzz//vM7z5eXlpxSUnIQzSS/KhrIi8A+rMXlcW+BM0jsmqLu7iIiIiIj4jib1V58yZQp5eXksXbqUkJAQvvjiC15++WW6du3Kxx9/3NwxyvGCEyC4chb9PNPl3ZmkHzjgoZjcbNky8PdzkBi+yxxQd3cREREREfEBTWpJnzNnDh999BGDBg3CbreTkZHB2LFjiYyM5JFHHuG8885r7jjleLGnw57PYMPTEP8G7dqZw7t2eTQqt1i2DJ56Cjol7sBuqwC/EAhO8nRYIiIiIiIip6xJLelFRUWu9dBjYmLYv38/AH379mXlypXNF53Ur+8DptzxLjjySU83uz/8AMeOeSyqFldSAtddZ7a7pWw2G+EdzdJ0IiIiIiIirVyTkvTu3buzYcMGAPr3788LL7zA7t27ef7550lJSWnWAKUecYMgvDNYZbBvnitJnzUL0tIgN9ez4bWUO++EtZXz5f3zUfMeJKK75wISERERERFpRk1K0m+77TZycnIA+NOf/sTnn39Oeno6f//733n44YebNUA5gaRRpjy41JWkgxmX/tZbngmppX34oSlnzoSOcRvNTmQ3T4UjIiIiIiLSrBqVpGdnm+WurrzySq655hoATjvtNLZv387333/Pzp07+cUvftHg+y1YsIBJkyaRmpqKzWbjQ2cGVo9FixYxZMgQ4uLiCAkJoUePHjz11FONeQm+xTmjedHOWmujf/KJ+8NpaTk5sHMn2O3w858DBWpJFxERERER39KoieM6d+5MRkYGI0eOZNSoUYwYMYL27dsTGhrKwIEDG/3kRUVF9O/fn1/96ldcfPHFJ70+LCyMm2++mX79+hEWFsaiRYu44YYbCAsL4ze/+U2jn7/VC00zZfFOkpLgpZdg8WLTyrxnj0cjaxFLl5qyZ08IDwfyK5P0SCXpIiIiIiLiGxqVpM+ZM4d58+Yxb9483nzzTUpLS+nUqROjRo1i5MiRjBw5kqSkhs+yPWHCBCZMmNDg6zMzM8nMzHTtd+jQgffff5+FCxe2zSQ9rCpJB7j+ejjtNJOkHzzoubBayty5phw2DLM+fOXrVpIuIiIiIiK+olFJ+ogRIxgxYgQAx44d49tvv3Ul7S+//DIOh4MePXqwbt26loi1llWrVvHtt9/y4IMP1ntNSUkJJSUlrv38/HwAHA4HDoejzsc4j9d33msEJhMAWMW7KCstBZuNqCiAAA4etCgtLfOpSc+/+cYfsDF8eBmOw+vNaw+Mo8weCSepq1ZTp9JgqlPfozr1PapT36M69T2qU9+jOvVOjakPm2VZ1qk8WWlpKYsXL+bzzz/nhRdeoLCwkPLy8kbfx2az8cEHH3DhhRee9Nr27duzf/9+ysrKeOCBB7jvvvvqvfaBBx5g+vTptY6/8cYbhIaGNjpOb2K3HEwqvgSAz0NfptQWRUmJH7/4xfkAvPHGZ4SGlnkyxGZjWfCLX5xPaakfL7wwm8y4rzi95AkO2nuwKORRT4cnIiIiIiJSr+LiYq644gqOHDlCZGTkCa9tdJJeWlrKkiVLmDt3LvPmzWPp0qWkpaUxbNgwhg0bxvDhw0mvPtV4AzUmSc/OzqawsJAlS5Zwzz338I9//IPLL7+8zmvraklPS0vjwIED9f7jOBwOZs+ezdixYwkICGj0a3En/4/TsJXswzFmKcSYoQCRkf4cO2bjp58cdOrk4QCbSX4+xMebusjLcxC+7SH81k2nosPVlJ/+0kkf35rqVBpGdep7VKe+R3Xqe1Snvkd16ntUp94pPz+f+Pj4BiXpjeruPmrUKJYuXUrHjh0ZPnw4N9xwA2+88Ybb10bvWDmVed++fdm3bx8PPPBAvUl6UFAQQUFBtY4HBASc9E3bkGs8LiwNSvYRUJoDAWcAEBcHu3dDfn4A3h5+Qx0+bMrwcIiKCoCizQDYo3pgb8SLbBV1Ko2iOvU9qlPfozr1PapT36M69T2qU+/SmLpo1BJsCxcuJC4ujlGjRjF69GjGjh3r9gT9eBUVFTVaytsc1wzvu1yH4uNN6UuTx+3bZ8rExMoDmtldRERERER8UKNa0vPy8li4cCHz5s3jscce4/LLL6dbt24MHz6cESNGMHz4cBISEhp8v8LCQjZv3uzaz87OJisri9jYWNLT05k2bRq7d+/mlVdeAWDGjBmkp6fTo0cPwKyz/sQTT3Drrbc25mX4ltCaM7yDaUkH30rSc3NNmZiIGaCuJF1ERERERHxQo5L0sLAwzj33XM4991wACgoKWLRoEXPnzuXxxx9n8uTJdO3albVr1zbofsuXL2fkyJGu/alTpwJw9dVXM3PmTHJyctixY4frfEVFBdOmTSM7Oxt/f386d+7MY489xg033NCYl+FbnMuwFW13HXIm6QcOeCCeFuJM0pOSgGN7oawAbHYI7+zRuERERERERJpTo5L044WFhREbG0tsbCwxMTH4+/vz448/NvjxI0aM4ETz1s2cObPG/i233MItt9zS1HB9U2RPU+atcR3yxZb0vXtNmZgI5G80O2Edwa/2fAMiIiIiIiKtVaOS9IqKCpYvX868efOYO3cuixcvpqioiHbt2jFy5EhmzJhRo2Vc3CBmgCnzf4Kyo+Af4pNj0rdtM2WHDkCBurqLiIiIiIhvalSSHh0dTVFREcnJyYwcOZKnnnqKESNG0Lmzuhx7TEgqBMVDyQE4uASSRvpkS/rWrabs2JGq8egR3TwWj4iIiIiISEtoVJL+17/+lZEjR9Ktm5Ijr2GzQfsLYcu/YP3jNZJ0XxqT7kzSO3UCCjaZnUi9D0VERERExLc0agm2G264QQm6N+p6oykPrwR8b0x6SYlZ9x2OS9IjunosJhERERERkZbQqCRdvFRYB1Mey4XyY64x6b7Skr5vn1l1LTAQ4mPLobCyWV1JuoiIiIiI+Bgl6b4gMBb8Qs128S46dDC94Hftgmor2LVazh4BcXFgO7oDKkrBHlS1RryIiIiIiIiPUJLuC2w2CEs320U7SEyEYcPM7rvvei6s5nLokCnj4qjW1b2zWSddRERERETEhyjL8RWhziR9OwAXXWR2v/rKQ/E0I2dLemwsVUl6eBePxSMiIiIiItJSlKT7itBUUx7bB8CYMWZ34UIz8VprVndLusaji4iIiIiI71GS7iuCEkx5LBeAXr0gORmOHoXvvvNgXM2gzpZ0JekiIiIiIuKDlKT7iuBEU5aYJN1mg9GjzaFvvvFQTM2k+sRxStJFRERERMSXKUn3FUGVSXplSzrAyJGm/PZbD8TTjJzd3ePjyqAw2+woSRcRERERER+kJN1XuFrS97sO9e9vyjVrPBBPM3K2pGfEbQOrDPyCIbSdR2MSERERERFpCUrSfUVw7Zb0Xr1Mt/f9+2HfPg/F1QycLento6rN7K7l10RERERExAcp0/EV1ZN0qwKA0FDoUrlS2fr1HoqrGThb0hNCKru6h3fyXDAiIiIiIiItSEm6rwhOBpu/6Q5+dI/rcLvKXuGtuSXdmaRHBziT9I6eC0ZERERERKQFKUn3FXZ/CMsw2wVbXIfj4025f38dj2kFKiqquruH27aZjTAl6SIiIiIi4puUpPuS8M6mLKxK0hMql09vrUl6fr5J1AGCHM6W9A4ei0dERERERKQlKUn3JRGVA9ALNrsOOZP0Awc8EE8zcLaih4WB/ei2yh21pIuIiIiIiG9Sku5LonqZ8vAq16HW3t3dOR49LbkASip31JIuIiIiIiI+Skm6L4kfbMoDS1wzvLf27u7OHgB9Om4zG4GxEBDpsXhERERERERakpJ0XxLdD/xCwZEH+T8BVUn6ypVw663w44+eC68pnF8u9MqoHI8e1sFjsYiIiIiIiLQ0Jem+xO4PcWeY7f3fAtC/P/j7Q0EBPPssTJoEluXBGBvJmaR3TtpmNrT8moiIiIiI+DAl6b4m4WxTHjBJenw8jB9fdXrLFvjhBw/E1US5uaZMj9tmNtSSLiIiIiIiPkxJuq+JO9OUh1a4Dv3jH/CHP1RdsmePm2M6Bc6W9JRI5/JrakkXERERERHfpSTd1zhneC/YCBXlAHToAA89VNWivm+fZ0JrCmeSHhe8zWyoJV1ERERERHyYknRfE9YR7IFQfgyKt9c4lZhoSmcX8tbAGWuUXS3pIiIiIiLi+5Sk+xq7H0R0M9tHak7lnpRkytaUpO/fD1GheQRwxBwIy/BsQCIiIiIiIi1ISboviuhqysLsGoedLemtrbt7x4TK1xGcCP5hng1IRERERESkBSlJ90XO1uaibTUOt7aW9KNHobAQOiRsMwc0Hl1ERERERHycknRf5Exmi2qOSU9JMeWuXe4Np6mck8Z1Sa5sSVeSLiIiIiIiPk5Jui+qpyW9Y+Wca9nZYFnuDakpnEl6j7RtZkOTxomIiIiIiI9Tku6LwjuYsqjmmPT0dLDbTTfy1jAu3dktXy3pIiIiIiLSVihJ90UR3QAblByEo1XZeGAgpKWZ7a1bPRNaYzhb0jPinMuvdfJcMCIiIiIiIm6gJN0X+YdWzfCe90ONU9W7vHs7k6RbJEc4W9LV3V1ERERERHybknRfFd3PlPsX1Tjcrp0pc3LcHE8T5OZCYmQuwf7FgA3C0j0dkoiIiIiISItSku6rUieY8qcnwVHgOuyc4b01JOn790PHxMpW9NB24Bfk2YBERERERERamJJ0X9XpGghpB2VFcGiF63Bysin37vVMWI2xfz90TNB4dBERERERaTuUpPsqmx3izzTbh5a7DjuT9NbQkp6bWy1J13h0ERERERFpA5Sk+7LY00xZrSXd2d29tbSkd0qsnIZea6SLiIiIiEgboCTdl8UOMmUd3d137wbL8kBMjVCju7ta0kVEREREpA1Qku7LnC3pBZug9AgAnTqBnx/k53t3l/ejR6GwENLjd5gD4R08Go+IiIiIiIg7KEn3ZUFxEJZhtg9nARAcDF0rl1Bfs8YzYTVEbq4pU6Irv0kISfVcMCIiIiIiIm6iJN3XRXQ3ZeFW16G+fU157rlQWuqBmBpg3z4IDy4gPLjIHAhJ8WxAIiIiIiIibqAk3dc5u4kXbXMduuCCqtPr17s1mgbLza3Wiu4fAf5hng1IRERERETEDTyapC9YsIBJkyaRmpqKzWbjww8/POH177//PmPHjiUhIYHIyEgGDx7Ml19+6Z5gW6uwDqaslqRPngzdupntrVtrPcIr7NtXvat7smeDERERERERcROPJulFRUX079+fGTNmNOj6BQsWMHbsWGbNmsWKFSsYOXIkkyZNYtWqVS0caSvmnBW9WpIOMHCgKbOz3RtOQ+XmQnJ05Tpx6uouIiIiIiJthL8nn3zChAlMmDChwdc//fTTNfYffvhhPvroIz755BMyMzPrfExJSQklJSWu/fz8fAAcDgcOh6POxziP13e+VQntSABgHVpJWfEhCIgAICPDDvixeXM5DkeFR0Osy969dlKj9wBQEZRE+SnWhU/VqQCqU1+kOvU9qlPfozr1PapT36M69U6NqQ+PJumnqqKigoKCAmJjY+u95pFHHmH69Om1jn/11VeEhoae8P6zZ88+5Rg9zrIYZWtHRNlu1syazs6AUQAUFqYDmSxbdoBZs5Z4NsY6rFp1GhdlmOXXtux1sH7WrGa5r0/UqdSgOvU9qlPfozr1PapT36M69T2qU+9SXFzc4GtbdZL+xBNPUFhYyKWXXlrvNdOmTWPq1Kmu/fz8fNLS0hg3bhyRkZF1PsbhcDB79mzGjh1LQEBAs8ftbvaVX8GW5+jfKYS+fScCYLPZmDEDKioSmThxoocjrO3vf/cjPc4k6Z36jKBDl1OL0dfqVFSnvkh16ntUp75Hdep7VKe+R3XqnZw9uhui1Sbpb7zxBtOnT+ejjz4iMTGx3uuCgoIICgqqdTwgIOCkb9qGXNMqhKcB4FeyF7/K19O+vTm1d6/NK19jbi6uJN0voqMr7lPlM3UqLqpT36M69T2qU9+jOvU9qlPfozr1Lo2pi1a5BNtbb73F9ddfzzvvvMOYMWM8HY73C2lnyqN7XIdSKudiy82F8nIPxHQSubmQHm+SdMLSPRuMiIiIiIiIm7S6JP3NN9/k2muv5c033+S8887zdDitQ2iqKY/udh1KSACbDSoqYP9+D8VVj/JyKDxylKSoXHMgNM2zAYmIiIiIiLiJR7u7FxYWsnnzZtd+dnY2WVlZxMbGkp6ezrRp09i9ezevvPIKYLq4X3311TzzzDOceeaZ7N1rlugKCQkhKirKI6+hVXC2pBdXJen+/pCYaNYj37sXkr1oKfKDByE9bhsAln8EtsD6JwYUERERERHxJR5tSV++fDmZmZmu5dOmTp1KZmYm999/PwA5OTns2LHDdf2LL75IWVkZN910EykpKa6f2267zSPxtxqhaWDzA8cRyKma5dHZ5X3TJg/FVY99+6BjglnA3Rbe0TT5i4iIiIiItAEebUkfMWIElmXVe37mzJk19ufNm9eyAfmqgHDociNsmgFb/g0pYwEYPRqysuDdd+GSSzwbYnU7d0LHRJOkE97Js8GIiIiIiIi4Uasbky5N1P5npjy80nXo4otNuWiRB+I5gR07qlrSCevo2WBERERERETcSEl6WxFjhhRQsAkcZo2+jAxzaP9+M4Gct9ixAzolbjU74UrSRURERESk7VCS3lYEJ0Bo5eLoh1cDZoZ3gLIyOHzYQ3HVoUZLupJ0ERERERFpQ5SktyUxA015yHR5DwyEmBhzKDfXQzHVYf16dXcXEREREZG2SUl6W+Ls8n54letQYqIp9+3zQDzHsSz45hvI3nCY6LAj5qBa0kVEREREpA1Rkt6WxAwwZd4a16GkJFN6Q0v6DTfAmDHQOWmLORCcBP6hng1KRERERETEjZSktyURnU1ZtM11yFta0rOz4aWXzHaftLVmI6q35wISERERERHxACXpbUlY5XTupYfAUQBUJemebklfu7Zqu097Z5LexzPBiIiIiIiIeIiS9LYkIBICY8120XbAe7q7//hj1fbpXSuT9Ggl6SIiIiIi0rYoSW9rnK3plV3evaW7uzNJnz4dhvdXS7qIiIiIiLRNStLbmoiupjyyDvCelvT1603Zv+dhOLrb7ERrTLqIiIiIiLQtStLbmthBpjy4DPCOlnTLqmpJ75dhvjwgNN10zxcREREREWlDlKS3NXFnmPLg94B3tKTv3g0FBeDnB2mRldm6ZnYXEREREZE2SEl6WxPT35TFO6H0iCtJLyw0P56wcaMpO3cG/6OVO5HdPROMiIiIiIiIBylJb2sCoyE42WznbyAiAqKjze62bZ4Jaf9+U6akAPnOJL2bZ4IRERERERHxICXpbVFUT1Pm/wRAp05mNzvbM+EcOmTK2FigoDJJj1CSLiIiIiIibY+S9LYosocp8834b2eSvnWrZ8JxJunxcWVQuMXsKEkXEREREZE2SEl6WxRZsyW9Y0ezu2WLZ8JxJumdk7ZBhQP8QiC0nWeCERERERER8SAl6W2RqyXdJOntKvNhTy3D5kzSO8Y7u7p3BZvemiIiIiIi0vYoE2qLnEl6wWaocBAVZXaPHPFMOM4kvX2UxqOLiIiIiEjbpiS9LQptD/4RYJVB/k9ek6QnhWhmdxERERERaduUpLdFNhvEDjTbB7/3miQ9xl8t6SIiIiIi0rYpSW+r4k43pRck6Xl5pgyvUJIuIiIiIiJtm5L0tip6gCnzf/SKJD0ksJjAsp3mgLq7i4iIiIhIG6Ukva0KSzNl8W5Xkl5UBOXl7g2jtBSKi6FL0mZzIDAWguLcG4SIiIiIiIiXUJLeVoW2N+XR3URFWq7D+fnuDcPZet8tRV3dRURERERElKS3VSGppiw/SiCHCQ42u+7u8u4cj943QzO7i4iIiIiIKElvq/yCISjebBfv8ti4dGeS3itNLekiIiIiIiJK0tsyZ5f3om0kJprNnBz3huBM0jsnbjEb4Z3dG4CIiIiIiIgXUZLelkX3M+WhFXTqZDa3bnVvCM6W+/Yx28xGeEf3BiAiIiIiIuJFlKS3ZbFVa6V3rMyN3Z2k5+VBoH8J8WG7zQEl6SIiIiIi0oYpSW/L4s4w5aFldOpkZnjPznZvCHl5kB63A7vNAr9QCEpwbwAiIiIiIiJeREl6WxbTH+wBUHKQXhnbANi2zb0h5OVBh4TKJw3vCDabewMQERERERHxIkrS2zK/IIjuD0B62DIADh50bwh5edAxobL5PqyDe59cRERERETEyyhJb+vizLj0eNtywENJemJlkq7x6CIiIiIi0sYpSW/rYk8DILx0JQCFhVBa6r6nP3IEOsRvMzthStJFRERERKRtU5Le1sUMBMC/YCU2m5k87tAh9z19zZb0Du57YhERERERES+kJL2ti+oNNj9sjjx6ZuQA7u3yXnNMulrSRURERESkbVOS3tb5BUJYBgD9u2wG3NuSfqyomKSoXLOjMekiIiIiItLGKUkXCO8MQM/2WwD3tqRH+W8DoNwvCgKj3ffEIiIiIiIiXkhJuriS9K4pJkl3V0t6WRkkhZmu7hWhakUXERERERFRki4Q0QWAjDj3tqTv3181Ht0/soN7nlRERERERMSLKUkXV0t6uwj3jknPyYFe7dYDYIvq7p4nFRERERER8WJK0gUiTJKeEFJ3S3pBAYwaBf/4R/M+7d690Lv9OrMT1bt5by4iIiIiItIKeTRJX7BgAZMmTSI1NRWbzcaHH354wutzcnK44oor6NatG3a7nSlTprglTp8X3gmAEL/DRIcerpWkP/44zJ0Lt9zSvE+bk2NVS9L7NO/NRUREREREWiGPJulFRUX079+fGTNmNOj6kpISEhIS+OMf/0j//v1bOLo2xD8MQlIA6JK8uVZ3961bW+Zp83MPEB9xkArLBpHq7i4iIiIiIuLvySefMGECEyZMaPD1HTp04JlnngHgP//5T0uF1TaFd4ajOXRK3MqPB0+vcSo3t2We0srfAMARRzox/qEt8yQiIiIiIiKtiEeTdHcoKSmhpKTEtZ+fnw+Aw+HA4XDU+Rjn8frO+yK/0A7YWUTnxC0sXmHhcJS5zuXm+gM2oHn/TRwHfwSgyK8r4S38b90W69TXqU59j+rU96hOfY/q1PeoTn2P6tQ7NaY+fD5Jf+SRR5g+fXqt41999RWhoSduvZ09e3ZLheV1upWW0xPonLSF3NwKPv10FvbKwRA7d44HggGYNWtWszxfebkNv+KNABxyhLOime57Mm2pTtsK1anvUZ36HtWp71Gd+h7Vqe9RnXqX4uLiBl/r80n6tGnTmDp1qms/Pz+ftLQ0xo0bR2RkZJ2PcTgczJ49m7FjxxIQEOCuUD3Ktj0Plr1J1+TNOBx+9Os3kfR0c66goOptMnHixGZ5vnXrwJ5ohiz0PHMEPbs1z33r0xbr1NepTn2P6tT3qE59j+rU96hOfY/q1Ds5e3Q3hM8n6UFBQQQFBdU6HhAQcNI3bUOu8RmxZnb1vunrAIvs7AA6m5XZKKvq+d5s/x7btkG3FNOSHhDbE9z079ym6rSNUJ36HtWp71Gd+h7Vqe9Rnfoe1al3aUxdaJ10MaJ6g82PmNCDtIvdzYYNLft02VvL6JK02exoZncRERERERHAwy3phYWFbN682bWfnZ1NVlYWsbGxpKenM23aNHbv3s0rr7ziuiYrK8v12P3795OVlUVgYCC9evVyd/i+xS8YInvAkXUMyMhi48b2Lfp0+Xu2E5jswFERTEBoWos+l4iIiIiISGvh0SR9+fLljBw50rXvHDt+9dVXM3PmTHJyctixY0eNx2RmZrq2V6xYwRtvvEFGRgbbtm1zS8w+LfY0OLKOs7osYdGG8wGwrJZ5qoojpqk+n67E2dShQ0REREREBDycpI8YMQLrBFngzJkzax070fVyihLOgexXGNp9If9+zRw6dqxlniq41IxHLwtRV3cREREREREnNWFKlYShAJzReRk7dlRw7BgUFVWdDg5unqepqIC4QNOSHhjXrXluKiIiIiIi4gOUpEuViK5Y9gBCAo/RPnYnS5dCYWHV6ebqxLB3L3ROMC3pEe3Uki4iIiIiIuKkJF2q2P2whXcBoFvyRt58s2ZLenl58zzN1q3QPdW0pPvHqCVdRERERETESUm61BTRFYCuyZuYNatlkvQdWwtpH7vb7Gj5NRERERERERcl6VJTpGnZ7p66iZ07YeHCqlOW1Txd3gv2bAIgvzQBAmNO/YYiIiIiIiI+Qkm61BTWAYBBPbYDcMcdNU83R2t6+WHT1f1Ihbq6i4iIiIiIVKckXWoKywDg9N7biY2tffpUk/T9+2HvJjNpnCNYXd1FRERERESqU5IuNVUm6YGO7UydWvv06tWndvtnnoHuKaYlPUDLr4mIiIiIiNSgJF1qCk03ZclBrvxFfq3TZ54J+bUPN9i6dWbmeIDEzmpJFxERERERqU5JutQUGAUhKQBkHPs7zz8PV1xR85J//rPp3d7zD5fQs92PAAQlKEkXERERERGpTkm61NbnPlNuf5sbboBXXql5eto0uOSSpt26a/jnhAcXUeLXTsuviYiIiIiIHEdJutTW/kJTHlkHjgLsdbxLPvigcbf87ju45x4Y0fEtAI4l/gJsevuJiIiIiIhU5+/pAMQLhaRAaBoU74RDK7ElDT+l261cCWefDWFBheQ+97F5ip6XN0ekIiIiIiIiPkVNmVK32IGmzDu16dz37oXTTjPbPzvtY0KDjrI1tzOBSaedYoAiIiIiIiK+R0m61C2qjynz1pzSbd59t2r74tPfB+CH/MvAZjul+4qIiIiIiPgiJelSt+i+pjzwLVhWk28zf37V9hmdlgEw8vKxpxKZiIiIiIiIz1KSLnWLO9NM7HZkPWS/cvLr67F1qyljww+SHr8TgKiMAc0QoIiIiIiIiO9Rki51C+8A3aeY7V0f1nnJydZKf/hhWLXKbJ/e6fvK+3Yya7GLiIiIiIhILUrSpX7plYuh587HZquodfro0doPef11GDoU9uyBe++tOv7p3182G8ljWiBQERERERER36AkXeoXOwj8I6D0MP3Ta8/yXlxc+yFXXgmLFsGDD1Ydu/Sst/HfbdZHp8PkFgpWRERERESk9VOSLvWz+0PiUADO7f9FrdN1JelOZWUQHW22n7juSbPR5QZIHNbMQYqIiIiIiPgOJelyYsnjALj3godIitpLZCTExZlTxyfpFdV6xCckmEQ9PmI/aaHfAzbo9xf3xCwiIiIiItJKKUmXE+vyawhNIzy4iOE952O3Q2ioOXV8kr5/f9V2bKw53y1lozkQmgbBCe6JWUREREREpJVSki4n5h8KKaY1vXe7ddhs9Sfpu3dXbR87ZlrWuyVXJumR3dwQrIiIiIiISOumJF1OLqo3AP0zVp+wJX3Xrqrtw4fBZqvgmatuMwcilKSLiIiIiIicjJJ0ObmYTAAmZX7CgPQVriR9376al61fX7Wdlwcje80lMqSgxj1ERERERESkfkrS5eQShzP/x2HY7RYT+33EsMoJ2mfMqHnZmjVV247iPL75Q+Wa6CGp0Olq98QqIiIiIiLSiilJl5Oz2Xhv2f8B0KddFrdV9mD//nvTYu70ww9V26fHvVq10+ePYA9o+ThFRERERERaOSXp0iCrd/QHoE+7VSQlQadO5vjXX5sW9G3bYO3aquszIldU7bS7wH2BioiIiIiItGJK0qVBsrYPoMQRSGr0Ltg4gzPPMIuiX3IJ9OsHv/tdzes7xZhm9akf/A9CU90droiIiIiISKukJF0apOBoJO8uvcTsLL+Zu0b+tsb5zz83ZUAAhAQW0yVhHQDb8we4MUoREREREZHWTUm6NNi97z7E52t/DsCA8BcZ3PVb17mIkHzuu+jPDB20h6HdFxIUUMrOg+3ZsLujp8IVERERERFpdZSkS4PtOJDBLe+8B52vA+Dxy+9ynXvml7fx5//7E9/c3I4v7zkXgNlrxtKnj80jsYqIiIiIiLRG/p4OQFoXux3o+2fY8m/O6b6Yslf9+HD5hfz8jPdrXfv6yt/z4tvuj1FERERERKS1Uku6NIrdjpkIrnJJNT97RZ0JespNe7jk+t507uzmAEVERERERFoxJenSKHbnO6bfg3We32b9gklPfMzevBTCw90Xl4iIiIiIiC9Qd3dpFFeS3uP3kDIOtr3BTyW/JKFDBnHxASx7P4RPV5lLwsI8FqaIiIiIiEirpCRdGsWVpNv9IGYAxAygR7XzgYFV22pJFxERERERaRx1d5dGOe20E59Xki4iIiIiItJ0akmXBsnKgtdeg3vvPfF1StJFRERERESaTkm6NEj//ubnZKon6RqTLiIiIiIi0jjq7i7Nyr/a1z5qSRcREREREWkcJenSrByOqm0l6SIiIiIiIo2jJF2aVWlp1XZIiOfiEBERERERaY2UpEuzCg2t2rbZPBeHiIiIiIhIa+TRJH3BggVMmjSJ1NRUbDYbH3744UkfM2/ePAYOHEhQUBBdunRh5syZLR6nNNzZZ8PNN8Ozz3o6EhERERERkdbHo0l6UVER/fv3Z8aMGQ26Pjs7m/POO4+RI0eSlZXFlClTuP766/nyyy9bOFJpKJvNJOg33+zpSERERERERFofjy7BNmHCBCZMmNDg659//nk6duzIk08+CUDPnj1ZtGgRTz31FOPHj2+pMEVERERERETcolWtk/7dd98xZsyYGsfGjx/PlClT6n1MSUkJJSUlrv38/HwAHA4HjupTkVfjPF7feWl9VKe+R3Xqe1Snvkd16ntUp75Hdep7VKfeqTH10aqS9L1795KUlFTjWFJSEvn5+Rw9epSQOqYTf+SRR5g+fXqt41999RWh1Wc5q8Ps2bNPLWDxOqpT36M69T2qU9+jOvU9qlPfozr1PapT71JcXNzga1tVkt4U06ZNY+rUqa79/Px80tLSGDduHJGRkXU+xuFwMHv2bMaOHUtAQIC7QpUWpDr1PapT36M69T2qU9+jOvU9qlPfozr1Ts4e3Q3RqpL05ORk9u3bV+PYvn37iIyMrLMVHSAoKIigoKBaxwMCAk76pm3INdK6qE59j+rU96hOfY/q1PeoTn2P6tT3qE69S2PqolWtkz548GC++eabGsdmz57N4MGDPRSRiIiIiIiISPPxaJJeWFhIVlYWWVlZgFliLSsrix07dgCmq/pVV13luv7GG29k69at3HXXXfz000/885//5J133uH222/3RPgiIiIiIiIizcqjSfry5cvJzMwkMzMTgKlTp5KZmcn9998PQE5OjithB+jYsSOfffYZs2fPpn///jz55JP861//0vJrIiIiIiIi4hM8OiZ9xIgRWJZV7/mZM2fW+ZhVq1a1YFQiIiIiIiIintGqxqSLiIiIiIiI+DIl6SIiIiIiIiJeQkm6iIiIiIiIiJdQki4iIiIiIiLiJZSki4iIiIiIiHgJJekiIiIiIiIiXkJJuoiIiIiIiIiXUJIuIiIiIiIi4iWUpIuIiIiIiIh4CX9PB+BulmUBkJ+fX+81DoeD4uJi8vPzCQgIcFdo0oJUp75Hdep7VKe+R3Xqe1Snvkd16ntUp97JmX8689ETaXNJekFBAQBpaWkejkRERERERETakoKCAqKiok54jc1qSCrvQyoqKtizZw8RERHYbLY6r8nPzyctLY2dO3cSGRnp5gilJahOfY/q1PeoTn2P6tT3qE59j+rU96hOvZNlWRQUFJCamordfuJR522uJd1ut9O+ffsGXRsZGak3to9Rnfoe1anvUZ36HtWp71Gd+h7Vqe9RnXqfk7WgO2niOBEREREREREvoSRdRERERERExEsoSa9DUFAQf/rTnwgKCvJ0KNJMVKe+R3Xqe1Snvkd16ntUp75Hdep7VKetX5ubOE5ERERERETEW6klXURERERERMRLKEkXERERERER8RJK0kVERERERES8hJJ0ERERERERES+hJP04M2bMoEOHDgQHB3PmmWeybNkyT4ck9XjkkUc4/fTTiYiIIDExkQsvvJANGzbUuObYsWPcdNNNxMXFER4ezs9//nP27dtX45odO3Zw3nnnERoaSmJiInfeeSdlZWXufClSh0cffRSbzcaUKVNcx1SfrdPu3bu58soriYuLIyQkhL59+7J8+XLXecuyuP/++0lJSSEkJIQxY8awadOmGvc4dOgQkydPJjIykujoaK677joKCwvd/VIEKC8v57777qNjx46EhITQuXNn/vKXv1B9HlrVqXdbsGABkyZNIjU1FZvNxocffljjfHPV3w8//MDQoUMJDg4mLS2Nxx9/vKVfWpt1ojp1OBzcfffd9O3bl7CwMFJTU7nqqqvYs2dPjXuoTr3LyX5Pq7vxxhux2Ww8/fTTNY6rTlsvJenVvP3220ydOpU//elPrFy5kv79+zN+/Hhyc3M9HZrUYf78+dx0000sWbKE2bNn43A4GDduHEVFRa5rbr/9dj755BPeffdd5s+fz549e7j44otd58vLyznvvPMoLS3l22+/5eWXX2bmzJncf//9nnhJUun777/nhRdeoF+/fjWOqz5bn8OHDzNkyBACAgL4/PPPWb9+PU8++SQxMTGuax5//HH+/ve/8/zzz7N06VLCwsIYP348x44dc10zefJk1q1bx+zZs/n0009ZsGABv/nNbzzxktq8xx57jOeee45//OMf/Pjjjzz22GM8/vjjPPvss65rVKferaioiP79+zNjxow6zzdH/eXn5zNu3DgyMjJYsWIFf/3rX3nggQd48cUXW/z1tUUnqtPi4mJWrlzJfffdx8qVK3n//ffZsGEDP/vZz2pcpzr1Lif7PXX64IMPWLJkCampqbXOqU5bMUtczjjjDOumm25y7ZeXl1upqanWI4884sGopKFyc3MtwJo/f75lWZaVlx5JL+0AAAvNSURBVJdnBQQEWO+++67rmh9//NECrO+++86yLMuaNWuWZbfbrb1797quee6556zIyEirpKTEvS9ALMuyrIKCAqtr167W7NmzreHDh1u33XabZVmqz9bq7rvvts4555x6z1dUVFjJycnWX//6V9exvLw8KygoyHrzzTcty7Ks9evXW4D1/fffu675/PPPLZvNZu3evbvlgpc6nXfeedavfvWrGscuvvhia/LkyZZlqU5bG8D64IMPXPvNVX///Oc/rZiYmBp/e++++26re/fuLfyK5Pg6rcuyZcsswNq+fbtlWapTb1dfne7atctq166dtXbtWisjI8N66qmnXOdUp62bWtIrlZaWsmLFCsaMGeM6ZrfbGTNmDN99950HI5OGOnLkCACxsbEArFixAofDUaNOe/ToQXp6uqtOv/vuO/r27UtSUpLrmvHjx5Ofn8+6devcGL043XTTTZx33nk16g1Un63Vxx9/zKBBg7jkkktITEwkMzOTl156yXU+OzubvXv31qjXqKgozjzzzBr1Gh0dzaBBg1zXjBkzBrvdztKlS933YgSAs88+m2+++YaNGzcCsHr1ahYtWsSECRMA1Wlr11z199133zFs2DACAwNd14wfP54NGzZw+PBhN70aqc+RI0ew2WxER0cDqtPWqKKigl/+8pfceeed9O7du9Z51WnrpiS90oEDBygvL6/x4R4gKSmJvXv3eigqaaiKigqmTJnCkCFD6NOnDwB79+4lMDDQ9R+QU/U63bt3b5117jwn7vXWW2+xcuVKHnnkkVrnVJ+t09atW3nuuefo2rUrX375Jb/97W+59dZbefnll4GqejnR3969e/eSmJhY47y/vz+xsbGqVw+45557uOyyy+jRowcBAQFkZmYyZcoUJk+eDKhOW7vmqj/9PfZex44d4+677+byyy8nMjISUJ22Ro899hj+/v7ceuutdZ5XnbZu/p4OQKQ53HTTTaxdu5ZFixZ5OhRpop07d3Lbbbcxe/ZsgoODPR2ONJOKigoGDRrEww8/DEBmZiZr167l+eef5+qrr/ZwdNIU77zzDq+//jpvvPEGvXv3JisriylTppCamqo6FfFyDoeDSy+9FMuyeO655zwdjjTRihUreOaZZ1i5ciU2m83T4UgLUEt6pfj4ePz8/GrNFL1v3z6Sk5M9FJU0xM0338ynn37K3Llzad++vet4cnIypaWl5OXl1bi+ep0mJyfXWefOc+I+K1asIDc3l4EDB+Lv74+/vz/z58/n73//O/7+/iQlJak+W6GUlBR69epV41jPnj3ZsWMHUFUvJ/rbm5ycXGsCz7KyMg4dOqR69YA777zT1Zret29ffvnLX3L77be7esCoTlu35qo//T32Ps4Effv27cyePdvVig6q09Zm4cKF5Obmkp6e7vrMtH37dn7/+9/ToUMHQHXa2ilJrxQYGMhpp53GN9984zpWUVHBN998w+DBgz0YmdTHsixuvvlmPvjgA+bMmUPHjh1rnD/ttNMICAioUacbNmxgx44drjodPHgwa9asqfFHzPkf1/GJhbSs0aNHs2bNGrKyslw/gwYNYvLkya5t1WfrM2TIkFpLI27cuJGMjAwAOnbsSHJyco16zc/PZ+nSpTXqNS8vjxUrVriumTNnDhUVFZx55plueBVSXXFxMXZ7zY8Pfn5+VFRUAKrT1q656m/w4MEsWLAAh8Phumb27Nl07969xuoO4h7OBH3Tpk18/fXXxMXF1TivOm1dfvnLX/LDDz/U+MyUmprKnXfeyZdffgmoTls9T89c503eeustKygoyJo5c6a1fv166ze/+Y0VHR1dY6Zo8R6//e1vraioKGvevHlWTk6O66e4uNh1zY033milp6dbc+bMsZYvX24NHjzYGjx4sOt8WVmZ1adPH2vcuHFWVlaW9cUXX1gJCQnWtGnTPPGS5DjVZ3e3LNVna7Rs2TLL39/feuihh6xNmzZZr7/+uhUaGmq99tprrmseffRRKzo62vroo4+sH374wbrgggusjh07WkePHnVdc+6551qZmZnW0qVLrUWLFlldu3a1Lr/8ck+8pDbv6quvttq1a2d9+umnVnZ2tvX+++9b8fHx1l133eW6RnXq3QoKCqxVq1ZZq1atsgDrb3/7m7Vq1SrXTN/NUX95eXlWUlKS9ctf/tJau3at9dZbb1mhoaHWCy+84PbX2xacqE5LS0utn/3sZ1b79u2trKysGp+Zqs/qrTr1Lif7PT3e8bO7W5bqtDVTkn6cZ5991kpPT7cCAwOtM844w1qyZImnQ5J6AHX+/Pe//3Vdc/ToUet3v/udFRMTY4WGhloXXXSRlZOTU+M+27ZtsyZMmGCFhIRY8fHx1u9//3vL4XC4+dVIXY5P0lWfrdMnn3xi9enTxwoKCrJ69OhhvfjiizXOV1RUWPfdd5+VlJRkBQUFWaNHj7Y2bNhQ45qDBw9al19+uRUeHm5FRkZa1157rVVQUODOlyGV8vPzrdtuu81KT0+3goODrU6dOln33ntvjQ/7qlPvNnfu3Dr//7z66qsty2q++lu9erV1zjnnWEFBQVa7du2sRx991F0vsc05UZ1mZ2fX+5lp7ty5rnuoTr3LyX5Pj1dXkq46bb1slmVZ7mixFxEREREREZET05h0ERERERERES+hJF1ERERERETESyhJFxEREREREfESStJFREREREREvISSdBEREREREREvoSRdRERERERExEsoSRcRERERERHxEkrSRURERERERLyEknQRERFpMJvNxocffujpMERERHyWknQREZE24pprruHCCy/0dBgiIiJyAkrSRURERERERLyEknQREZE2aMSIEdx6663cddddxMbGkpyczAMPPFDjmk2bNjFs2DCCg4Pp1asXs2fPrnWfnTt3cumllxIdHU1sbCwXXHAB27ZtA+Cnn34iNDSUN954w3X9O++8Q0hICOvXr2/JlyciItJqKUkXERFpo15++WXCwsJYunQpjz/+OH/+859diXhFRQUXX3wxgYGBLF26lOeff5677767xuMdDgfjx48nIiKChQsXsnjxYsLDwzn33HMpLS2lR48ePPHEE/zud79jx44d7Nq1ixtvvJHHHnuMXr16eeIli4iIeD2bZVmWp4MQERGRlnfNNdeQl5fHhx9+yIgRIygvL2fhwoWu82eccQajRo3i0Ucf5auvvuK8885j+/btpKamAvDFF18wYcIEPvjgAy688EJee+01HnzwQX788UdsNhsApaWlREdH8+GHHzJu3DgAzj//fPLz8wkMDMTPz48vvvjCdb2IiIjU5O/pAERERMQz+vXrV2M/JSWF3NxcAH788UfS0tJcCTrA4MGDa1y/evVqNm/eTERERI3jx44dY8uWLa79//znP3Tr1g273c66deuUoIuIiJyAknQREZE2KiAgoMa+zWajoqKiwY8vLCzktNNO4/XXX691LiEhwbW9evVqioqKsNvt5OTkkJKS0vSgRUREfJySdBEREamlZ8+e7Ny5s0ZSvWTJkhrXDBw4kLfffpvExEQiIyPrvM+hQ4e45ppruPfee8nJyWHy5MmsXLmSkJCQFn8NIiIirZEmjhMREZFaxowZQ7du3bj66qtZvXo1Cxcu5N57761xzeTJk4mPj+eCCy5g4cKFZGdnM2/ePG699VZ27doFwI033khaWhp//OMf+dvf/kZ5eTl33HGHJ16SiIhIq6AkXURERGqx2+188MEHHD16lDPOOIPrr7+ehx56qMY1oaGhLFiwgPT0dC6++GJ69uzJddddx7Fjx4iMjOSVV15h1qxZvPrqq/j7+xMWFsZrr73GSy+9xOeff+6hVyYiIuLdNLu7iIiIiIiIiJdQS7qIiIiIiIiIl1CSLiIiIiIiIuIllKSLiIiIiIiIeAkl6SIiIiIiIiJeQkm6iIiIiIiIiJdQki4iIiIiIiLiJZSki4iIiIiIiHgJJekiIiIiIiIiXkJJuoiIiIiIiIiXUJIuIiIiIiIi4iWUpIuIiIiIiIh4if8HNa39iU/RjG0AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot time series of observed vs predicted over first 1000 indices of test set\n",
    "predictions = model.predict(X_test, batch_size=len(X_test))\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(indices_test[:1000], y_test[:1000], label='Test Observed', color='blue')\n",
    "plt.plot(indices_test[:1000], predictions[:1000], label='Test Predicted', color='orange')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Water Level (m)')\n",
    "plt.title('Observed vs Predicted Water Levels (First 1000 Samples)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
