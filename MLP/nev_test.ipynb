{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0358c342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, mean_absolute_error, median_absolute_error, r2_score, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f878319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VRAM limited to 10000 MB.\n"
     ]
    }
   ],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_logical_device_configuration(\n",
    "            gpus[0],\n",
    "            [tf.config.LogicalDeviceConfiguration(memory_limit=10000)]  # MB\n",
    "        )\n",
    "        print(\"VRAM limited to 10000 MB.\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Memory configuration must be set at program start:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7aa9595e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_csv(path):\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    # Drop last 6 rows\n",
    "    df = df.iloc[:-6]\n",
    "    \n",
    "    # Convert date column to datetime\n",
    "    df['#date+time'] = pd.to_datetime(df['#date+time'], errors='coerce')\n",
    "    df = df.rename(columns={'#date+time': 'date_time'})\n",
    "    \n",
    "    # Convert all other columns to numeric\n",
    "    for col in df.columns:\n",
    "        if col != 'date_time':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    \n",
    "    return df\n",
    "def wind_to_uv(speed, direction_deg):\n",
    "    # Convert to radians\n",
    "    direction_rad = np.deg2rad(direction_deg)\n",
    "\n",
    "    # U = -speed * sin(direction), V = -speed * cos(direction)\n",
    "    # This converts FROM meteorological TO Cartesian\n",
    "    u = -speed * np.sin(direction_rad)\n",
    "    v = -speed * np.cos(direction_rad)\n",
    "    return u, v\n",
    "\n",
    "def prepare_dataframe(df):\n",
    "    # Rename columns to a consistent format\n",
    "\n",
    "    df = df.rename(columns={\n",
    "        df.columns[0]: 'date_time',\n",
    "        df.columns[1]: 'pwl',\n",
    "        df.columns[2]: 'harmwl',\n",
    "        df.columns[3]: 'wsd',  # Wind speed\n",
    "        df.columns[4]: 'wdr',  # Wind direction\n",
    "    })\n",
    "    \n",
    "    # Convert wind to U/V components\n",
    "    u, v = wind_to_uv(df['wsd'], df['wdr'])\n",
    "    df[['u', 'v']] = np.column_stack((u, v))\n",
    "    \n",
    "    # Drop raw wind columns\n",
    "    df.drop(columns=['wsd', 'wdr','harmwl'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def input_output_arrays(source_df, target_df, target_hourly_wind_df, wl_half_window=5, wind_window=3):\n",
    "\n",
    "    source_df = source_df.reset_index(drop=True)\n",
    "    target_df = target_df.reset_index(drop=True)\n",
    "\n",
    "    # Extract arrays\n",
    "    pl_pwl = source_df['pwl'].to_numpy()\n",
    "    target_pwl = target_df['pwl'].to_numpy()\n",
    "    datetimes = source_df['date_time'].to_numpy()\n",
    "\n",
    "    # Convert hourly wind df to dictionary for fast lookup\n",
    "    wind_lookup = {\n",
    "        ts: (row['u'], row['v']) for ts, row in target_hourly_wind_df.set_index('date_time')[['u', 'v']].iterrows()\n",
    "    }\n",
    "\n",
    "    X, y, indices = [], [], []\n",
    "    for t in range(wl_half_window, len(source_df) - wl_half_window):\n",
    "        curr_time = datetimes[t]\n",
    "\n",
    "        # Water level input\n",
    "        pwl_input = pl_pwl[t - wl_half_window: t + wl_half_window + 1]\n",
    "        if np.isnan(pwl_input).any():\n",
    "            continue\n",
    "\n",
    "        # Hourly wind input timestamps\n",
    "        hourly_times = [(curr_time - pd.Timedelta(hours=i)).replace(minute=0, second=0, microsecond=0)\n",
    "                        for i in reversed(range(wind_window))]\n",
    "\n",
    "        try:\n",
    "            uv_values = np.array([wind_lookup[ts] for ts in hourly_times]).flatten()\n",
    "        except KeyError:\n",
    "            continue  # skip if any timestamp is missing\n",
    "\n",
    "        target = target_pwl[t]\n",
    "        if np.isnan(uv_values).any() or np.isnan(target):\n",
    "            continue\n",
    "\n",
    "        X.append(np.concatenate([pwl_input, uv_values]))\n",
    "        y.append(target)\n",
    "        indices.append(t)\n",
    "\n",
    "    return np.array(X), np.array(y), np.array(indices)\n",
    "\n",
    "\n",
    "def calculate_central_frequency_percentage(testing_label_array, predictions, cm):\n",
    "  \"\"\"Find the percentage of predictions with a central frequency (CF) of less than\n",
    "  or equal to a given number of centimeters (cm)\n",
    "\n",
    "\tArgs:\n",
    "        testing_label_array (array): Testing labels\n",
    "\n",
    "        predictions (array): Model predictions\n",
    "\n",
    "        cm (int): Number of centimeters\n",
    "\n",
    "\tReturns:\n",
    "\t\t(float): central frequency (CF) percentage\n",
    "\t\"\"\"\n",
    "  less_than_cm_counter = 0\n",
    "\n",
    "  # Convert cm to m\n",
    "  cm_to_m = cm / 100\n",
    "\n",
    "  for index, prediction in enumerate(predictions):\n",
    "    if abs(testing_label_array[index] - prediction) <= cm_to_m:\n",
    "      less_than_cm_counter += 1\n",
    "\n",
    "  cf_percentage = (less_than_cm_counter / len(predictions)) * 100\n",
    "\n",
    "  return cf_percentage\n",
    "\n",
    "\n",
    "def evaluate_model(model, testing_input_array, testing_label_array):\n",
    "  \"\"\"Calculates loss, makes predictions, and calculates Central Frequency (CF),\n",
    "  Mean Squared Error (MSE), Root Mean Squared Error(RMSE), Mean Absolute Error (MAE),\n",
    "  Median Absolute Error, and R-squared (R2)\n",
    "\n",
    "\tArgs:\n",
    "        model (tf.keras.model): The trained model\n",
    "\n",
    "        testing_input_array (array): Testing inputs\n",
    "\n",
    "        testing_label_array (array): Testing labels\n",
    "\t\"\"\"\n",
    "  print(\"Calculating Loss:\")\n",
    "  test_loss = model.evaluate(testing_input_array, testing_label_array, batch_size = len(testing_input_array))\n",
    "\n",
    "  print(\"Loss:\", test_loss)\n",
    "\n",
    "\n",
    "  print(\"\\nGenerating output predictions with model:\")\n",
    "  predictions = model.predict(testing_input_array, batch_size = len(testing_input_array))\n",
    "\n",
    "  # Calculate evaluation metrics\n",
    "  cf_15cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 15)\n",
    "  cf_5cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 5)\n",
    "  cf_1cm_percentage = calculate_central_frequency_percentage(testing_label_array, predictions, 1)\n",
    "  mse = mean_squared_error(testing_label_array, predictions)\n",
    "  rmse = root_mean_squared_error(testing_label_array, predictions)\n",
    "  mae = mean_absolute_error(testing_label_array, predictions)\n",
    "  medae = median_absolute_error(testing_label_array, predictions)\n",
    "  r2 = r2_score(testing_label_array, predictions)\n",
    "\n",
    "  print(\"\\nCentral Frequency Percentage 15cm:\", cf_15cm_percentage)\n",
    "  print(\"\\nCentral Frequency Percentage 5cm:\", cf_5cm_percentage)\n",
    "  print(\"\\nCentral Frequency Percentage 1cm:\", cf_1cm_percentage)\n",
    "  print(\"Mean Squared Error:\", mse)\n",
    "  print(\"Root Mean Squared Error:\", rmse)\n",
    "  print(\"Mean Absolute Error:\", mae)\n",
    "  print(\"Median Absolute Error:\", medae)\n",
    "  print(\"R-squared:\", r2)\n",
    "\n",
    "\n",
    "file_paths = {\n",
    "    'pi08': '/home/ryan/Downloads/pIsabel_pwl+wind_june2008-2009.csv',\n",
    "    'cg08': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_june2008-2009.csv',\n",
    "    'pi09': '/home/ryan/Downloads/pIsabel_pwl+wind+surge_mar2009-apr2010.csv',\n",
    "    'cg09': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_mar2009-apr2010.csv',\n",
    "    'pi11': '//home/ryan/Downloads/pIsabel_pwl+wind+surge_mar2011-apr2012.csv',\n",
    "    'cg11': '/home/ryan/Downloads/spiCoastGuard_pwl+wind+surge_mar2011-apr2012.csv',\n",
    "\n",
    "}\n",
    "\n",
    "datasets = {key: load_and_clean_csv(path) for key, path in file_paths.items()}\n",
    "\n",
    "for name, df in datasets.items():\n",
    "    datasets[name] = prepare_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "73934f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1143849/586016251.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['hour'] = df['date_time'].dt.floor('H')\n",
      "/tmp/ipykernel_1143849/586016251.py:8: FutureWarning: The provided callable <function nanmean at 0x75c095bb1a80> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  hourly_avg = df.groupby('hour')[['u', 'v']].agg(np.nanmean).reset_index()\n",
      "/tmp/ipykernel_1143849/586016251.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['hour'] = df['date_time'].dt.floor('H')\n",
      "/tmp/ipykernel_1143849/586016251.py:8: FutureWarning: The provided callable <function nanmean at 0x75c095bb1a80> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  hourly_avg = df.groupby('hour')[['u', 'v']].agg(np.nanmean).reset_index()\n",
      "/tmp/ipykernel_1143849/586016251.py:5: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  df['hour'] = df['date_time'].dt.floor('H')\n",
      "/tmp/ipykernel_1143849/586016251.py:8: FutureWarning: The provided callable <function nanmean at 0x75c095bb1a80> is currently using DataFrameGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"mean\" instead.\n",
      "  hourly_avg = df.groupby('hour')[['u', 'v']].agg(np.nanmean).reset_index()\n"
     ]
    }
   ],
   "source": [
    "for key in ['cg08', 'cg09', 'cg11']:\n",
    "    df = datasets[key].copy()\n",
    "    \n",
    "    # Floor datetimes to the hour\n",
    "    df['hour'] = df['date_time'].dt.floor('H')\n",
    "    \n",
    "    # Group by hourly bins and compute nanmean for u and v\n",
    "    hourly_avg = df.groupby('hour')[['u', 'v']].agg(np.nanmean).reset_index()\n",
    "    \n",
    "    # Rename 'hour' back to 'date_time' to match expected column\n",
    "    hourly_avg.rename(columns={'hour': 'date_time'}, inplace=True)\n",
    "    \n",
    "    datasets[f'{key}_uv_hourly'] = hourly_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7860cac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69257, 67) (69257,)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, indices_train = input_output_arrays(datasets['cg08'], datasets['pi08'],datasets['cg08_uv_hourly'], wl_half_window=30, wind_window=3)\n",
    "\n",
    "X_valid, y_valid, indices_valid = input_output_arrays(datasets['cg09'], datasets['pi09'], datasets['cg09_uv_hourly'], wl_half_window=30, wind_window=3)\n",
    "\n",
    "X_test, y_test, indices_test = input_output_arrays(datasets['cg11'], datasets['pi11'], datasets['cg11_uv_hourly'], wl_half_window=30, wind_window=3)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e725a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.02))\n",
    "model.add(Dense(1, kernel_initializer = 'normal' ))\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a72645b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - loss: 2.5507 - mae: 1.5755\n",
      "Epoch 1: val_loss improved from inf to 2.27419, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1s/step - loss: 2.5507 - mae: 1.5755 - val_loss: 2.2742 - val_mae: 1.4892\n",
      "Epoch 2/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 2.3152 - mae: 1.4995\n",
      "Epoch 2: val_loss improved from 2.27419 to 2.05575, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 2.3152 - mae: 1.4995 - val_loss: 2.0558 - val_mae: 1.4140\n",
      "Epoch 3/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.0956 - mae: 1.4248\n",
      "Epoch 3: val_loss improved from 2.05575 to 1.84998, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 2.0956 - mae: 1.4248 - val_loss: 1.8500 - val_mae: 1.3392\n",
      "Epoch 4/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.8862 - mae: 1.3496\n",
      "Epoch 4: val_loss improved from 1.84998 to 1.65683, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 1.8862 - mae: 1.3496 - val_loss: 1.6568 - val_mae: 1.2648\n",
      "Epoch 5/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 1.6894 - mae: 1.2747\n",
      "Epoch 5: val_loss improved from 1.65683 to 1.47606, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 1.6894 - mae: 1.2747 - val_loss: 1.4761 - val_mae: 1.1907\n",
      "Epoch 6/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.5079 - mae: 1.2010\n",
      "Epoch 6: val_loss improved from 1.47606 to 1.30735, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 1.5079 - mae: 1.2010 - val_loss: 1.3074 - val_mae: 1.1170\n",
      "Epoch 7/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 1.3374 - mae: 1.1274\n",
      "Epoch 7: val_loss improved from 1.30735 to 1.15049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 1.3374 - mae: 1.1274 - val_loss: 1.1505 - val_mae: 1.0437\n",
      "Epoch 8/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 1.1784 - mae: 1.0538\n",
      "Epoch 8: val_loss improved from 1.15049 to 1.00527, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 1.1784 - mae: 1.0538 - val_loss: 1.0053 - val_mae: 0.9706\n",
      "Epoch 9/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 1.0317 - mae: 0.9807\n",
      "Epoch 9: val_loss improved from 1.00527 to 0.87141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 1.0317 - mae: 0.9807 - val_loss: 0.8714 - val_mae: 0.8978\n",
      "Epoch 10/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.8970 - mae: 0.9081\n",
      "Epoch 10: val_loss improved from 0.87141 to 0.74868, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.8970 - mae: 0.9081 - val_loss: 0.7487 - val_mae: 0.8252\n",
      "Epoch 11/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.7727 - mae: 0.8353\n",
      "Epoch 11: val_loss improved from 0.74868 to 0.63692, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.7727 - mae: 0.8353 - val_loss: 0.6369 - val_mae: 0.7528\n",
      "Epoch 12/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.6593 - mae: 0.7627\n",
      "Epoch 12: val_loss improved from 0.63692 to 0.53602, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.6593 - mae: 0.7627 - val_loss: 0.5360 - val_mae: 0.6808\n",
      "Epoch 13/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.5574 - mae: 0.6907\n",
      "Epoch 13: val_loss improved from 0.53602 to 0.44586, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.5574 - mae: 0.6907 - val_loss: 0.4459 - val_mae: 0.6095\n",
      "Epoch 14/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.4654 - mae: 0.6197\n",
      "Epoch 14: val_loss improved from 0.44586 to 0.36628, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.4654 - mae: 0.6197 - val_loss: 0.3663 - val_mae: 0.5394\n",
      "Epoch 15/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.3849 - mae: 0.5511\n",
      "Epoch 15: val_loss improved from 0.36628 to 0.29712, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3849 - mae: 0.5511 - val_loss: 0.2971 - val_mae: 0.4722\n",
      "Epoch 16/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.3152 - mae: 0.4868\n",
      "Epoch 16: val_loss improved from 0.29712 to 0.23818, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.3152 - mae: 0.4868 - val_loss: 0.2382 - val_mae: 0.4101\n",
      "Epoch 17/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.2553 - mae: 0.4290\n",
      "Epoch 17: val_loss improved from 0.23818 to 0.18918, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.2553 - mae: 0.4290 - val_loss: 0.1892 - val_mae: 0.3557\n",
      "Epoch 18/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.2057 - mae: 0.3796\n",
      "Epoch 18: val_loss improved from 0.18918 to 0.14971, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.2057 - mae: 0.3796 - val_loss: 0.1497 - val_mae: 0.3109\n",
      "Epoch 19/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1652 - mae: 0.3381\n",
      "Epoch 19: val_loss improved from 0.14971 to 0.11930, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.1652 - mae: 0.3381 - val_loss: 0.1193 - val_mae: 0.2769\n",
      "Epoch 20/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1346 - mae: 0.3059\n",
      "Epoch 20: val_loss improved from 0.11930 to 0.09730, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.1346 - mae: 0.3059 - val_loss: 0.0973 - val_mae: 0.2535\n",
      "Epoch 21/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.1129 - mae: 0.2819\n",
      "Epoch 21: val_loss improved from 0.09730 to 0.08282, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.1129 - mae: 0.2819 - val_loss: 0.0828 - val_mae: 0.2389\n",
      "Epoch 22/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0976 - mae: 0.2645\n",
      "Epoch 22: val_loss improved from 0.08282 to 0.07479, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0976 - mae: 0.2645 - val_loss: 0.0748 - val_mae: 0.2310\n",
      "Epoch 23/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0898 - mae: 0.2525\n",
      "Epoch 23: val_loss improved from 0.07479 to 0.07192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0898 - mae: 0.2525 - val_loss: 0.0719 - val_mae: 0.2276\n",
      "Epoch 24/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0876 - mae: 0.2461\n",
      "Epoch 24: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0876 - mae: 0.2461 - val_loss: 0.0728 - val_mae: 0.2274\n",
      "Epoch 25/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0894 - mae: 0.2441\n",
      "Epoch 25: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0894 - mae: 0.2441 - val_loss: 0.0760 - val_mae: 0.2293\n",
      "Epoch 26/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0927 - mae: 0.2439\n",
      "Epoch 26: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0927 - mae: 0.2439 - val_loss: 0.0802 - val_mae: 0.2324\n",
      "Epoch 27/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0978 - mae: 0.2476\n",
      "Epoch 27: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0978 - mae: 0.2476 - val_loss: 0.0840 - val_mae: 0.2357\n",
      "Epoch 28/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.1020 - mae: 0.2521\n",
      "Epoch 28: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.1020 - mae: 0.2521 - val_loss: 0.0866 - val_mae: 0.2383\n",
      "Epoch 29/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.1052 - mae: 0.2566\n",
      "Epoch 29: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.1052 - mae: 0.2566 - val_loss: 0.0872 - val_mae: 0.2395\n",
      "Epoch 30/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.1068 - mae: 0.2607\n",
      "Epoch 30: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1068 - mae: 0.2607 - val_loss: 0.0856 - val_mae: 0.2383\n",
      "Epoch 31/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.1050 - mae: 0.2607\n",
      "Epoch 31: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.1050 - mae: 0.2607 - val_loss: 0.0818 - val_mae: 0.2344\n",
      "Epoch 32/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.1013 - mae: 0.2585\n",
      "Epoch 32: val_loss did not improve from 0.07192\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.1013 - mae: 0.2585 - val_loss: 0.0760 - val_mae: 0.2271\n",
      "Epoch 33/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0953 - mae: 0.2526\n",
      "Epoch 33: val_loss improved from 0.07192 to 0.06871, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0953 - mae: 0.2526 - val_loss: 0.0687 - val_mae: 0.2166\n",
      "Epoch 34/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0880 - mae: 0.2439\n",
      "Epoch 34: val_loss improved from 0.06871 to 0.06050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0880 - mae: 0.2439 - val_loss: 0.0605 - val_mae: 0.2031\n",
      "Epoch 35/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0794 - mae: 0.2322\n",
      "Epoch 35: val_loss improved from 0.06050 to 0.05192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0794 - mae: 0.2322 - val_loss: 0.0519 - val_mae: 0.1874\n",
      "Epoch 36/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0700 - mae: 0.2179\n",
      "Epoch 36: val_loss improved from 0.05192 to 0.04352, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0700 - mae: 0.2179 - val_loss: 0.0435 - val_mae: 0.1700\n",
      "Epoch 37/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0608 - mae: 0.2024\n",
      "Epoch 37: val_loss improved from 0.04352 to 0.03575, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0608 - mae: 0.2024 - val_loss: 0.0358 - val_mae: 0.1519\n",
      "Epoch 38/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0521 - mae: 0.1861\n",
      "Epoch 38: val_loss improved from 0.03575 to 0.02896, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0521 - mae: 0.1861 - val_loss: 0.0290 - val_mae: 0.1342\n",
      "Epoch 39/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0446 - mae: 0.1703\n",
      "Epoch 39: val_loss improved from 0.02896 to 0.02336, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0446 - mae: 0.1703 - val_loss: 0.0234 - val_mae: 0.1184\n",
      "Epoch 40/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0379 - mae: 0.1548\n",
      "Epoch 40: val_loss improved from 0.02336 to 0.01904, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0379 - mae: 0.1548 - val_loss: 0.0190 - val_mae: 0.1058\n",
      "Epoch 41/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0327 - mae: 0.1415\n",
      "Epoch 41: val_loss improved from 0.01904 to 0.01601, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0327 - mae: 0.1415 - val_loss: 0.0160 - val_mae: 0.0971\n",
      "Epoch 42/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0286 - mae: 0.1304\n",
      "Epoch 42: val_loss improved from 0.01601 to 0.01416, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0286 - mae: 0.1304 - val_loss: 0.0142 - val_mae: 0.0926\n",
      "Epoch 43/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0257 - mae: 0.1223\n",
      "Epoch 43: val_loss improved from 0.01416 to 0.01336, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0257 - mae: 0.1223 - val_loss: 0.0134 - val_mae: 0.0918\n",
      "Epoch 44/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0241 - mae: 0.1174\n",
      "Epoch 44: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0241 - mae: 0.1174 - val_loss: 0.0134 - val_mae: 0.0937\n",
      "Epoch 45/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0232 - mae: 0.1150\n",
      "Epoch 45: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0232 - mae: 0.1150 - val_loss: 0.0141 - val_mae: 0.0973\n",
      "Epoch 46/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0230 - mae: 0.1141\n",
      "Epoch 46: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0230 - mae: 0.1141 - val_loss: 0.0152 - val_mae: 0.1020\n",
      "Epoch 47/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0236 - mae: 0.1155\n",
      "Epoch 47: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0236 - mae: 0.1155 - val_loss: 0.0165 - val_mae: 0.1070\n",
      "Epoch 48/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0239 - mae: 0.1166\n",
      "Epoch 48: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0239 - mae: 0.1166 - val_loss: 0.0179 - val_mae: 0.1120\n",
      "Epoch 49/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0249 - mae: 0.1191\n",
      "Epoch 49: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0249 - mae: 0.1191 - val_loss: 0.0192 - val_mae: 0.1165\n",
      "Epoch 50/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0259 - mae: 0.1215\n",
      "Epoch 50: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0259 - mae: 0.1215 - val_loss: 0.0203 - val_mae: 0.1203\n",
      "Epoch 51/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0264 - mae: 0.1234\n",
      "Epoch 51: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0264 - mae: 0.1234 - val_loss: 0.0211 - val_mae: 0.1231\n",
      "Epoch 52/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0272 - mae: 0.1252\n",
      "Epoch 52: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0272 - mae: 0.1252 - val_loss: 0.0216 - val_mae: 0.1248\n",
      "Epoch 53/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0277 - mae: 0.1264\n",
      "Epoch 53: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0277 - mae: 0.1264 - val_loss: 0.0217 - val_mae: 0.1254\n",
      "Epoch 54/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0278 - mae: 0.1265\n",
      "Epoch 54: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0278 - mae: 0.1265 - val_loss: 0.0216 - val_mae: 0.1250\n",
      "Epoch 55/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0271 - mae: 0.1250\n",
      "Epoch 55: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0271 - mae: 0.1250 - val_loss: 0.0211 - val_mae: 0.1235\n",
      "Epoch 56/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0268 - mae: 0.1239\n",
      "Epoch 56: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0268 - mae: 0.1239 - val_loss: 0.0204 - val_mae: 0.1211\n",
      "Epoch 57/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0260 - mae: 0.1216\n",
      "Epoch 57: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0260 - mae: 0.1216 - val_loss: 0.0196 - val_mae: 0.1180\n",
      "Epoch 58/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0255 - mae: 0.1194\n",
      "Epoch 58: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0255 - mae: 0.1194 - val_loss: 0.0186 - val_mae: 0.1144\n",
      "Epoch 59/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0248 - mae: 0.1169\n",
      "Epoch 59: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0248 - mae: 0.1169 - val_loss: 0.0176 - val_mae: 0.1103\n",
      "Epoch 60/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0239 - mae: 0.1137\n",
      "Epoch 60: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0239 - mae: 0.1137 - val_loss: 0.0165 - val_mae: 0.1060\n",
      "Epoch 61/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0225 - mae: 0.1098\n",
      "Epoch 61: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 134ms/step - loss: 0.0225 - mae: 0.1098 - val_loss: 0.0155 - val_mae: 0.1016\n",
      "Epoch 62/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0224 - mae: 0.1079\n",
      "Epoch 62: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0224 - mae: 0.1079 - val_loss: 0.0146 - val_mae: 0.0973\n",
      "Epoch 63/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0216 - mae: 0.1053\n",
      "Epoch 63: val_loss did not improve from 0.01336\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0216 - mae: 0.1053 - val_loss: 0.0138 - val_mae: 0.0932\n",
      "Epoch 64/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0214 - mae: 0.1035\n",
      "Epoch 64: val_loss improved from 0.01336 to 0.01306, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0214 - mae: 0.1035 - val_loss: 0.0131 - val_mae: 0.0893\n",
      "Epoch 65/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0207 - mae: 0.1015\n",
      "Epoch 65: val_loss improved from 0.01306 to 0.01244, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0207 - mae: 0.1015 - val_loss: 0.0124 - val_mae: 0.0859\n",
      "Epoch 66/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0204 - mae: 0.1000\n",
      "Epoch 66: val_loss improved from 0.01244 to 0.01192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0204 - mae: 0.1000 - val_loss: 0.0119 - val_mae: 0.0828\n",
      "Epoch 67/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0200 - mae: 0.0989\n",
      "Epoch 67: val_loss improved from 0.01192 to 0.01147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0200 - mae: 0.0989 - val_loss: 0.0115 - val_mae: 0.0801\n",
      "Epoch 68/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0198 - mae: 0.0983\n",
      "Epoch 68: val_loss improved from 0.01147 to 0.01109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0198 - mae: 0.0983 - val_loss: 0.0111 - val_mae: 0.0778\n",
      "Epoch 69/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0197 - mae: 0.0979\n",
      "Epoch 69: val_loss improved from 0.01109 to 0.01074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0197 - mae: 0.0979 - val_loss: 0.0107 - val_mae: 0.0758\n",
      "Epoch 70/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0196 - mae: 0.0978\n",
      "Epoch 70: val_loss improved from 0.01074 to 0.01042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0196 - mae: 0.0978 - val_loss: 0.0104 - val_mae: 0.0741\n",
      "Epoch 71/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0193 - mae: 0.0974\n",
      "Epoch 71: val_loss improved from 0.01042 to 0.01011, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0193 - mae: 0.0974 - val_loss: 0.0101 - val_mae: 0.0726\n",
      "Epoch 72/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0193 - mae: 0.0977\n",
      "Epoch 72: val_loss improved from 0.01011 to 0.00979, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0193 - mae: 0.0977 - val_loss: 0.0098 - val_mae: 0.0712\n",
      "Epoch 73/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0190 - mae: 0.0969\n",
      "Epoch 73: val_loss improved from 0.00979 to 0.00948, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0190 - mae: 0.0969 - val_loss: 0.0095 - val_mae: 0.0700\n",
      "Epoch 74/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0187 - mae: 0.0964\n",
      "Epoch 74: val_loss improved from 0.00948 to 0.00915, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0187 - mae: 0.0964 - val_loss: 0.0092 - val_mae: 0.0690\n",
      "Epoch 75/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0185 - mae: 0.0958\n",
      "Epoch 75: val_loss improved from 0.00915 to 0.00884, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0185 - mae: 0.0958 - val_loss: 0.0088 - val_mae: 0.0680\n",
      "Epoch 76/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0183 - mae: 0.0951\n",
      "Epoch 76: val_loss improved from 0.00884 to 0.00853, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0183 - mae: 0.0951 - val_loss: 0.0085 - val_mae: 0.0671\n",
      "Epoch 77/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0182 - mae: 0.0947\n",
      "Epoch 77: val_loss improved from 0.00853 to 0.00823, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0182 - mae: 0.0947 - val_loss: 0.0082 - val_mae: 0.0664\n",
      "Epoch 78/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0176 - mae: 0.0933\n",
      "Epoch 78: val_loss improved from 0.00823 to 0.00796, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0176 - mae: 0.0933 - val_loss: 0.0080 - val_mae: 0.0658\n",
      "Epoch 79/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0176 - mae: 0.0929\n",
      "Epoch 79: val_loss improved from 0.00796 to 0.00771, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0176 - mae: 0.0929 - val_loss: 0.0077 - val_mae: 0.0653\n",
      "Epoch 80/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0170 - mae: 0.0914\n",
      "Epoch 80: val_loss improved from 0.00771 to 0.00749, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0170 - mae: 0.0914 - val_loss: 0.0075 - val_mae: 0.0649\n",
      "Epoch 81/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0169 - mae: 0.0905\n",
      "Epoch 81: val_loss improved from 0.00749 to 0.00731, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0169 - mae: 0.0905 - val_loss: 0.0073 - val_mae: 0.0646\n",
      "Epoch 82/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0168 - mae: 0.0900\n",
      "Epoch 82: val_loss improved from 0.00731 to 0.00715, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0168 - mae: 0.0900 - val_loss: 0.0071 - val_mae: 0.0644\n",
      "Epoch 83/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0165 - mae: 0.0892\n",
      "Epoch 83: val_loss improved from 0.00715 to 0.00702, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0165 - mae: 0.0892 - val_loss: 0.0070 - val_mae: 0.0642\n",
      "Epoch 84/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0166 - mae: 0.0889\n",
      "Epoch 84: val_loss improved from 0.00702 to 0.00691, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0166 - mae: 0.0889 - val_loss: 0.0069 - val_mae: 0.0641\n",
      "Epoch 85/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0163 - mae: 0.0882\n",
      "Epoch 85: val_loss improved from 0.00691 to 0.00681, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0163 - mae: 0.0882 - val_loss: 0.0068 - val_mae: 0.0640\n",
      "Epoch 86/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0158 - mae: 0.0868\n",
      "Epoch 86: val_loss improved from 0.00681 to 0.00672, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0158 - mae: 0.0868 - val_loss: 0.0067 - val_mae: 0.0638\n",
      "Epoch 87/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0160 - mae: 0.0871\n",
      "Epoch 87: val_loss improved from 0.00672 to 0.00663, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0160 - mae: 0.0871 - val_loss: 0.0066 - val_mae: 0.0636\n",
      "Epoch 88/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0158 - mae: 0.0862\n",
      "Epoch 88: val_loss improved from 0.00663 to 0.00654, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0158 - mae: 0.0862 - val_loss: 0.0065 - val_mae: 0.0633\n",
      "Epoch 89/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0158 - mae: 0.0861\n",
      "Epoch 89: val_loss improved from 0.00654 to 0.00644, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0158 - mae: 0.0861 - val_loss: 0.0064 - val_mae: 0.0628\n",
      "Epoch 90/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0158 - mae: 0.0858\n",
      "Epoch 90: val_loss improved from 0.00644 to 0.00634, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0158 - mae: 0.0858 - val_loss: 0.0063 - val_mae: 0.0623\n",
      "Epoch 91/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0155 - mae: 0.0851\n",
      "Epoch 91: val_loss improved from 0.00634 to 0.00622, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0155 - mae: 0.0851 - val_loss: 0.0062 - val_mae: 0.0617\n",
      "Epoch 92/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0156 - mae: 0.0849\n",
      "Epoch 92: val_loss improved from 0.00622 to 0.00610, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0156 - mae: 0.0849 - val_loss: 0.0061 - val_mae: 0.0610\n",
      "Epoch 93/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0156 - mae: 0.0843\n",
      "Epoch 93: val_loss improved from 0.00610 to 0.00597, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0156 - mae: 0.0843 - val_loss: 0.0060 - val_mae: 0.0602\n",
      "Epoch 94/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0150 - mae: 0.0833\n",
      "Epoch 94: val_loss improved from 0.00597 to 0.00584, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0150 - mae: 0.0833 - val_loss: 0.0058 - val_mae: 0.0593\n",
      "Epoch 95/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0150 - mae: 0.0831\n",
      "Epoch 95: val_loss improved from 0.00584 to 0.00571, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0150 - mae: 0.0831 - val_loss: 0.0057 - val_mae: 0.0584\n",
      "Epoch 96/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0148 - mae: 0.0823\n",
      "Epoch 96: val_loss improved from 0.00571 to 0.00558, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0148 - mae: 0.0823 - val_loss: 0.0056 - val_mae: 0.0575\n",
      "Epoch 97/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0150 - mae: 0.0825\n",
      "Epoch 97: val_loss improved from 0.00558 to 0.00546, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0150 - mae: 0.0825 - val_loss: 0.0055 - val_mae: 0.0566\n",
      "Epoch 98/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0146 - mae: 0.0816\n",
      "Epoch 98: val_loss improved from 0.00546 to 0.00534, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0146 - mae: 0.0816 - val_loss: 0.0053 - val_mae: 0.0557\n",
      "Epoch 99/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0146 - mae: 0.0814\n",
      "Epoch 99: val_loss improved from 0.00534 to 0.00523, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0146 - mae: 0.0814 - val_loss: 0.0052 - val_mae: 0.0549\n",
      "Epoch 100/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0144 - mae: 0.0811\n",
      "Epoch 100: val_loss improved from 0.00523 to 0.00513, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0144 - mae: 0.0811 - val_loss: 0.0051 - val_mae: 0.0541\n",
      "Epoch 101/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0147 - mae: 0.0814\n",
      "Epoch 101: val_loss improved from 0.00513 to 0.00503, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0147 - mae: 0.0814 - val_loss: 0.0050 - val_mae: 0.0533\n",
      "Epoch 102/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0142 - mae: 0.0805\n",
      "Epoch 102: val_loss improved from 0.00503 to 0.00494, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0142 - mae: 0.0805 - val_loss: 0.0049 - val_mae: 0.0526\n",
      "Epoch 103/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0141 - mae: 0.0801\n",
      "Epoch 103: val_loss improved from 0.00494 to 0.00486, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0141 - mae: 0.0801 - val_loss: 0.0049 - val_mae: 0.0520\n",
      "Epoch 104/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0143 - mae: 0.0803\n",
      "Epoch 104: val_loss improved from 0.00486 to 0.00479, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0143 - mae: 0.0803 - val_loss: 0.0048 - val_mae: 0.0514\n",
      "Epoch 105/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0141 - mae: 0.0798\n",
      "Epoch 105: val_loss improved from 0.00479 to 0.00472, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0141 - mae: 0.0798 - val_loss: 0.0047 - val_mae: 0.0509\n",
      "Epoch 106/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0139 - mae: 0.0793\n",
      "Epoch 106: val_loss improved from 0.00472 to 0.00465, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0139 - mae: 0.0793 - val_loss: 0.0047 - val_mae: 0.0504\n",
      "Epoch 107/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0138 - mae: 0.0791\n",
      "Epoch 107: val_loss improved from 0.00465 to 0.00459, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0138 - mae: 0.0791 - val_loss: 0.0046 - val_mae: 0.0500\n",
      "Epoch 108/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0139 - mae: 0.0792\n",
      "Epoch 108: val_loss improved from 0.00459 to 0.00452, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0139 - mae: 0.0792 - val_loss: 0.0045 - val_mae: 0.0496\n",
      "Epoch 109/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0138 - mae: 0.0786\n",
      "Epoch 109: val_loss improved from 0.00452 to 0.00446, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0138 - mae: 0.0786 - val_loss: 0.0045 - val_mae: 0.0492\n",
      "Epoch 110/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0137 - mae: 0.0785\n",
      "Epoch 110: val_loss improved from 0.00446 to 0.00441, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0137 - mae: 0.0785 - val_loss: 0.0044 - val_mae: 0.0489\n",
      "Epoch 111/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0134 - mae: 0.0776\n",
      "Epoch 111: val_loss improved from 0.00441 to 0.00435, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0134 - mae: 0.0776 - val_loss: 0.0044 - val_mae: 0.0486\n",
      "Epoch 112/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0135 - mae: 0.0773\n",
      "Epoch 112: val_loss improved from 0.00435 to 0.00430, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0135 - mae: 0.0773 - val_loss: 0.0043 - val_mae: 0.0483\n",
      "Epoch 113/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0133 - mae: 0.0767\n",
      "Epoch 113: val_loss improved from 0.00430 to 0.00424, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0133 - mae: 0.0767 - val_loss: 0.0042 - val_mae: 0.0480\n",
      "Epoch 114/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0133 - mae: 0.0763\n",
      "Epoch 114: val_loss improved from 0.00424 to 0.00419, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0133 - mae: 0.0763 - val_loss: 0.0042 - val_mae: 0.0478\n",
      "Epoch 115/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0131 - mae: 0.0757\n",
      "Epoch 115: val_loss improved from 0.00419 to 0.00414, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0131 - mae: 0.0757 - val_loss: 0.0041 - val_mae: 0.0475\n",
      "Epoch 116/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0131 - mae: 0.0752\n",
      "Epoch 116: val_loss improved from 0.00414 to 0.00410, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0131 - mae: 0.0752 - val_loss: 0.0041 - val_mae: 0.0473\n",
      "Epoch 117/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0132 - mae: 0.0752\n",
      "Epoch 117: val_loss improved from 0.00410 to 0.00405, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0132 - mae: 0.0752 - val_loss: 0.0041 - val_mae: 0.0471\n",
      "Epoch 118/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0132 - mae: 0.0752\n",
      "Epoch 118: val_loss improved from 0.00405 to 0.00401, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0132 - mae: 0.0752 - val_loss: 0.0040 - val_mae: 0.0469\n",
      "Epoch 119/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0131 - mae: 0.0746\n",
      "Epoch 119: val_loss improved from 0.00401 to 0.00396, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0131 - mae: 0.0746 - val_loss: 0.0040 - val_mae: 0.0466\n",
      "Epoch 120/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0128 - mae: 0.0736\n",
      "Epoch 120: val_loss improved from 0.00396 to 0.00392, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0128 - mae: 0.0736 - val_loss: 0.0039 - val_mae: 0.0464\n",
      "Epoch 121/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0130 - mae: 0.0739\n",
      "Epoch 121: val_loss improved from 0.00392 to 0.00387, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0130 - mae: 0.0739 - val_loss: 0.0039 - val_mae: 0.0461\n",
      "Epoch 122/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0129 - mae: 0.0739\n",
      "Epoch 122: val_loss improved from 0.00387 to 0.00383, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0129 - mae: 0.0739 - val_loss: 0.0038 - val_mae: 0.0459\n",
      "Epoch 123/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0128 - mae: 0.0733\n",
      "Epoch 123: val_loss improved from 0.00383 to 0.00378, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0128 - mae: 0.0733 - val_loss: 0.0038 - val_mae: 0.0456\n",
      "Epoch 124/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0127 - mae: 0.0731\n",
      "Epoch 124: val_loss improved from 0.00378 to 0.00373, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0127 - mae: 0.0731 - val_loss: 0.0037 - val_mae: 0.0453\n",
      "Epoch 125/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0126 - mae: 0.0727\n",
      "Epoch 125: val_loss improved from 0.00373 to 0.00369, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0126 - mae: 0.0727 - val_loss: 0.0037 - val_mae: 0.0450\n",
      "Epoch 126/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0125 - mae: 0.0723\n",
      "Epoch 126: val_loss improved from 0.00369 to 0.00364, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0125 - mae: 0.0723 - val_loss: 0.0036 - val_mae: 0.0447\n",
      "Epoch 127/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0127 - mae: 0.0727\n",
      "Epoch 127: val_loss improved from 0.00364 to 0.00359, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0127 - mae: 0.0727 - val_loss: 0.0036 - val_mae: 0.0443\n",
      "Epoch 128/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0126 - mae: 0.0724\n",
      "Epoch 128: val_loss improved from 0.00359 to 0.00354, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0126 - mae: 0.0724 - val_loss: 0.0035 - val_mae: 0.0440\n",
      "Epoch 129/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0124 - mae: 0.0721\n",
      "Epoch 129: val_loss improved from 0.00354 to 0.00349, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0124 - mae: 0.0721 - val_loss: 0.0035 - val_mae: 0.0437\n",
      "Epoch 130/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0123 - mae: 0.0718\n",
      "Epoch 130: val_loss improved from 0.00349 to 0.00344, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0123 - mae: 0.0718 - val_loss: 0.0034 - val_mae: 0.0433\n",
      "Epoch 131/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0120 - mae: 0.0711\n",
      "Epoch 131: val_loss improved from 0.00344 to 0.00338, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0120 - mae: 0.0711 - val_loss: 0.0034 - val_mae: 0.0429\n",
      "Epoch 132/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0122 - mae: 0.0717\n",
      "Epoch 132: val_loss improved from 0.00338 to 0.00332, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0122 - mae: 0.0717 - val_loss: 0.0033 - val_mae: 0.0424\n",
      "Epoch 133/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0122 - mae: 0.0716\n",
      "Epoch 133: val_loss improved from 0.00332 to 0.00325, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0122 - mae: 0.0716 - val_loss: 0.0033 - val_mae: 0.0418\n",
      "Epoch 134/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0120 - mae: 0.0714\n",
      "Epoch 134: val_loss improved from 0.00325 to 0.00323, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0120 - mae: 0.0714 - val_loss: 0.0032 - val_mae: 0.0413\n",
      "Epoch 135/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0119 - mae: 0.0722\n",
      "Epoch 135: val_loss did not improve from 0.00323\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0119 - mae: 0.0722 - val_loss: 0.0032 - val_mae: 0.0411\n",
      "Epoch 136/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0119 - mae: 0.0731\n",
      "Epoch 136: val_loss improved from 0.00323 to 0.00320, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0119 - mae: 0.0731 - val_loss: 0.0032 - val_mae: 0.0409\n",
      "Epoch 137/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0118 - mae: 0.0727\n",
      "Epoch 137: val_loss improved from 0.00320 to 0.00313, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0118 - mae: 0.0727 - val_loss: 0.0031 - val_mae: 0.0406\n",
      "Epoch 138/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0118 - mae: 0.0717\n",
      "Epoch 138: val_loss improved from 0.00313 to 0.00307, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0118 - mae: 0.0717 - val_loss: 0.0031 - val_mae: 0.0405\n",
      "Epoch 139/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0120 - mae: 0.0714\n",
      "Epoch 139: val_loss improved from 0.00307 to 0.00302, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0120 - mae: 0.0714 - val_loss: 0.0030 - val_mae: 0.0406\n",
      "Epoch 140/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0117 - mae: 0.0699\n",
      "Epoch 140: val_loss improved from 0.00302 to 0.00299, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0117 - mae: 0.0699 - val_loss: 0.0030 - val_mae: 0.0406\n",
      "Epoch 141/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0116 - mae: 0.0691\n",
      "Epoch 141: val_loss improved from 0.00299 to 0.00295, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0116 - mae: 0.0691 - val_loss: 0.0030 - val_mae: 0.0404\n",
      "Epoch 142/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0115 - mae: 0.0688\n",
      "Epoch 142: val_loss improved from 0.00295 to 0.00291, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0115 - mae: 0.0688 - val_loss: 0.0029 - val_mae: 0.0401\n",
      "Epoch 143/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0114 - mae: 0.0684\n",
      "Epoch 143: val_loss improved from 0.00291 to 0.00287, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0114 - mae: 0.0684 - val_loss: 0.0029 - val_mae: 0.0398\n",
      "Epoch 144/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0115 - mae: 0.0693\n",
      "Epoch 144: val_loss improved from 0.00287 to 0.00286, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0115 - mae: 0.0693 - val_loss: 0.0029 - val_mae: 0.0396\n",
      "Epoch 145/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0695\n",
      "Epoch 145: val_loss improved from 0.00286 to 0.00285, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0113 - mae: 0.0695 - val_loss: 0.0028 - val_mae: 0.0394\n",
      "Epoch 146/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0696\n",
      "Epoch 146: val_loss improved from 0.00285 to 0.00282, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0112 - mae: 0.0696 - val_loss: 0.0028 - val_mae: 0.0393\n",
      "Epoch 147/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0696\n",
      "Epoch 147: val_loss improved from 0.00282 to 0.00278, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0113 - mae: 0.0696 - val_loss: 0.0028 - val_mae: 0.0391\n",
      "Epoch 148/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0113 - mae: 0.0690\n",
      "Epoch 148: val_loss improved from 0.00278 to 0.00274, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0113 - mae: 0.0690 - val_loss: 0.0027 - val_mae: 0.0389\n",
      "Epoch 149/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0112 - mae: 0.0681\n",
      "Epoch 149: val_loss improved from 0.00274 to 0.00271, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0112 - mae: 0.0681 - val_loss: 0.0027 - val_mae: 0.0389\n",
      "Epoch 150/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0112 - mae: 0.0675\n",
      "Epoch 150: val_loss improved from 0.00271 to 0.00268, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0112 - mae: 0.0675 - val_loss: 0.0027 - val_mae: 0.0388\n",
      "Epoch 151/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0111 - mae: 0.0668\n",
      "Epoch 151: val_loss improved from 0.00268 to 0.00266, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0111 - mae: 0.0668 - val_loss: 0.0027 - val_mae: 0.0386\n",
      "Epoch 152/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0109 - mae: 0.0667\n",
      "Epoch 152: val_loss improved from 0.00266 to 0.00263, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0109 - mae: 0.0667 - val_loss: 0.0026 - val_mae: 0.0383\n",
      "Epoch 153/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0110 - mae: 0.0671\n",
      "Epoch 153: val_loss improved from 0.00263 to 0.00262, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0110 - mae: 0.0671 - val_loss: 0.0026 - val_mae: 0.0381\n",
      "Epoch 154/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0110 - mae: 0.0675\n",
      "Epoch 154: val_loss improved from 0.00262 to 0.00260, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0110 - mae: 0.0675 - val_loss: 0.0026 - val_mae: 0.0380\n",
      "Epoch 155/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0109 - mae: 0.0678\n",
      "Epoch 155: val_loss improved from 0.00260 to 0.00257, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0109 - mae: 0.0678 - val_loss: 0.0026 - val_mae: 0.0378\n",
      "Epoch 156/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0108 - mae: 0.0674\n",
      "Epoch 156: val_loss improved from 0.00257 to 0.00253, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0108 - mae: 0.0674 - val_loss: 0.0025 - val_mae: 0.0377\n",
      "Epoch 157/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0108 - mae: 0.0669\n",
      "Epoch 157: val_loss improved from 0.00253 to 0.00250, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0108 - mae: 0.0669 - val_loss: 0.0025 - val_mae: 0.0375\n",
      "Epoch 158/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0110 - mae: 0.0666\n",
      "Epoch 158: val_loss improved from 0.00250 to 0.00247, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0110 - mae: 0.0666 - val_loss: 0.0025 - val_mae: 0.0375\n",
      "Epoch 159/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0105 - mae: 0.0650\n",
      "Epoch 159: val_loss improved from 0.00247 to 0.00245, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0105 - mae: 0.0650 - val_loss: 0.0024 - val_mae: 0.0373\n",
      "Epoch 160/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0107 - mae: 0.0654\n",
      "Epoch 160: val_loss improved from 0.00245 to 0.00242, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0107 - mae: 0.0654 - val_loss: 0.0024 - val_mae: 0.0371\n",
      "Epoch 161/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0104 - mae: 0.0648\n",
      "Epoch 161: val_loss improved from 0.00242 to 0.00240, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0104 - mae: 0.0648 - val_loss: 0.0024 - val_mae: 0.0369\n",
      "Epoch 162/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0654\n",
      "Epoch 162: val_loss improved from 0.00240 to 0.00239, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0105 - mae: 0.0654 - val_loss: 0.0024 - val_mae: 0.0366\n",
      "Epoch 163/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0107 - mae: 0.0661\n",
      "Epoch 163: val_loss improved from 0.00239 to 0.00237, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0107 - mae: 0.0661 - val_loss: 0.0024 - val_mae: 0.0365\n",
      "Epoch 164/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0106 - mae: 0.0661\n",
      "Epoch 164: val_loss improved from 0.00237 to 0.00234, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0106 - mae: 0.0661 - val_loss: 0.0023 - val_mae: 0.0363\n",
      "Epoch 165/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0105 - mae: 0.0659\n",
      "Epoch 165: val_loss improved from 0.00234 to 0.00232, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0105 - mae: 0.0659 - val_loss: 0.0023 - val_mae: 0.0361\n",
      "Epoch 166/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0105 - mae: 0.0652\n",
      "Epoch 166: val_loss improved from 0.00232 to 0.00229, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0105 - mae: 0.0652 - val_loss: 0.0023 - val_mae: 0.0360\n",
      "Epoch 167/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0105 - mae: 0.0649\n",
      "Epoch 167: val_loss improved from 0.00229 to 0.00227, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0105 - mae: 0.0649 - val_loss: 0.0023 - val_mae: 0.0359\n",
      "Epoch 168/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0106 - mae: 0.0649\n",
      "Epoch 168: val_loss improved from 0.00227 to 0.00225, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0106 - mae: 0.0649 - val_loss: 0.0022 - val_mae: 0.0357\n",
      "Epoch 169/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0105 - mae: 0.0647\n",
      "Epoch 169: val_loss improved from 0.00225 to 0.00223, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0105 - mae: 0.0647 - val_loss: 0.0022 - val_mae: 0.0355\n",
      "Epoch 170/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0102 - mae: 0.0644\n",
      "Epoch 170: val_loss improved from 0.00223 to 0.00221, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0102 - mae: 0.0644 - val_loss: 0.0022 - val_mae: 0.0353\n",
      "Epoch 171/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0104 - mae: 0.0649\n",
      "Epoch 171: val_loss improved from 0.00221 to 0.00219, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0104 - mae: 0.0649 - val_loss: 0.0022 - val_mae: 0.0351\n",
      "Epoch 172/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0104 - mae: 0.0648\n",
      "Epoch 172: val_loss improved from 0.00219 to 0.00216, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0104 - mae: 0.0648 - val_loss: 0.0022 - val_mae: 0.0350\n",
      "Epoch 173/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0103 - mae: 0.0643\n",
      "Epoch 173: val_loss improved from 0.00216 to 0.00214, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0103 - mae: 0.0643 - val_loss: 0.0021 - val_mae: 0.0349\n",
      "Epoch 174/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0103 - mae: 0.0641\n",
      "Epoch 174: val_loss improved from 0.00214 to 0.00212, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0103 - mae: 0.0641 - val_loss: 0.0021 - val_mae: 0.0347\n",
      "Epoch 175/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0101 - mae: 0.0635\n",
      "Epoch 175: val_loss improved from 0.00212 to 0.00210, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0101 - mae: 0.0635 - val_loss: 0.0021 - val_mae: 0.0346\n",
      "Epoch 176/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0101 - mae: 0.0633\n",
      "Epoch 176: val_loss improved from 0.00210 to 0.00208, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0101 - mae: 0.0633 - val_loss: 0.0021 - val_mae: 0.0344\n",
      "Epoch 177/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0101 - mae: 0.0633\n",
      "Epoch 177: val_loss improved from 0.00208 to 0.00206, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0101 - mae: 0.0633 - val_loss: 0.0021 - val_mae: 0.0342\n",
      "Epoch 178/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0102 - mae: 0.0636\n",
      "Epoch 178: val_loss improved from 0.00206 to 0.00205, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0102 - mae: 0.0636 - val_loss: 0.0020 - val_mae: 0.0341\n",
      "Epoch 179/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0634\n",
      "Epoch 179: val_loss improved from 0.00205 to 0.00203, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0100 - mae: 0.0634 - val_loss: 0.0020 - val_mae: 0.0339\n",
      "Epoch 180/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0631\n",
      "Epoch 180: val_loss improved from 0.00203 to 0.00201, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0100 - mae: 0.0631 - val_loss: 0.0020 - val_mae: 0.0338\n",
      "Epoch 181/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0101 - mae: 0.0631\n",
      "Epoch 181: val_loss improved from 0.00201 to 0.00199, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0101 - mae: 0.0631 - val_loss: 0.0020 - val_mae: 0.0336\n",
      "Epoch 182/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0100 - mae: 0.0629\n",
      "Epoch 182: val_loss improved from 0.00199 to 0.00197, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0100 - mae: 0.0629 - val_loss: 0.0020 - val_mae: 0.0335\n",
      "Epoch 183/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0099 - mae: 0.0626\n",
      "Epoch 183: val_loss improved from 0.00197 to 0.00195, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0099 - mae: 0.0626 - val_loss: 0.0020 - val_mae: 0.0333\n",
      "Epoch 184/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0099 - mae: 0.0626\n",
      "Epoch 184: val_loss improved from 0.00195 to 0.00193, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0099 - mae: 0.0626 - val_loss: 0.0019 - val_mae: 0.0332\n",
      "Epoch 185/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0099 - mae: 0.0626\n",
      "Epoch 185: val_loss improved from 0.00193 to 0.00192, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0099 - mae: 0.0626 - val_loss: 0.0019 - val_mae: 0.0330\n",
      "Epoch 186/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0099 - mae: 0.0625\n",
      "Epoch 186: val_loss improved from 0.00192 to 0.00190, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0099 - mae: 0.0625 - val_loss: 0.0019 - val_mae: 0.0329\n",
      "Epoch 187/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0098 - mae: 0.0624\n",
      "Epoch 187: val_loss improved from 0.00190 to 0.00188, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0098 - mae: 0.0624 - val_loss: 0.0019 - val_mae: 0.0327\n",
      "Epoch 188/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0096 - mae: 0.0617\n",
      "Epoch 188: val_loss improved from 0.00188 to 0.00186, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0096 - mae: 0.0617 - val_loss: 0.0019 - val_mae: 0.0326\n",
      "Epoch 189/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0096 - mae: 0.0614\n",
      "Epoch 189: val_loss improved from 0.00186 to 0.00185, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0096 - mae: 0.0614 - val_loss: 0.0018 - val_mae: 0.0325\n",
      "Epoch 190/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0097 - mae: 0.0615\n",
      "Epoch 190: val_loss improved from 0.00185 to 0.00183, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0097 - mae: 0.0615 - val_loss: 0.0018 - val_mae: 0.0323\n",
      "Epoch 191/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0095 - mae: 0.0611\n",
      "Epoch 191: val_loss improved from 0.00183 to 0.00182, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0095 - mae: 0.0611 - val_loss: 0.0018 - val_mae: 0.0322\n",
      "Epoch 192/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0095 - mae: 0.0613\n",
      "Epoch 192: val_loss improved from 0.00182 to 0.00180, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0095 - mae: 0.0613 - val_loss: 0.0018 - val_mae: 0.0320\n",
      "Epoch 193/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0613\n",
      "Epoch 193: val_loss improved from 0.00180 to 0.00179, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0095 - mae: 0.0613 - val_loss: 0.0018 - val_mae: 0.0319\n",
      "Epoch 194/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0097 - mae: 0.0618\n",
      "Epoch 194: val_loss improved from 0.00179 to 0.00177, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0097 - mae: 0.0618 - val_loss: 0.0018 - val_mae: 0.0318\n",
      "Epoch 195/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0096 - mae: 0.0613\n",
      "Epoch 195: val_loss improved from 0.00177 to 0.00176, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0096 - mae: 0.0613 - val_loss: 0.0018 - val_mae: 0.0316\n",
      "Epoch 196/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0095 - mae: 0.0609\n",
      "Epoch 196: val_loss improved from 0.00176 to 0.00174, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0095 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0315\n",
      "Epoch 197/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0096 - mae: 0.0612\n",
      "Epoch 197: val_loss improved from 0.00174 to 0.00173, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0096 - mae: 0.0612 - val_loss: 0.0017 - val_mae: 0.0314\n",
      "Epoch 198/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0617\n",
      "Epoch 198: val_loss improved from 0.00173 to 0.00171, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0097 - mae: 0.0617 - val_loss: 0.0017 - val_mae: 0.0312\n",
      "Epoch 199/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0097 - mae: 0.0620\n",
      "Epoch 199: val_loss improved from 0.00171 to 0.00170, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0097 - mae: 0.0620 - val_loss: 0.0017 - val_mae: 0.0311\n",
      "Epoch 200/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0095 - mae: 0.0614\n",
      "Epoch 200: val_loss improved from 0.00170 to 0.00168, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0095 - mae: 0.0614 - val_loss: 0.0017 - val_mae: 0.0310\n",
      "Epoch 201/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0609\n",
      "Epoch 201: val_loss improved from 0.00168 to 0.00167, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0094 - mae: 0.0609 - val_loss: 0.0017 - val_mae: 0.0309\n",
      "Epoch 202/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0603\n",
      "Epoch 202: val_loss improved from 0.00167 to 0.00166, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0094 - mae: 0.0603 - val_loss: 0.0017 - val_mae: 0.0308\n",
      "Epoch 203/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0095 - mae: 0.0603\n",
      "Epoch 203: val_loss improved from 0.00166 to 0.00165, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0095 - mae: 0.0603 - val_loss: 0.0016 - val_mae: 0.0306\n",
      "Epoch 204/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0094 - mae: 0.0607\n",
      "Epoch 204: val_loss improved from 0.00165 to 0.00164, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0094 - mae: 0.0607 - val_loss: 0.0016 - val_mae: 0.0305\n",
      "Epoch 205/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0094 - mae: 0.0611\n",
      "Epoch 205: val_loss improved from 0.00164 to 0.00162, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0094 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0304\n",
      "Epoch 206/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0094 - mae: 0.0609\n",
      "Epoch 206: val_loss improved from 0.00162 to 0.00161, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0094 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0303\n",
      "Epoch 207/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0094 - mae: 0.0604\n",
      "Epoch 207: val_loss improved from 0.00161 to 0.00160, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0094 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0303\n",
      "Epoch 208/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0597\n",
      "Epoch 208: val_loss improved from 0.00160 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0093 - mae: 0.0597 - val_loss: 0.0016 - val_mae: 0.0301\n",
      "Epoch 209/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0602\n",
      "Epoch 209: val_loss improved from 0.00158 to 0.00158, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0094 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0300\n",
      "Epoch 210/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0094 - mae: 0.0609\n",
      "Epoch 210: val_loss improved from 0.00158 to 0.00157, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0094 - mae: 0.0609 - val_loss: 0.0016 - val_mae: 0.0299\n",
      "Epoch 211/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0095 - mae: 0.0614\n",
      "Epoch 211: val_loss improved from 0.00157 to 0.00155, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0095 - mae: 0.0614 - val_loss: 0.0016 - val_mae: 0.0297\n",
      "Epoch 212/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0093 - mae: 0.0608\n",
      "Epoch 212: val_loss improved from 0.00155 to 0.00154, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0093 - mae: 0.0608 - val_loss: 0.0015 - val_mae: 0.0297\n",
      "Epoch 213/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0598\n",
      "Epoch 213: val_loss improved from 0.00154 to 0.00153, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0091 - mae: 0.0598 - val_loss: 0.0015 - val_mae: 0.0296\n",
      "Epoch 214/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0093 - mae: 0.0596\n",
      "Epoch 214: val_loss improved from 0.00153 to 0.00152, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0093 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0294\n",
      "Epoch 215/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0091 - mae: 0.0594\n",
      "Epoch 215: val_loss improved from 0.00152 to 0.00151, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0091 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0293\n",
      "Epoch 216/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0092 - mae: 0.0600\n",
      "Epoch 216: val_loss improved from 0.00151 to 0.00150, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0092 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0292\n",
      "Epoch 217/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0091 - mae: 0.0601\n",
      "Epoch 217: val_loss improved from 0.00150 to 0.00149, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0091 - mae: 0.0601 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 218/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0599\n",
      "Epoch 218: val_loss improved from 0.00149 to 0.00148, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0091 - mae: 0.0599 - val_loss: 0.0015 - val_mae: 0.0291\n",
      "Epoch 219/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0595\n",
      "Epoch 219: val_loss improved from 0.00148 to 0.00147, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0092 - mae: 0.0595 - val_loss: 0.0015 - val_mae: 0.0290\n",
      "Epoch 220/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0596\n",
      "Epoch 220: val_loss improved from 0.00147 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0093 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0289\n",
      "Epoch 221/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0093 - mae: 0.0600\n",
      "Epoch 221: val_loss improved from 0.00146 to 0.00146, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0093 - mae: 0.0600 - val_loss: 0.0015 - val_mae: 0.0288\n",
      "Epoch 222/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0091 - mae: 0.0600\n",
      "Epoch 222: val_loss improved from 0.00146 to 0.00145, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0091 - mae: 0.0600 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 223/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0092 - mae: 0.0599\n",
      "Epoch 223: val_loss improved from 0.00145 to 0.00144, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0092 - mae: 0.0599 - val_loss: 0.0014 - val_mae: 0.0287\n",
      "Epoch 224/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0091 - mae: 0.0593\n",
      "Epoch 224: val_loss improved from 0.00144 to 0.00143, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0091 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0286\n",
      "Epoch 225/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0094 - mae: 0.0598\n",
      "Epoch 225: val_loss improved from 0.00143 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0094 - mae: 0.0598 - val_loss: 0.0014 - val_mae: 0.0285\n",
      "Epoch 226/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0589\n",
      "Epoch 226: val_loss improved from 0.00142 to 0.00142, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0088 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0284\n",
      "Epoch 227/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0090 - mae: 0.0593\n",
      "Epoch 227: val_loss improved from 0.00142 to 0.00141, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0090 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0283\n",
      "Epoch 228/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0092 - mae: 0.0597\n",
      "Epoch 228: val_loss improved from 0.00141 to 0.00140, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0092 - mae: 0.0597 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 229/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0592\n",
      "Epoch 229: val_loss improved from 0.00140 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0089 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 230/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0590\n",
      "Epoch 230: val_loss improved from 0.00139 to 0.00139, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0089 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0282\n",
      "Epoch 231/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - mae: 0.0585\n",
      "Epoch 231: val_loss improved from 0.00139 to 0.00138, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0089 - mae: 0.0585 - val_loss: 0.0014 - val_mae: 0.0281\n",
      "Epoch 232/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0090 - mae: 0.0590\n",
      "Epoch 232: val_loss improved from 0.00138 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0090 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0280\n",
      "Epoch 233/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0592\n",
      "Epoch 233: val_loss improved from 0.00137 to 0.00137, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0089 - mae: 0.0592 - val_loss: 0.0014 - val_mae: 0.0279\n",
      "Epoch 234/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0090 - mae: 0.0594\n",
      "Epoch 234: val_loss improved from 0.00137 to 0.00136, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0090 - mae: 0.0594 - val_loss: 0.0014 - val_mae: 0.0278\n",
      "Epoch 235/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0089 - mae: 0.0591\n",
      "Epoch 235: val_loss improved from 0.00136 to 0.00135, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0089 - mae: 0.0591 - val_loss: 0.0013 - val_mae: 0.0277\n",
      "Epoch 236/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0089 - mae: 0.0589\n",
      "Epoch 236: val_loss improved from 0.00135 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0089 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0276\n",
      "Epoch 237/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0088 - mae: 0.0587\n",
      "Epoch 237: val_loss improved from 0.00134 to 0.00134, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0088 - mae: 0.0587 - val_loss: 0.0013 - val_mae: 0.0276\n",
      "Epoch 238/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0591\n",
      "Epoch 238: val_loss improved from 0.00134 to 0.00133, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0089 - mae: 0.0591 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 239/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0088 - mae: 0.0590\n",
      "Epoch 239: val_loss improved from 0.00133 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0088 - mae: 0.0590 - val_loss: 0.0013 - val_mae: 0.0275\n",
      "Epoch 240/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0586\n",
      "Epoch 240: val_loss improved from 0.00132 to 0.00132, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0087 - mae: 0.0586 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 241/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0087 - mae: 0.0582\n",
      "Epoch 241: val_loss improved from 0.00132 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0087 - mae: 0.0582 - val_loss: 0.0013 - val_mae: 0.0274\n",
      "Epoch 242/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0582\n",
      "Epoch 242: val_loss improved from 0.00131 to 0.00131, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0087 - mae: 0.0582 - val_loss: 0.0013 - val_mae: 0.0273\n",
      "Epoch 243/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0087 - mae: 0.0585\n",
      "Epoch 243: val_loss improved from 0.00131 to 0.00130, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0087 - mae: 0.0585 - val_loss: 0.0013 - val_mae: 0.0272\n",
      "Epoch 244/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0088 - mae: 0.0588\n",
      "Epoch 244: val_loss improved from 0.00130 to 0.00129, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0088 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 245/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0089 - mae: 0.0589\n",
      "Epoch 245: val_loss improved from 0.00129 to 0.00129, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0089 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0271\n",
      "Epoch 246/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0584\n",
      "Epoch 246: val_loss improved from 0.00129 to 0.00128, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0087 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 247/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0087 - mae: 0.0581\n",
      "Epoch 247: val_loss improved from 0.00128 to 0.00128, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0087 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0270\n",
      "Epoch 248/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 248: val_loss improved from 0.00128 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 249/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 249: val_loss improved from 0.00127 to 0.00127, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0013 - val_mae: 0.0269\n",
      "Epoch 250/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0581\n",
      "Epoch 250: val_loss improved from 0.00127 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0086 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 251/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0086 - mae: 0.0581\n",
      "Epoch 251: val_loss improved from 0.00126 to 0.00126, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0086 - mae: 0.0581 - val_loss: 0.0013 - val_mae: 0.0268\n",
      "Epoch 252/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0087 - mae: 0.0584\n",
      "Epoch 252: val_loss improved from 0.00126 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0087 - mae: 0.0584 - val_loss: 0.0013 - val_mae: 0.0267\n",
      "Epoch 253/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0580\n",
      "Epoch 253: val_loss improved from 0.00125 to 0.00125, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0086 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 254/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 254: val_loss improved from 0.00125 to 0.00124, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0266\n",
      "Epoch 255/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0086 - mae: 0.0578\n",
      "Epoch 255: val_loss improved from 0.00124 to 0.00124, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0086 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0265\n",
      "Epoch 256/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0085 - mae: 0.0577\n",
      "Epoch 256: val_loss improved from 0.00124 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0085 - mae: 0.0577 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 257/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 257: val_loss improved from 0.00123 to 0.00123, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0264\n",
      "Epoch 258/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0580\n",
      "Epoch 258: val_loss improved from 0.00123 to 0.00122, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0086 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 259/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 259: val_loss improved from 0.00122 to 0.00122, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 260/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0585\n",
      "Epoch 260: val_loss improved from 0.00122 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0087 - mae: 0.0585 - val_loss: 0.0012 - val_mae: 0.0263\n",
      "Epoch 261/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0086 - mae: 0.0584\n",
      "Epoch 261: val_loss improved from 0.00121 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0086 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 262/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 262: val_loss improved from 0.00121 to 0.00121, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0012 - val_mae: 0.0262\n",
      "Epoch 263/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0086 - mae: 0.0575\n",
      "Epoch 263: val_loss improved from 0.00121 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0086 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 264/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 264: val_loss improved from 0.00120 to 0.00120, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0261\n",
      "Epoch 265/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0084 - mae: 0.0581\n",
      "Epoch 265: val_loss improved from 0.00120 to 0.00119, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0084 - mae: 0.0581 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 266/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0085 - mae: 0.0580\n",
      "Epoch 266: val_loss improved from 0.00119 to 0.00119, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0085 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0260\n",
      "Epoch 267/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0576\n",
      "Epoch 267: val_loss improved from 0.00119 to 0.00118, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0086 - mae: 0.0576 - val_loss: 0.0012 - val_mae: 0.0259\n",
      "Epoch 268/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0085 - mae: 0.0571\n",
      "Epoch 268: val_loss improved from 0.00118 to 0.00118, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0085 - mae: 0.0571 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 269/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0575\n",
      "Epoch 269: val_loss improved from 0.00118 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0084 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0258\n",
      "Epoch 270/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0085 - mae: 0.0580\n",
      "Epoch 270: val_loss improved from 0.00117 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0085 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 271/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0581\n",
      "Epoch 271: val_loss improved from 0.00117 to 0.00117, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0086 - mae: 0.0581 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 272/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0087 - mae: 0.0580\n",
      "Epoch 272: val_loss improved from 0.00117 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0087 - mae: 0.0580 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 273/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 273: val_loss improved from 0.00116 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0012 - val_mae: 0.0257\n",
      "Epoch 274/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0086 - mae: 0.0578\n",
      "Epoch 274: val_loss improved from 0.00116 to 0.00116, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0086 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0256\n",
      "Epoch 275/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0085 - mae: 0.0575\n",
      "Epoch 275: val_loss improved from 0.00116 to 0.00115, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0085 - mae: 0.0575 - val_loss: 0.0012 - val_mae: 0.0255\n",
      "Epoch 276/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0572\n",
      "Epoch 276: val_loss improved from 0.00115 to 0.00115, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0082 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0255\n",
      "Epoch 277/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0085 - mae: 0.0574\n",
      "Epoch 277: val_loss improved from 0.00115 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0085 - mae: 0.0574 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 278/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0086 - mae: 0.0579\n",
      "Epoch 278: val_loss improved from 0.00114 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0086 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 279/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 0.0084 - mae: 0.0579\n",
      "Epoch 279: val_loss improved from 0.00114 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0084 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 280/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0083 - mae: 0.0575\n",
      "Epoch 280: val_loss improved from 0.00114 to 0.00114, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0083 - mae: 0.0575 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 281/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0083 - mae: 0.0566\n",
      "Epoch 281: val_loss improved from 0.00114 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0083 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0254\n",
      "Epoch 282/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0085 - mae: 0.0569\n",
      "Epoch 282: val_loss improved from 0.00113 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0085 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 283/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0084 - mae: 0.0575\n",
      "Epoch 283: val_loss improved from 0.00113 to 0.00113, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0084 - mae: 0.0575 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 284/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 284: val_loss improved from 0.00113 to 0.00112, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0253\n",
      "Epoch 285/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0083 - mae: 0.0568\n",
      "Epoch 285: val_loss improved from 0.00112 to 0.00112, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0083 - mae: 0.0568 - val_loss: 0.0011 - val_mae: 0.0252\n",
      "Epoch 286/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0085 - mae: 0.0569\n",
      "Epoch 286: val_loss improved from 0.00112 to 0.00111, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0085 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 287/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0084 - mae: 0.0576\n",
      "Epoch 287: val_loss improved from 0.00111 to 0.00111, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0084 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 288/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0083 - mae: 0.0579\n",
      "Epoch 288: val_loss improved from 0.00111 to 0.00111, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0083 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 289/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0084 - mae: 0.0572\n",
      "Epoch 289: val_loss did not improve from 0.00111\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0084 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0251\n",
      "Epoch 290/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0562\n",
      "Epoch 290: val_loss improved from 0.00111 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0084 - mae: 0.0562 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 291/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0083 - mae: 0.0569\n",
      "Epoch 291: val_loss improved from 0.00110 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0083 - mae: 0.0569 - val_loss: 0.0011 - val_mae: 0.0249\n",
      "Epoch 292/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0085 - mae: 0.0582\n",
      "Epoch 292: val_loss improved from 0.00110 to 0.00110, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0085 - mae: 0.0582 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 293/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0577\n",
      "Epoch 293: val_loss improved from 0.00110 to 0.00109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0083 - mae: 0.0577 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 294/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0558\n",
      "Epoch 294: val_loss did not improve from 0.00109\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0080 - mae: 0.0558 - val_loss: 0.0011 - val_mae: 0.0250\n",
      "Epoch 295/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0555\n",
      "Epoch 295: val_loss improved from 0.00109 to 0.00109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0082 - mae: 0.0555 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 296/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0084 - mae: 0.0568\n",
      "Epoch 296: val_loss improved from 0.00109 to 0.00109, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0084 - mae: 0.0568 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 297/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0083 - mae: 0.0582\n",
      "Epoch 297: val_loss improved from 0.00109 to 0.00108, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0083 - mae: 0.0582 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 298/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0081 - mae: 0.0575\n",
      "Epoch 298: val_loss improved from 0.00108 to 0.00108, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0081 - mae: 0.0575 - val_loss: 0.0011 - val_mae: 0.0247\n",
      "Epoch 299/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0561\n",
      "Epoch 299: val_loss did not improve from 0.00108\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0082 - mae: 0.0561 - val_loss: 0.0011 - val_mae: 0.0248\n",
      "Epoch 300/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0083 - mae: 0.0556\n",
      "Epoch 300: val_loss improved from 0.00108 to 0.00107, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0083 - mae: 0.0556 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 301/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0081 - mae: 0.0563\n",
      "Epoch 301: val_loss did not improve from 0.00107\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0081 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 302/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0082 - mae: 0.0579\n",
      "Epoch 302: val_loss improved from 0.00107 to 0.00106, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0082 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0245\n",
      "Epoch 303/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0578\n",
      "Epoch 303: val_loss improved from 0.00106 to 0.00106, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0082 - mae: 0.0578 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 304/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0565\n",
      "Epoch 304: val_loss did not improve from 0.00106\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0082 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0246\n",
      "Epoch 305/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0556\n",
      "Epoch 305: val_loss improved from 0.00106 to 0.00106, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0081 - mae: 0.0556 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 306/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0081 - mae: 0.0561\n",
      "Epoch 306: val_loss improved from 0.00106 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0081 - mae: 0.0561 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 307/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0082 - mae: 0.0571\n",
      "Epoch 307: val_loss improved from 0.00105 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0082 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 308/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0574\n",
      "Epoch 308: val_loss improved from 0.00105 to 0.00105, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0081 - mae: 0.0574 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 309/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0566\n",
      "Epoch 309: val_loss did not improve from 0.00105\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0082 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0244\n",
      "Epoch 310/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0556\n",
      "Epoch 310: val_loss improved from 0.00105 to 0.00104, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0080 - mae: 0.0556 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 311/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0082 - mae: 0.0563\n",
      "Epoch 311: val_loss improved from 0.00104 to 0.00104, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0082 - mae: 0.0563 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 312/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0083 - mae: 0.0577\n",
      "Epoch 312: val_loss did not improve from 0.00104\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0083 - mae: 0.0577 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 313/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0578\n",
      "Epoch 313: val_loss improved from 0.00104 to 0.00103, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0082 - mae: 0.0578 - val_loss: 0.0010 - val_mae: 0.0241\n",
      "Epoch 314/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0564\n",
      "Epoch 314: val_loss did not improve from 0.00103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0081 - mae: 0.0564 - val_loss: 0.0010 - val_mae: 0.0243\n",
      "Epoch 315/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0081 - mae: 0.0553\n",
      "Epoch 315: val_loss did not improve from 0.00103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0081 - mae: 0.0553 - val_loss: 0.0010 - val_mae: 0.0242\n",
      "Epoch 316/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0549\n",
      "Epoch 316: val_loss improved from 0.00103 to 0.00103, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0080 - mae: 0.0549 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 317/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0079 - mae: 0.0562\n",
      "Epoch 317: val_loss did not improve from 0.00103\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0079 - mae: 0.0562 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 318/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - loss: 0.0082 - mae: 0.0575\n",
      "Epoch 318: val_loss improved from 0.00103 to 0.00102, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0082 - mae: 0.0575 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 319/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0081 - mae: 0.0571\n",
      "Epoch 319: val_loss improved from 0.00102 to 0.00102, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0081 - mae: 0.0571 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 320/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0560\n",
      "Epoch 320: val_loss did not improve from 0.00102\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0081 - mae: 0.0560 - val_loss: 0.0010 - val_mae: 0.0240\n",
      "Epoch 321/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0555\n",
      "Epoch 321: val_loss improved from 0.00102 to 0.00101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0081 - mae: 0.0555 - val_loss: 0.0010 - val_mae: 0.0239\n",
      "Epoch 322/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0081 - mae: 0.0560\n",
      "Epoch 322: val_loss improved from 0.00101 to 0.00101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0081 - mae: 0.0560 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 323/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0565\n",
      "Epoch 323: val_loss improved from 0.00101 to 0.00101, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0080 - mae: 0.0565 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 324/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0082 - mae: 0.0571\n",
      "Epoch 324: val_loss improved from 0.00101 to 0.00100, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0082 - mae: 0.0571 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 325/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0561\n",
      "Epoch 325: val_loss did not improve from 0.00100\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0080 - mae: 0.0561 - val_loss: 0.0010 - val_mae: 0.0238\n",
      "Epoch 326/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0552\n",
      "Epoch 326: val_loss improved from 0.00100 to 0.00100, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0079 - mae: 0.0552 - val_loss: 0.0010 - val_mae: 0.0237\n",
      "Epoch 327/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0555\n",
      "Epoch 327: val_loss improved from 0.00100 to 0.00100, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0080 - mae: 0.0555 - val_loss: 9.9635e-04 - val_mae: 0.0237\n",
      "Epoch 328/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0080 - mae: 0.0560\n",
      "Epoch 328: val_loss improved from 0.00100 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0080 - mae: 0.0560 - val_loss: 9.9316e-04 - val_mae: 0.0236\n",
      "Epoch 329/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0080 - mae: 0.0565\n",
      "Epoch 329: val_loss improved from 0.00099 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0080 - mae: 0.0565 - val_loss: 9.9045e-04 - val_mae: 0.0236\n",
      "Epoch 330/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0082 - mae: 0.0570\n",
      "Epoch 330: val_loss improved from 0.00099 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0082 - mae: 0.0570 - val_loss: 9.8793e-04 - val_mae: 0.0236\n",
      "Epoch 331/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0561\n",
      "Epoch 331: val_loss improved from 0.00099 to 0.00099, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0079 - mae: 0.0561 - val_loss: 9.8684e-04 - val_mae: 0.0235\n",
      "Epoch 332/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0559\n",
      "Epoch 332: val_loss improved from 0.00099 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0080 - mae: 0.0559 - val_loss: 9.8376e-04 - val_mae: 0.0235\n",
      "Epoch 333/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0081 - mae: 0.0559\n",
      "Epoch 333: val_loss improved from 0.00098 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0081 - mae: 0.0559 - val_loss: 9.8010e-04 - val_mae: 0.0234\n",
      "Epoch 334/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0563\n",
      "Epoch 334: val_loss improved from 0.00098 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0080 - mae: 0.0563 - val_loss: 9.7756e-04 - val_mae: 0.0234\n",
      "Epoch 335/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0079 - mae: 0.0563\n",
      "Epoch 335: val_loss improved from 0.00098 to 0.00098, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0079 - mae: 0.0563 - val_loss: 9.7607e-04 - val_mae: 0.0234\n",
      "Epoch 336/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0555\n",
      "Epoch 336: val_loss did not improve from 0.00098\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0078 - mae: 0.0555 - val_loss: 9.7677e-04 - val_mae: 0.0234\n",
      "Epoch 337/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0554\n",
      "Epoch 337: val_loss improved from 0.00098 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0079 - mae: 0.0554 - val_loss: 9.7200e-04 - val_mae: 0.0233\n",
      "Epoch 338/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0080 - mae: 0.0559\n",
      "Epoch 338: val_loss improved from 0.00097 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0080 - mae: 0.0559 - val_loss: 9.6921e-04 - val_mae: 0.0233\n",
      "Epoch 339/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - mae: 0.0564\n",
      "Epoch 339: val_loss improved from 0.00097 to 0.00097, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0078 - mae: 0.0564 - val_loss: 9.6693e-04 - val_mae: 0.0233\n",
      "Epoch 340/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0560\n",
      "Epoch 340: val_loss did not improve from 0.00097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0077 - mae: 0.0560 - val_loss: 9.6896e-04 - val_mae: 0.0233\n",
      "Epoch 341/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0553\n",
      "Epoch 341: val_loss did not improve from 0.00097\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0080 - mae: 0.0553 - val_loss: 9.6832e-04 - val_mae: 0.0233\n",
      "Epoch 342/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - mae: 0.0549\n",
      "Epoch 342: val_loss improved from 0.00097 to 0.00096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0078 - mae: 0.0549 - val_loss: 9.6007e-04 - val_mae: 0.0232\n",
      "Epoch 343/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0561\n",
      "Epoch 343: val_loss improved from 0.00096 to 0.00096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0079 - mae: 0.0561 - val_loss: 9.5954e-04 - val_mae: 0.0232\n",
      "Epoch 344/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0566\n",
      "Epoch 344: val_loss improved from 0.00096 to 0.00096, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0077 - mae: 0.0566 - val_loss: 9.5506e-04 - val_mae: 0.0231\n",
      "Epoch 345/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0080 - mae: 0.0562\n",
      "Epoch 345: val_loss did not improve from 0.00096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0080 - mae: 0.0562 - val_loss: 9.5825e-04 - val_mae: 0.0232\n",
      "Epoch 346/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0079 - mae: 0.0549\n",
      "Epoch 346: val_loss did not improve from 0.00096\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0079 - mae: 0.0549 - val_loss: 9.5512e-04 - val_mae: 0.0231\n",
      "Epoch 347/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0079 - mae: 0.0552\n",
      "Epoch 347: val_loss improved from 0.00096 to 0.00095, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0079 - mae: 0.0552 - val_loss: 9.4811e-04 - val_mae: 0.0230\n",
      "Epoch 348/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0562\n",
      "Epoch 348: val_loss improved from 0.00095 to 0.00095, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0079 - mae: 0.0562 - val_loss: 9.4807e-04 - val_mae: 0.0230\n",
      "Epoch 349/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0568\n",
      "Epoch 349: val_loss improved from 0.00095 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0079 - mae: 0.0568 - val_loss: 9.4328e-04 - val_mae: 0.0230\n",
      "Epoch 350/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0078 - mae: 0.0555\n",
      "Epoch 350: val_loss did not improve from 0.00094\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0078 - mae: 0.0555 - val_loss: 9.4923e-04 - val_mae: 0.0231\n",
      "Epoch 351/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0080 - mae: 0.0551\n",
      "Epoch 351: val_loss improved from 0.00094 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0080 - mae: 0.0551 - val_loss: 9.4272e-04 - val_mae: 0.0230\n",
      "Epoch 352/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0079 - mae: 0.0553\n",
      "Epoch 352: val_loss improved from 0.00094 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0079 - mae: 0.0553 - val_loss: 9.3775e-04 - val_mae: 0.0229\n",
      "Epoch 353/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0079 - mae: 0.0565\n",
      "Epoch 353: val_loss improved from 0.00094 to 0.00094, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0079 - mae: 0.0565 - val_loss: 9.3723e-04 - val_mae: 0.0229\n",
      "Epoch 354/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0566\n",
      "Epoch 354: val_loss improved from 0.00094 to 0.00093, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0078 - mae: 0.0566 - val_loss: 9.3264e-04 - val_mae: 0.0228\n",
      "Epoch 355/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0556\n",
      "Epoch 355: val_loss did not improve from 0.00093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0078 - mae: 0.0556 - val_loss: 9.3975e-04 - val_mae: 0.0229\n",
      "Epoch 356/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0078 - mae: 0.0546\n",
      "Epoch 356: val_loss improved from 0.00093 to 0.00093, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0078 - mae: 0.0546 - val_loss: 9.3039e-04 - val_mae: 0.0228\n",
      "Epoch 357/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0079 - mae: 0.0554\n",
      "Epoch 357: val_loss improved from 0.00093 to 0.00093, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0079 - mae: 0.0554 - val_loss: 9.2729e-04 - val_mae: 0.0227\n",
      "Epoch 358/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0080 - mae: 0.0570\n",
      "Epoch 358: val_loss did not improve from 0.00093\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0080 - mae: 0.0570 - val_loss: 9.2779e-04 - val_mae: 0.0227\n",
      "Epoch 359/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0078 - mae: 0.0570\n",
      "Epoch 359: val_loss improved from 0.00093 to 0.00092, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0078 - mae: 0.0570 - val_loss: 9.2119e-04 - val_mae: 0.0227\n",
      "Epoch 360/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mae: 0.0555\n",
      "Epoch 360: val_loss did not improve from 0.00092\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0078 - mae: 0.0555 - val_loss: 9.2739e-04 - val_mae: 0.0228\n",
      "Epoch 361/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0541\n",
      "Epoch 361: val_loss improved from 0.00092 to 0.00092, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0077 - mae: 0.0541 - val_loss: 9.2105e-04 - val_mae: 0.0227\n",
      "Epoch 362/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076 - mae: 0.0542\n",
      "Epoch 362: val_loss improved from 0.00092 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0076 - mae: 0.0542 - val_loss: 9.1411e-04 - val_mae: 0.0226\n",
      "Epoch 363/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0078 - mae: 0.0558\n",
      "Epoch 363: val_loss improved from 0.00091 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0078 - mae: 0.0558 - val_loss: 9.1382e-04 - val_mae: 0.0226\n",
      "Epoch 364/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0078 - mae: 0.0564\n",
      "Epoch 364: val_loss improved from 0.00091 to 0.00091, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0078 - mae: 0.0564 - val_loss: 9.0908e-04 - val_mae: 0.0225\n",
      "Epoch 365/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mae: 0.0552\n",
      "Epoch 365: val_loss did not improve from 0.00091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0076 - mae: 0.0552 - val_loss: 9.1456e-04 - val_mae: 0.0226\n",
      "Epoch 366/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - mae: 0.0543\n",
      "Epoch 366: val_loss did not improve from 0.00091\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0077 - mae: 0.0543 - val_loss: 9.1042e-04 - val_mae: 0.0225\n",
      "Epoch 367/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0545\n",
      "Epoch 367: val_loss improved from 0.00091 to 0.00090, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0077 - mae: 0.0545 - val_loss: 9.0224e-04 - val_mae: 0.0224\n",
      "Epoch 368/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0552\n",
      "Epoch 368: val_loss improved from 0.00090 to 0.00090, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0076 - mae: 0.0552 - val_loss: 8.9977e-04 - val_mae: 0.0224\n",
      "Epoch 369/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076 - mae: 0.0558\n",
      "Epoch 369: val_loss improved from 0.00090 to 0.00090, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0076 - mae: 0.0558 - val_loss: 8.9790e-04 - val_mae: 0.0223\n",
      "Epoch 370/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077 - mae: 0.0552\n",
      "Epoch 370: val_loss did not improve from 0.00090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0077 - mae: 0.0552 - val_loss: 9.0067e-04 - val_mae: 0.0224\n",
      "Epoch 371/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0076 - mae: 0.0545\n",
      "Epoch 371: val_loss did not improve from 0.00090\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0076 - mae: 0.0545 - val_loss: 8.9820e-04 - val_mae: 0.0224\n",
      "Epoch 372/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0076 - mae: 0.0544\n",
      "Epoch 372: val_loss improved from 0.00090 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0076 - mae: 0.0544 - val_loss: 8.9154e-04 - val_mae: 0.0223\n",
      "Epoch 373/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0077 - mae: 0.0555\n",
      "Epoch 373: val_loss improved from 0.00089 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0077 - mae: 0.0555 - val_loss: 8.8946e-04 - val_mae: 0.0222\n",
      "Epoch 374/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0555\n",
      "Epoch 374: val_loss improved from 0.00089 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0076 - mae: 0.0555 - val_loss: 8.8811e-04 - val_mae: 0.0222\n",
      "Epoch 375/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0077 - mae: 0.0555\n",
      "Epoch 375: val_loss did not improve from 0.00089\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0077 - mae: 0.0555 - val_loss: 8.8827e-04 - val_mae: 0.0222\n",
      "Epoch 376/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0077 - mae: 0.0549\n",
      "Epoch 376: val_loss improved from 0.00089 to 0.00089, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0077 - mae: 0.0549 - val_loss: 8.8531e-04 - val_mae: 0.0222\n",
      "Epoch 377/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0075 - mae: 0.0544\n",
      "Epoch 377: val_loss improved from 0.00089 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0075 - mae: 0.0544 - val_loss: 8.8354e-04 - val_mae: 0.0222\n",
      "Epoch 378/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0548\n",
      "Epoch 378: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0076 - mae: 0.0548 - val_loss: 8.8169e-04 - val_mae: 0.0221\n",
      "Epoch 379/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0077 - mae: 0.0550\n",
      "Epoch 379: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0077 - mae: 0.0550 - val_loss: 8.7850e-04 - val_mae: 0.0221\n",
      "Epoch 380/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0554\n",
      "Epoch 380: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0076 - mae: 0.0554 - val_loss: 8.7647e-04 - val_mae: 0.0221\n",
      "Epoch 381/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0555\n",
      "Epoch 381: val_loss improved from 0.00088 to 0.00088, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0076 - mae: 0.0555 - val_loss: 8.7520e-04 - val_mae: 0.0220\n",
      "Epoch 382/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0551\n",
      "Epoch 382: val_loss improved from 0.00088 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0076 - mae: 0.0551 - val_loss: 8.7426e-04 - val_mae: 0.0220\n",
      "Epoch 383/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077 - mae: 0.0550\n",
      "Epoch 383: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0077 - mae: 0.0550 - val_loss: 8.7052e-04 - val_mae: 0.0220\n",
      "Epoch 384/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0076 - mae: 0.0550\n",
      "Epoch 384: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0076 - mae: 0.0550 - val_loss: 8.6793e-04 - val_mae: 0.0219\n",
      "Epoch 385/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0556\n",
      "Epoch 385: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0076 - mae: 0.0556 - val_loss: 8.6591e-04 - val_mae: 0.0219\n",
      "Epoch 386/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0547\n",
      "Epoch 386: val_loss improved from 0.00087 to 0.00087, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 8.6571e-04 - val_mae: 0.0219\n",
      "Epoch 387/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mae: 0.0547\n",
      "Epoch 387: val_loss improved from 0.00087 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0076 - mae: 0.0547 - val_loss: 8.6208e-04 - val_mae: 0.0219\n",
      "Epoch 388/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0547\n",
      "Epoch 388: val_loss improved from 0.00086 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0075 - mae: 0.0547 - val_loss: 8.5962e-04 - val_mae: 0.0218\n",
      "Epoch 389/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0076 - mae: 0.0551\n",
      "Epoch 389: val_loss improved from 0.00086 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0076 - mae: 0.0551 - val_loss: 8.5850e-04 - val_mae: 0.0218\n",
      "Epoch 390/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0076 - mae: 0.0549\n",
      "Epoch 390: val_loss improved from 0.00086 to 0.00086, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0076 - mae: 0.0549 - val_loss: 8.5664e-04 - val_mae: 0.0218\n",
      "Epoch 391/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076 - mae: 0.0547\n",
      "Epoch 391: val_loss improved from 0.00086 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0076 - mae: 0.0547 - val_loss: 8.5470e-04 - val_mae: 0.0217\n",
      "Epoch 392/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0543\n",
      "Epoch 392: val_loss improved from 0.00085 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0074 - mae: 0.0543 - val_loss: 8.5307e-04 - val_mae: 0.0217\n",
      "Epoch 393/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0075 - mae: 0.0544\n",
      "Epoch 393: val_loss improved from 0.00085 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0075 - mae: 0.0544 - val_loss: 8.5136e-04 - val_mae: 0.0217\n",
      "Epoch 394/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - mae: 0.0546\n",
      "Epoch 394: val_loss improved from 0.00085 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0077 - mae: 0.0546 - val_loss: 8.4754e-04 - val_mae: 0.0217\n",
      "Epoch 395/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0075 - mae: 0.0548\n",
      "Epoch 395: val_loss improved from 0.00085 to 0.00085, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0075 - mae: 0.0548 - val_loss: 8.4570e-04 - val_mae: 0.0216\n",
      "Epoch 396/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0075 - mae: 0.0547\n",
      "Epoch 396: val_loss improved from 0.00085 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0075 - mae: 0.0547 - val_loss: 8.4487e-04 - val_mae: 0.0216\n",
      "Epoch 397/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0076 - mae: 0.0548\n",
      "Epoch 397: val_loss improved from 0.00084 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0076 - mae: 0.0548 - val_loss: 8.4270e-04 - val_mae: 0.0216\n",
      "Epoch 398/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0077 - mae: 0.0551\n",
      "Epoch 398: val_loss improved from 0.00084 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0077 - mae: 0.0551 - val_loss: 8.4055e-04 - val_mae: 0.0215\n",
      "Epoch 399/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0550\n",
      "Epoch 399: val_loss improved from 0.00084 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0074 - mae: 0.0550 - val_loss: 8.3905e-04 - val_mae: 0.0215\n",
      "Epoch 400/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - mae: 0.0545\n",
      "Epoch 400: val_loss did not improve from 0.00084\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0074 - mae: 0.0545 - val_loss: 8.4137e-04 - val_mae: 0.0216\n",
      "Epoch 401/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0538\n",
      "Epoch 401: val_loss improved from 0.00084 to 0.00084, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0074 - mae: 0.0538 - val_loss: 8.3627e-04 - val_mae: 0.0215\n",
      "Epoch 402/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0543\n",
      "Epoch 402: val_loss improved from 0.00084 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0075 - mae: 0.0543 - val_loss: 8.3140e-04 - val_mae: 0.0214\n",
      "Epoch 403/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0075 - mae: 0.0552\n",
      "Epoch 403: val_loss improved from 0.00083 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0075 - mae: 0.0552 - val_loss: 8.2981e-04 - val_mae: 0.0214\n",
      "Epoch 404/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0551\n",
      "Epoch 404: val_loss improved from 0.00083 to 0.00083, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0074 - mae: 0.0551 - val_loss: 8.2889e-04 - val_mae: 0.0214\n",
      "Epoch 405/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0539\n",
      "Epoch 405: val_loss did not improve from 0.00083\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0073 - mae: 0.0539 - val_loss: 8.3410e-04 - val_mae: 0.0215\n",
      "Epoch 406/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0076 - mae: 0.0540\n",
      "Epoch 406: val_loss improved from 0.00083 to 0.00082, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0076 - mae: 0.0540 - val_loss: 8.2219e-04 - val_mae: 0.0213\n",
      "Epoch 407/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0075 - mae: 0.0549\n",
      "Epoch 407: val_loss did not improve from 0.00082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0075 - mae: 0.0549 - val_loss: 8.2309e-04 - val_mae: 0.0213\n",
      "Epoch 408/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0556\n",
      "Epoch 408: val_loss improved from 0.00082 to 0.00082, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0074 - mae: 0.0556 - val_loss: 8.1883e-04 - val_mae: 0.0212\n",
      "Epoch 409/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0075 - mae: 0.0550\n",
      "Epoch 409: val_loss did not improve from 0.00082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 8.2642e-04 - val_mae: 0.0213\n",
      "Epoch 410/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0536\n",
      "Epoch 410: val_loss did not improve from 0.00082\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0074 - mae: 0.0536 - val_loss: 8.1983e-04 - val_mae: 0.0212\n",
      "Epoch 411/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0537\n",
      "Epoch 411: val_loss improved from 0.00082 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0074 - mae: 0.0537 - val_loss: 8.1306e-04 - val_mae: 0.0211\n",
      "Epoch 412/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0551\n",
      "Epoch 412: val_loss improved from 0.00081 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0075 - mae: 0.0551 - val_loss: 8.1187e-04 - val_mae: 0.0212\n",
      "Epoch 413/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0551\n",
      "Epoch 413: val_loss did not improve from 0.00081\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0074 - mae: 0.0551 - val_loss: 8.1352e-04 - val_mae: 0.0212\n",
      "Epoch 414/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0077 - mae: 0.0547\n",
      "Epoch 414: val_loss improved from 0.00081 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0077 - mae: 0.0547 - val_loss: 8.1118e-04 - val_mae: 0.0211\n",
      "Epoch 415/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0535\n",
      "Epoch 415: val_loss improved from 0.00081 to 0.00081, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0073 - mae: 0.0535 - val_loss: 8.0795e-04 - val_mae: 0.0211\n",
      "Epoch 416/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0074 - mae: 0.0543\n",
      "Epoch 416: val_loss improved from 0.00081 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0074 - mae: 0.0543 - val_loss: 8.0493e-04 - val_mae: 0.0211\n",
      "Epoch 417/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0544\n",
      "Epoch 417: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0073 - mae: 0.0544 - val_loss: 8.0380e-04 - val_mae: 0.0210\n",
      "Epoch 418/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0545\n",
      "Epoch 418: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0074 - mae: 0.0545 - val_loss: 8.0257e-04 - val_mae: 0.0210\n",
      "Epoch 419/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0074 - mae: 0.0544\n",
      "Epoch 419: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0074 - mae: 0.0544 - val_loss: 8.0092e-04 - val_mae: 0.0210\n",
      "Epoch 420/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0074 - mae: 0.0544\n",
      "Epoch 420: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0074 - mae: 0.0544 - val_loss: 7.9810e-04 - val_mae: 0.0209\n",
      "Epoch 421/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - mae: 0.0543\n",
      "Epoch 421: val_loss improved from 0.00080 to 0.00080, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0074 - mae: 0.0543 - val_loss: 7.9656e-04 - val_mae: 0.0209\n",
      "Epoch 422/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0543\n",
      "Epoch 422: val_loss improved from 0.00080 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0073 - mae: 0.0543 - val_loss: 7.9367e-04 - val_mae: 0.0209\n",
      "Epoch 423/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0545\n",
      "Epoch 423: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0074 - mae: 0.0545 - val_loss: 7.9152e-04 - val_mae: 0.0209\n",
      "Epoch 424/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0074 - mae: 0.0547\n",
      "Epoch 424: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 7.8977e-04 - val_mae: 0.0208\n",
      "Epoch 425/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0074 - mae: 0.0547\n",
      "Epoch 425: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 7.8898e-04 - val_mae: 0.0208\n",
      "Epoch 426/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0075 - mae: 0.0545\n",
      "Epoch 426: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0075 - mae: 0.0545 - val_loss: 7.8765e-04 - val_mae: 0.0208\n",
      "Epoch 427/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0074 - mae: 0.0546\n",
      "Epoch 427: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0074 - mae: 0.0546 - val_loss: 7.8674e-04 - val_mae: 0.0208\n",
      "Epoch 428/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0542\n",
      "Epoch 428: val_loss improved from 0.00079 to 0.00079, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0073 - mae: 0.0542 - val_loss: 7.8522e-04 - val_mae: 0.0207\n",
      "Epoch 429/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0074 - mae: 0.0541\n",
      "Epoch 429: val_loss improved from 0.00079 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0074 - mae: 0.0541 - val_loss: 7.8458e-04 - val_mae: 0.0207\n",
      "Epoch 430/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0536\n",
      "Epoch 430: val_loss improved from 0.00078 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0073 - mae: 0.0536 - val_loss: 7.8190e-04 - val_mae: 0.0207\n",
      "Epoch 431/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0073 - mae: 0.0538\n",
      "Epoch 431: val_loss improved from 0.00078 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0073 - mae: 0.0538 - val_loss: 7.7844e-04 - val_mae: 0.0207\n",
      "Epoch 432/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0543\n",
      "Epoch 432: val_loss improved from 0.00078 to 0.00078, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0073 - mae: 0.0543 - val_loss: 7.7641e-04 - val_mae: 0.0206\n",
      "Epoch 433/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0547\n",
      "Epoch 433: val_loss improved from 0.00078 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 7.7461e-04 - val_mae: 0.0206\n",
      "Epoch 434/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0544\n",
      "Epoch 434: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0073 - mae: 0.0544 - val_loss: 7.7252e-04 - val_mae: 0.0206\n",
      "Epoch 435/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0074 - mae: 0.0545\n",
      "Epoch 435: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0074 - mae: 0.0545 - val_loss: 7.7083e-04 - val_mae: 0.0205\n",
      "Epoch 436/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0540\n",
      "Epoch 436: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0072 - mae: 0.0540 - val_loss: 7.6988e-04 - val_mae: 0.0205\n",
      "Epoch 437/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0538\n",
      "Epoch 437: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0073 - mae: 0.0538 - val_loss: 7.6851e-04 - val_mae: 0.0205\n",
      "Epoch 438/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0073 - mae: 0.0537\n",
      "Epoch 438: val_loss improved from 0.00077 to 0.00077, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0073 - mae: 0.0537 - val_loss: 7.6629e-04 - val_mae: 0.0205\n",
      "Epoch 439/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0535\n",
      "Epoch 439: val_loss improved from 0.00077 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0071 - mae: 0.0535 - val_loss: 7.6478e-04 - val_mae: 0.0204\n",
      "Epoch 440/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0539\n",
      "Epoch 440: val_loss improved from 0.00076 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0072 - mae: 0.0539 - val_loss: 7.6219e-04 - val_mae: 0.0204\n",
      "Epoch 441/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0073 - mae: 0.0540\n",
      "Epoch 441: val_loss improved from 0.00076 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0073 - mae: 0.0540 - val_loss: 7.6011e-04 - val_mae: 0.0204\n",
      "Epoch 442/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0073 - mae: 0.0539\n",
      "Epoch 442: val_loss did not improve from 0.00076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0073 - mae: 0.0539 - val_loss: 7.6040e-04 - val_mae: 0.0204\n",
      "Epoch 443/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0534\n",
      "Epoch 443: val_loss did not improve from 0.00076\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0071 - mae: 0.0534 - val_loss: 7.6030e-04 - val_mae: 0.0204\n",
      "Epoch 444/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0537\n",
      "Epoch 444: val_loss improved from 0.00076 to 0.00076, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0073 - mae: 0.0537 - val_loss: 7.5538e-04 - val_mae: 0.0203\n",
      "Epoch 445/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0541\n",
      "Epoch 445: val_loss improved from 0.00076 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0072 - mae: 0.0541 - val_loss: 7.5451e-04 - val_mae: 0.0203\n",
      "Epoch 446/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0539\n",
      "Epoch 446: val_loss did not improve from 0.00075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0072 - mae: 0.0539 - val_loss: 7.5578e-04 - val_mae: 0.0203\n",
      "Epoch 447/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0533\n",
      "Epoch 447: val_loss did not improve from 0.00075\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0071 - mae: 0.0533 - val_loss: 7.5507e-04 - val_mae: 0.0203\n",
      "Epoch 448/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0531\n",
      "Epoch 448: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 7.4997e-04 - val_mae: 0.0202\n",
      "Epoch 449/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0540\n",
      "Epoch 449: val_loss improved from 0.00075 to 0.00075, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0072 - mae: 0.0540 - val_loss: 7.4736e-04 - val_mae: 0.0202\n",
      "Epoch 450/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0073 - mae: 0.0549\n",
      "Epoch 450: val_loss improved from 0.00075 to 0.00074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0073 - mae: 0.0549 - val_loss: 7.4491e-04 - val_mae: 0.0202\n",
      "Epoch 451/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0070 - mae: 0.0534\n",
      "Epoch 451: val_loss did not improve from 0.00074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 7.5863e-04 - val_mae: 0.0204\n",
      "Epoch 452/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0524\n",
      "Epoch 452: val_loss did not improve from 0.00074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0071 - mae: 0.0524 - val_loss: 7.4622e-04 - val_mae: 0.0202\n",
      "Epoch 453/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0073 - mae: 0.0536\n",
      "Epoch 453: val_loss did not improve from 0.00074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0073 - mae: 0.0536 - val_loss: 7.4532e-04 - val_mae: 0.0202\n",
      "Epoch 454/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0554\n",
      "Epoch 454: val_loss improved from 0.00074 to 0.00074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0072 - mae: 0.0554 - val_loss: 7.3971e-04 - val_mae: 0.0201\n",
      "Epoch 455/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0544\n",
      "Epoch 455: val_loss did not improve from 0.00074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0070 - mae: 0.0544 - val_loss: 7.5346e-04 - val_mae: 0.0203\n",
      "Epoch 456/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0523\n",
      "Epoch 456: val_loss did not improve from 0.00074\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0071 - mae: 0.0523 - val_loss: 7.4670e-04 - val_mae: 0.0202\n",
      "Epoch 457/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0528\n",
      "Epoch 457: val_loss improved from 0.00074 to 0.00074, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0072 - mae: 0.0528 - val_loss: 7.3734e-04 - val_mae: 0.0201\n",
      "Epoch 458/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0546\n",
      "Epoch 458: val_loss improved from 0.00074 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0071 - mae: 0.0546 - val_loss: 7.3259e-04 - val_mae: 0.0200\n",
      "Epoch 459/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0542\n",
      "Epoch 459: val_loss did not improve from 0.00073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0072 - mae: 0.0542 - val_loss: 7.4230e-04 - val_mae: 0.0201\n",
      "Epoch 460/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0524\n",
      "Epoch 460: val_loss did not improve from 0.00073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0071 - mae: 0.0524 - val_loss: 7.3768e-04 - val_mae: 0.0200\n",
      "Epoch 461/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0072 - mae: 0.0529\n",
      "Epoch 461: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0072 - mae: 0.0529 - val_loss: 7.3057e-04 - val_mae: 0.0199\n",
      "Epoch 462/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0543\n",
      "Epoch 462: val_loss improved from 0.00073 to 0.00073, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0071 - mae: 0.0543 - val_loss: 7.2999e-04 - val_mae: 0.0199\n",
      "Epoch 463/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0071 - mae: 0.0545\n",
      "Epoch 463: val_loss did not improve from 0.00073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0071 - mae: 0.0545 - val_loss: 7.3032e-04 - val_mae: 0.0199\n",
      "Epoch 464/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0530\n",
      "Epoch 464: val_loss did not improve from 0.00073\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0071 - mae: 0.0530 - val_loss: 7.3761e-04 - val_mae: 0.0201\n",
      "Epoch 465/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0520\n",
      "Epoch 465: val_loss improved from 0.00073 to 0.00072, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0070 - mae: 0.0520 - val_loss: 7.2464e-04 - val_mae: 0.0199\n",
      "Epoch 466/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0072 - mae: 0.0538\n",
      "Epoch 466: val_loss did not improve from 0.00072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0072 - mae: 0.0538 - val_loss: 7.2912e-04 - val_mae: 0.0200\n",
      "Epoch 467/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0072 - mae: 0.0556\n",
      "Epoch 467: val_loss improved from 0.00072 to 0.00072, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0072 - mae: 0.0556 - val_loss: 7.2056e-04 - val_mae: 0.0198\n",
      "Epoch 468/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0071 - mae: 0.0543\n",
      "Epoch 468: val_loss did not improve from 0.00072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0071 - mae: 0.0543 - val_loss: 7.3168e-04 - val_mae: 0.0200\n",
      "Epoch 469/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0523\n",
      "Epoch 469: val_loss did not improve from 0.00072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0071 - mae: 0.0523 - val_loss: 7.2539e-04 - val_mae: 0.0199\n",
      "Epoch 470/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0071 - mae: 0.0525\n",
      "Epoch 470: val_loss improved from 0.00072 to 0.00072, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0071 - mae: 0.0525 - val_loss: 7.1598e-04 - val_mae: 0.0197\n",
      "Epoch 471/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0072 - mae: 0.0547\n",
      "Epoch 471: val_loss did not improve from 0.00072\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0072 - mae: 0.0547 - val_loss: 7.1705e-04 - val_mae: 0.0197\n",
      "Epoch 472/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0070 - mae: 0.0548\n",
      "Epoch 472: val_loss improved from 0.00072 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0070 - mae: 0.0548 - val_loss: 7.1455e-04 - val_mae: 0.0197\n",
      "Epoch 473/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0069 - mae: 0.0527\n",
      "Epoch 473: val_loss did not improve from 0.00071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0069 - mae: 0.0527 - val_loss: 7.2910e-04 - val_mae: 0.0199\n",
      "Epoch 474/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0518\n",
      "Epoch 474: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0070 - mae: 0.0518 - val_loss: 7.1200e-04 - val_mae: 0.0197\n",
      "Epoch 475/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0531\n",
      "Epoch 475: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 7.1096e-04 - val_mae: 0.0197\n",
      "Epoch 476/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0071 - mae: 0.0551\n",
      "Epoch 476: val_loss improved from 0.00071 to 0.00071, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0071 - mae: 0.0551 - val_loss: 7.0745e-04 - val_mae: 0.0196\n",
      "Epoch 477/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0542\n",
      "Epoch 477: val_loss did not improve from 0.00071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0070 - mae: 0.0542 - val_loss: 7.1323e-04 - val_mae: 0.0197\n",
      "Epoch 478/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0071 - mae: 0.0527\n",
      "Epoch 478: val_loss did not improve from 0.00071\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0071 - mae: 0.0527 - val_loss: 7.1395e-04 - val_mae: 0.0197\n",
      "Epoch 479/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0525\n",
      "Epoch 479: val_loss improved from 0.00071 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0071 - mae: 0.0525 - val_loss: 7.0338e-04 - val_mae: 0.0195\n",
      "Epoch 480/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0071 - mae: 0.0541\n",
      "Epoch 480: val_loss did not improve from 0.00070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0071 - mae: 0.0541 - val_loss: 7.0459e-04 - val_mae: 0.0196\n",
      "Epoch 481/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0546\n",
      "Epoch 481: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0070 - mae: 0.0546 - val_loss: 7.0301e-04 - val_mae: 0.0195\n",
      "Epoch 482/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0071 - mae: 0.0531\n",
      "Epoch 482: val_loss did not improve from 0.00070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 7.1139e-04 - val_mae: 0.0196\n",
      "Epoch 483/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0071 - mae: 0.0524\n",
      "Epoch 483: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0071 - mae: 0.0524 - val_loss: 6.9845e-04 - val_mae: 0.0194\n",
      "Epoch 484/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0531\n",
      "Epoch 484: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 6.9644e-04 - val_mae: 0.0194\n",
      "Epoch 485/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0540\n",
      "Epoch 485: val_loss improved from 0.00070 to 0.00070, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0070 - mae: 0.0540 - val_loss: 6.9528e-04 - val_mae: 0.0194\n",
      "Epoch 486/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0535\n",
      "Epoch 486: val_loss did not improve from 0.00070\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0070 - mae: 0.0535 - val_loss: 6.9829e-04 - val_mae: 0.0194\n",
      "Epoch 487/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0525\n",
      "Epoch 487: val_loss improved from 0.00070 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0070 - mae: 0.0525 - val_loss: 6.9497e-04 - val_mae: 0.0194\n",
      "Epoch 488/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0529\n",
      "Epoch 488: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0070 - mae: 0.0529 - val_loss: 6.9081e-04 - val_mae: 0.0193\n",
      "Epoch 489/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0538\n",
      "Epoch 489: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0070 - mae: 0.0538 - val_loss: 6.8929e-04 - val_mae: 0.0193\n",
      "Epoch 490/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0537\n",
      "Epoch 490: val_loss did not improve from 0.00069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0069 - mae: 0.0537 - val_loss: 6.9072e-04 - val_mae: 0.0193\n",
      "Epoch 491/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0523\n",
      "Epoch 491: val_loss did not improve from 0.00069\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0068 - mae: 0.0523 - val_loss: 6.9657e-04 - val_mae: 0.0194\n",
      "Epoch 492/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0070 - mae: 0.0522\n",
      "Epoch 492: val_loss improved from 0.00069 to 0.00069, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0070 - mae: 0.0522 - val_loss: 6.8553e-04 - val_mae: 0.0192\n",
      "Epoch 493/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0530\n",
      "Epoch 493: val_loss improved from 0.00069 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0069 - mae: 0.0530 - val_loss: 6.8485e-04 - val_mae: 0.0192\n",
      "Epoch 494/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0069 - mae: 0.0538\n",
      "Epoch 494: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0069 - mae: 0.0538 - val_loss: 6.8411e-04 - val_mae: 0.0192\n",
      "Epoch 495/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0070 - mae: 0.0534\n",
      "Epoch 495: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 6.8801e-04 - val_mae: 0.0193\n",
      "Epoch 496/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0523\n",
      "Epoch 496: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0068 - mae: 0.0523 - val_loss: 6.8733e-04 - val_mae: 0.0193\n",
      "Epoch 497/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0524\n",
      "Epoch 497: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0069 - mae: 0.0524 - val_loss: 6.7997e-04 - val_mae: 0.0192\n",
      "Epoch 498/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0069 - mae: 0.0531\n",
      "Epoch 498: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 6.7807e-04 - val_mae: 0.0191\n",
      "Epoch 499/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0539\n",
      "Epoch 499: val_loss improved from 0.00068 to 0.00068, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0070 - mae: 0.0539 - val_loss: 6.7669e-04 - val_mae: 0.0191\n",
      "Epoch 500/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0532\n",
      "Epoch 500: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0069 - mae: 0.0532 - val_loss: 6.7803e-04 - val_mae: 0.0191\n",
      "Epoch 501/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0069 - mae: 0.0527\n",
      "Epoch 501: val_loss did not improve from 0.00068\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0069 - mae: 0.0527 - val_loss: 6.7736e-04 - val_mae: 0.0191\n",
      "Epoch 502/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0070 - mae: 0.0527\n",
      "Epoch 502: val_loss improved from 0.00068 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0070 - mae: 0.0527 - val_loss: 6.7326e-04 - val_mae: 0.0190\n",
      "Epoch 503/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0531\n",
      "Epoch 503: val_loss improved from 0.00067 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 6.7138e-04 - val_mae: 0.0190\n",
      "Epoch 504/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0534\n",
      "Epoch 504: val_loss did not improve from 0.00067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0069 - mae: 0.0534 - val_loss: 6.7238e-04 - val_mae: 0.0190\n",
      "Epoch 505/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0524\n",
      "Epoch 505: val_loss did not improve from 0.00067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 6.7670e-04 - val_mae: 0.0191\n",
      "Epoch 506/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0069 - mae: 0.0522\n",
      "Epoch 506: val_loss improved from 0.00067 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0069 - mae: 0.0522 - val_loss: 6.6834e-04 - val_mae: 0.0190\n",
      "Epoch 507/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 507: val_loss improved from 0.00067 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 6.6650e-04 - val_mae: 0.0189\n",
      "Epoch 508/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0540\n",
      "Epoch 508: val_loss improved from 0.00067 to 0.00067, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0069 - mae: 0.0540 - val_loss: 6.6504e-04 - val_mae: 0.0189\n",
      "Epoch 509/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0534\n",
      "Epoch 509: val_loss did not improve from 0.00067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0069 - mae: 0.0534 - val_loss: 6.6982e-04 - val_mae: 0.0190\n",
      "Epoch 510/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0519\n",
      "Epoch 510: val_loss did not improve from 0.00067\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0068 - mae: 0.0519 - val_loss: 6.6969e-04 - val_mae: 0.0190\n",
      "Epoch 511/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0070 - mae: 0.0524\n",
      "Epoch 511: val_loss improved from 0.00067 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0070 - mae: 0.0524 - val_loss: 6.6224e-04 - val_mae: 0.0189\n",
      "Epoch 512/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0533\n",
      "Epoch 512: val_loss improved from 0.00066 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0068 - mae: 0.0533 - val_loss: 6.6039e-04 - val_mae: 0.0188\n",
      "Epoch 513/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0068 - mae: 0.0533\n",
      "Epoch 513: val_loss did not improve from 0.00066\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0068 - mae: 0.0533 - val_loss: 6.6373e-04 - val_mae: 0.0189\n",
      "Epoch 514/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0067 - mae: 0.0523\n",
      "Epoch 514: val_loss improved from 0.00066 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 6.6019e-04 - val_mae: 0.0188\n",
      "Epoch 515/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0523\n",
      "Epoch 515: val_loss improved from 0.00066 to 0.00066, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0068 - mae: 0.0523 - val_loss: 6.5653e-04 - val_mae: 0.0188\n",
      "Epoch 516/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0069 - mae: 0.0531\n",
      "Epoch 516: val_loss improved from 0.00066 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 6.5479e-04 - val_mae: 0.0188\n",
      "Epoch 517/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0535\n",
      "Epoch 517: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0068 - mae: 0.0535 - val_loss: 6.5556e-04 - val_mae: 0.0188\n",
      "Epoch 518/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0522\n",
      "Epoch 518: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0067 - mae: 0.0522 - val_loss: 6.6043e-04 - val_mae: 0.0188\n",
      "Epoch 519/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0521\n",
      "Epoch 519: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0068 - mae: 0.0521 - val_loss: 6.5253e-04 - val_mae: 0.0187\n",
      "Epoch 520/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0529\n",
      "Epoch 520: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0069 - mae: 0.0529 - val_loss: 6.5070e-04 - val_mae: 0.0187\n",
      "Epoch 521/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0535\n",
      "Epoch 521: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0068 - mae: 0.0535 - val_loss: 6.5102e-04 - val_mae: 0.0187\n",
      "Epoch 522/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 522: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 6.5502e-04 - val_mae: 0.0187\n",
      "Epoch 523/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0520\n",
      "Epoch 523: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0068 - mae: 0.0520 - val_loss: 6.4768e-04 - val_mae: 0.0186\n",
      "Epoch 524/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0069 - mae: 0.0528\n",
      "Epoch 524: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - loss: 0.0069 - mae: 0.0528 - val_loss: 6.4628e-04 - val_mae: 0.0186\n",
      "Epoch 525/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0068 - mae: 0.0537\n",
      "Epoch 525: val_loss improved from 0.00065 to 0.00065, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0068 - mae: 0.0537 - val_loss: 6.4578e-04 - val_mae: 0.0186\n",
      "Epoch 526/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0530\n",
      "Epoch 526: val_loss did not improve from 0.00065\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0069 - mae: 0.0530 - val_loss: 6.4994e-04 - val_mae: 0.0187\n",
      "Epoch 527/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0068 - mae: 0.0522\n",
      "Epoch 527: val_loss improved from 0.00065 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0068 - mae: 0.0522 - val_loss: 6.4498e-04 - val_mae: 0.0186\n",
      "Epoch 528/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 528: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 6.4351e-04 - val_mae: 0.0186\n",
      "Epoch 529/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0529\n",
      "Epoch 529: val_loss did not improve from 0.00064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0067 - mae: 0.0529 - val_loss: 6.4392e-04 - val_mae: 0.0186\n",
      "Epoch 530/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 530: val_loss did not improve from 0.00064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 6.4811e-04 - val_mae: 0.0186\n",
      "Epoch 531/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0517\n",
      "Epoch 531: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0068 - mae: 0.0517 - val_loss: 6.4161e-04 - val_mae: 0.0185\n",
      "Epoch 532/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 532: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 6.4009e-04 - val_mae: 0.0185\n",
      "Epoch 533/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0067 - mae: 0.0535\n",
      "Epoch 533: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0067 - mae: 0.0535 - val_loss: 6.3759e-04 - val_mae: 0.0185\n",
      "Epoch 534/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0526\n",
      "Epoch 534: val_loss did not improve from 0.00064\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0067 - mae: 0.0526 - val_loss: 6.4637e-04 - val_mae: 0.0186\n",
      "Epoch 535/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0516\n",
      "Epoch 535: val_loss improved from 0.00064 to 0.00064, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0068 - mae: 0.0516 - val_loss: 6.3666e-04 - val_mae: 0.0184\n",
      "Epoch 536/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0519\n",
      "Epoch 536: val_loss improved from 0.00064 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0067 - mae: 0.0519 - val_loss: 6.3364e-04 - val_mae: 0.0184\n",
      "Epoch 537/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 537: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 6.3315e-04 - val_mae: 0.0184\n",
      "Epoch 538/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0523\n",
      "Epoch 538: val_loss did not improve from 0.00063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 6.3988e-04 - val_mae: 0.0185\n",
      "Epoch 539/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0522\n",
      "Epoch 539: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0068 - mae: 0.0522 - val_loss: 6.3031e-04 - val_mae: 0.0183\n",
      "Epoch 540/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0529\n",
      "Epoch 540: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0068 - mae: 0.0529 - val_loss: 6.2801e-04 - val_mae: 0.0183\n",
      "Epoch 541/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0538\n",
      "Epoch 541: val_loss improved from 0.00063 to 0.00063, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0068 - mae: 0.0538 - val_loss: 6.2607e-04 - val_mae: 0.0183\n",
      "Epoch 542/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 542: val_loss did not improve from 0.00063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 6.3309e-04 - val_mae: 0.0184\n",
      "Epoch 543/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0068 - mae: 0.0519\n",
      "Epoch 543: val_loss did not improve from 0.00063\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0068 - mae: 0.0519 - val_loss: 6.2628e-04 - val_mae: 0.0183\n",
      "Epoch 544/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 544: val_loss improved from 0.00063 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 6.2415e-04 - val_mae: 0.0182\n",
      "Epoch 545/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0528\n",
      "Epoch 545: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0066 - mae: 0.0528 - val_loss: 6.2618e-04 - val_mae: 0.0183\n",
      "Epoch 546/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0068 - mae: 0.0525\n",
      "Epoch 546: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0068 - mae: 0.0525 - val_loss: 6.2843e-04 - val_mae: 0.0183\n",
      "Epoch 547/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0069 - mae: 0.0525\n",
      "Epoch 547: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0069 - mae: 0.0525 - val_loss: 6.2270e-04 - val_mae: 0.0182\n",
      "Epoch 548/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0524\n",
      "Epoch 548: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0524 - val_loss: 6.2188e-04 - val_mae: 0.0182\n",
      "Epoch 549/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0067 - mae: 0.0526\n",
      "Epoch 549: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0067 - mae: 0.0526 - val_loss: 6.2376e-04 - val_mae: 0.0182\n",
      "Epoch 550/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0520\n",
      "Epoch 550: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0067 - mae: 0.0520 - val_loss: 6.1957e-04 - val_mae: 0.0182\n",
      "Epoch 551/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0525\n",
      "Epoch 551: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0066 - mae: 0.0525 - val_loss: 6.1801e-04 - val_mae: 0.0182\n",
      "Epoch 552/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0527\n",
      "Epoch 552: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0067 - mae: 0.0527 - val_loss: 6.1840e-04 - val_mae: 0.0182\n",
      "Epoch 553/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0068 - mae: 0.0526\n",
      "Epoch 553: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0068 - mae: 0.0526 - val_loss: 6.1726e-04 - val_mae: 0.0181\n",
      "Epoch 554/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 554: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 6.1708e-04 - val_mae: 0.0181\n",
      "Epoch 555/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0526\n",
      "Epoch 555: val_loss did not improve from 0.00062\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0066 - mae: 0.0526 - val_loss: 6.1776e-04 - val_mae: 0.0181\n",
      "Epoch 556/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 556: val_loss improved from 0.00062 to 0.00062, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 6.1596e-04 - val_mae: 0.0181\n",
      "Epoch 557/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 557: val_loss improved from 0.00062 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 6.1167e-04 - val_mae: 0.0180\n",
      "Epoch 558/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0524\n",
      "Epoch 558: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 6.1049e-04 - val_mae: 0.0180\n",
      "Epoch 559/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 559: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 6.1108e-04 - val_mae: 0.0180\n",
      "Epoch 560/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 560: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 6.1072e-04 - val_mae: 0.0180\n",
      "Epoch 561/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0521\n",
      "Epoch 561: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0066 - mae: 0.0521 - val_loss: 6.0802e-04 - val_mae: 0.0180\n",
      "Epoch 562/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 562: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 6.0867e-04 - val_mae: 0.0180\n",
      "Epoch 563/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 563: val_loss did not improve from 0.00061\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 6.1072e-04 - val_mae: 0.0180\n",
      "Epoch 564/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0520\n",
      "Epoch 564: val_loss improved from 0.00061 to 0.00061, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0067 - mae: 0.0520 - val_loss: 6.0690e-04 - val_mae: 0.0180\n",
      "Epoch 565/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0066 - mae: 0.0525\n",
      "Epoch 565: val_loss improved from 0.00061 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0066 - mae: 0.0525 - val_loss: 6.0408e-04 - val_mae: 0.0179\n",
      "Epoch 566/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0528\n",
      "Epoch 566: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0067 - mae: 0.0528 - val_loss: 6.0312e-04 - val_mae: 0.0179\n",
      "Epoch 567/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0066 - mae: 0.0524\n",
      "Epoch 567: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0066 - mae: 0.0524 - val_loss: 6.0819e-04 - val_mae: 0.0180\n",
      "Epoch 568/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0068 - mae: 0.0521\n",
      "Epoch 568: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0068 - mae: 0.0521 - val_loss: 6.0109e-04 - val_mae: 0.0179\n",
      "Epoch 569/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 569: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.9985e-04 - val_mae: 0.0179\n",
      "Epoch 570/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0525\n",
      "Epoch 570: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0065 - mae: 0.0525 - val_loss: 6.0142e-04 - val_mae: 0.0179\n",
      "Epoch 571/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0522\n",
      "Epoch 571: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0067 - mae: 0.0522 - val_loss: 6.0070e-04 - val_mae: 0.0179\n",
      "Epoch 572/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 572: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.9948e-04 - val_mae: 0.0178\n",
      "Epoch 573/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0527\n",
      "Epoch 573: val_loss did not improve from 0.00060\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 5.9979e-04 - val_mae: 0.0178\n",
      "Epoch 574/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0067 - mae: 0.0529\n",
      "Epoch 574: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0067 - mae: 0.0529 - val_loss: 5.9678e-04 - val_mae: 0.0178\n",
      "Epoch 575/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0526\n",
      "Epoch 575: val_loss improved from 0.00060 to 0.00060, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0066 - mae: 0.0526 - val_loss: 5.9542e-04 - val_mae: 0.0178\n",
      "Epoch 576/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0067 - mae: 0.0525\n",
      "Epoch 576: val_loss improved from 0.00060 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 5.9306e-04 - val_mae: 0.0177\n",
      "Epoch 577/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0524\n",
      "Epoch 577: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0066 - mae: 0.0524 - val_loss: 5.9323e-04 - val_mae: 0.0177\n",
      "Epoch 578/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0067 - mae: 0.0523\n",
      "Epoch 578: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 5.9357e-04 - val_mae: 0.0177\n",
      "Epoch 579/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 579: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 5.9351e-04 - val_mae: 0.0177\n",
      "Epoch 580/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 580: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 5.9337e-04 - val_mae: 0.0177\n",
      "Epoch 581/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0066 - mae: 0.0525\n",
      "Epoch 581: val_loss improved from 0.00059 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0066 - mae: 0.0525 - val_loss: 5.9169e-04 - val_mae: 0.0177\n",
      "Epoch 582/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0523\n",
      "Epoch 582: val_loss improved from 0.00059 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 5.8977e-04 - val_mae: 0.0177\n",
      "Epoch 583/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0523\n",
      "Epoch 583: val_loss improved from 0.00059 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0066 - mae: 0.0523 - val_loss: 5.8714e-04 - val_mae: 0.0176\n",
      "Epoch 584/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0520\n",
      "Epoch 584: val_loss did not improve from 0.00059\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0065 - mae: 0.0520 - val_loss: 5.8724e-04 - val_mae: 0.0176\n",
      "Epoch 585/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0520\n",
      "Epoch 585: val_loss improved from 0.00059 to 0.00059, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0066 - mae: 0.0520 - val_loss: 5.8683e-04 - val_mae: 0.0176\n",
      "Epoch 586/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0066 - mae: 0.0522\n",
      "Epoch 586: val_loss improved from 0.00059 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 5.8425e-04 - val_mae: 0.0176\n",
      "Epoch 587/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0065 - mae: 0.0528\n",
      "Epoch 587: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0065 - mae: 0.0528 - val_loss: 5.8471e-04 - val_mae: 0.0176\n",
      "Epoch 588/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0529\n",
      "Epoch 588: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0067 - mae: 0.0529 - val_loss: 5.8934e-04 - val_mae: 0.0176\n",
      "Epoch 589/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0519\n",
      "Epoch 589: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0066 - mae: 0.0519 - val_loss: 5.8900e-04 - val_mae: 0.0176\n",
      "Epoch 590/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 590: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 5.8306e-04 - val_mae: 0.0176\n",
      "Epoch 591/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0066 - mae: 0.0527\n",
      "Epoch 591: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 5.8026e-04 - val_mae: 0.0175\n",
      "Epoch 592/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 592: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 5.8346e-04 - val_mae: 0.0176\n",
      "Epoch 593/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0066 - mae: 0.0516\n",
      "Epoch 593: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0066 - mae: 0.0516 - val_loss: 5.8107e-04 - val_mae: 0.0175\n",
      "Epoch 594/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0066 - mae: 0.0519\n",
      "Epoch 594: val_loss improved from 0.00058 to 0.00058, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0066 - mae: 0.0519 - val_loss: 5.7726e-04 - val_mae: 0.0175\n",
      "Epoch 595/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0067 - mae: 0.0532\n",
      "Epoch 595: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0067 - mae: 0.0532 - val_loss: 5.7732e-04 - val_mae: 0.0175\n",
      "Epoch 596/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0530\n",
      "Epoch 596: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0065 - mae: 0.0530 - val_loss: 5.8118e-04 - val_mae: 0.0175\n",
      "Epoch 597/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0514\n",
      "Epoch 597: val_loss did not improve from 0.00058\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0065 - mae: 0.0514 - val_loss: 5.8593e-04 - val_mae: 0.0176\n",
      "Epoch 598/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0512\n",
      "Epoch 598: val_loss improved from 0.00058 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0065 - mae: 0.0512 - val_loss: 5.7419e-04 - val_mae: 0.0174\n",
      "Epoch 599/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 599: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 5.7241e-04 - val_mae: 0.0174\n",
      "Epoch 600/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0529\n",
      "Epoch 600: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0065 - mae: 0.0529 - val_loss: 5.7508e-04 - val_mae: 0.0174\n",
      "Epoch 601/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0513\n",
      "Epoch 601: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0064 - mae: 0.0513 - val_loss: 5.7805e-04 - val_mae: 0.0175\n",
      "Epoch 602/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0512\n",
      "Epoch 602: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0065 - mae: 0.0512 - val_loss: 5.6970e-04 - val_mae: 0.0173\n",
      "Epoch 603/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0523\n",
      "Epoch 603: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 5.6984e-04 - val_mae: 0.0173\n",
      "Epoch 604/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0527\n",
      "Epoch 604: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0064 - mae: 0.0527 - val_loss: 5.7701e-04 - val_mae: 0.0174\n",
      "Epoch 605/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0511\n",
      "Epoch 605: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0065 - mae: 0.0511 - val_loss: 5.7787e-04 - val_mae: 0.0175\n",
      "Epoch 606/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0513\n",
      "Epoch 606: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0065 - mae: 0.0513 - val_loss: 5.6995e-04 - val_mae: 0.0173\n",
      "Epoch 607/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0528\n",
      "Epoch 607: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0528 - val_loss: 5.6719e-04 - val_mae: 0.0173\n",
      "Epoch 608/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0527\n",
      "Epoch 608: val_loss did not improve from 0.00057\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0065 - mae: 0.0527 - val_loss: 5.7179e-04 - val_mae: 0.0174\n",
      "Epoch 609/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0513\n",
      "Epoch 609: val_loss improved from 0.00057 to 0.00057, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0065 - mae: 0.0513 - val_loss: 5.6663e-04 - val_mae: 0.0173\n",
      "Epoch 610/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0064 - mae: 0.0517\n",
      "Epoch 610: val_loss improved from 0.00057 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 5.6351e-04 - val_mae: 0.0173\n",
      "Epoch 611/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0526\n",
      "Epoch 611: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0064 - mae: 0.0526 - val_loss: 5.6361e-04 - val_mae: 0.0172\n",
      "Epoch 612/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0517\n",
      "Epoch 612: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 5.7184e-04 - val_mae: 0.0174\n",
      "Epoch 613/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0512\n",
      "Epoch 613: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0064 - mae: 0.0512 - val_loss: 5.6291e-04 - val_mae: 0.0172\n",
      "Epoch 614/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0065 - mae: 0.0524\n",
      "Epoch 614: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0065 - mae: 0.0524 - val_loss: 5.6109e-04 - val_mae: 0.0172\n",
      "Epoch 615/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0064 - mae: 0.0527\n",
      "Epoch 615: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0064 - mae: 0.0527 - val_loss: 5.6297e-04 - val_mae: 0.0172\n",
      "Epoch 616/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0518\n",
      "Epoch 616: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0065 - mae: 0.0518 - val_loss: 5.6332e-04 - val_mae: 0.0172\n",
      "Epoch 617/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 617: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 5.5812e-04 - val_mae: 0.0171\n",
      "Epoch 618/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0064 - mae: 0.0515\n",
      "Epoch 618: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0064 - mae: 0.0515 - val_loss: 5.5622e-04 - val_mae: 0.0171\n",
      "Epoch 619/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0521\n",
      "Epoch 619: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0064 - mae: 0.0521 - val_loss: 5.5816e-04 - val_mae: 0.0171\n",
      "Epoch 620/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0516\n",
      "Epoch 620: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0063 - mae: 0.0516 - val_loss: 5.6266e-04 - val_mae: 0.0172\n",
      "Epoch 621/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 621: val_loss did not improve from 0.00056\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 5.5732e-04 - val_mae: 0.0171\n",
      "Epoch 622/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0063 - mae: 0.0516\n",
      "Epoch 622: val_loss improved from 0.00056 to 0.00056, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0063 - mae: 0.0516 - val_loss: 5.5518e-04 - val_mae: 0.0171\n",
      "Epoch 623/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0065 - mae: 0.0523\n",
      "Epoch 623: val_loss improved from 0.00056 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0065 - mae: 0.0523 - val_loss: 5.5404e-04 - val_mae: 0.0171\n",
      "Epoch 624/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0065 - mae: 0.0522\n",
      "Epoch 624: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0065 - mae: 0.0522 - val_loss: 5.5420e-04 - val_mae: 0.0171\n",
      "Epoch 625/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 625: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 5.5474e-04 - val_mae: 0.0171\n",
      "Epoch 626/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0512\n",
      "Epoch 626: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0063 - mae: 0.0512 - val_loss: 5.5312e-04 - val_mae: 0.0170\n",
      "Epoch 627/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0517\n",
      "Epoch 627: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0064 - mae: 0.0517 - val_loss: 5.4977e-04 - val_mae: 0.0170\n",
      "Epoch 628/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0520\n",
      "Epoch 628: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0063 - mae: 0.0520 - val_loss: 5.5046e-04 - val_mae: 0.0170\n",
      "Epoch 629/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 629: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 5.5352e-04 - val_mae: 0.0170\n",
      "Epoch 630/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 630: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 5.5088e-04 - val_mae: 0.0170\n",
      "Epoch 631/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0516\n",
      "Epoch 631: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 5.4836e-04 - val_mae: 0.0170\n",
      "Epoch 632/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0064 - mae: 0.0521\n",
      "Epoch 632: val_loss improved from 0.00055 to 0.00055, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0064 - mae: 0.0521 - val_loss: 5.4757e-04 - val_mae: 0.0169\n",
      "Epoch 633/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0517\n",
      "Epoch 633: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 5.4848e-04 - val_mae: 0.0170\n",
      "Epoch 634/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 634: val_loss did not improve from 0.00055\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 5.4837e-04 - val_mae: 0.0170\n",
      "Epoch 635/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0513\n",
      "Epoch 635: val_loss improved from 0.00055 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0064 - mae: 0.0513 - val_loss: 5.4336e-04 - val_mae: 0.0169\n",
      "Epoch 636/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0064 - mae: 0.0520\n",
      "Epoch 636: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0064 - mae: 0.0520 - val_loss: 5.4284e-04 - val_mae: 0.0169\n",
      "Epoch 637/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0516\n",
      "Epoch 637: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0061 - mae: 0.0516 - val_loss: 5.5521e-04 - val_mae: 0.0171\n",
      "Epoch 638/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0503\n",
      "Epoch 638: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0063 - mae: 0.0503 - val_loss: 5.5011e-04 - val_mae: 0.0170\n",
      "Epoch 639/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0062 - mae: 0.0507\n",
      "Epoch 639: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0062 - mae: 0.0507 - val_loss: 5.4307e-04 - val_mae: 0.0169\n",
      "Epoch 640/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0063 - mae: 0.0521\n",
      "Epoch 640: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 5.4134e-04 - val_mae: 0.0168\n",
      "Epoch 641/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0064 - mae: 0.0522\n",
      "Epoch 641: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0064 - mae: 0.0522 - val_loss: 5.4817e-04 - val_mae: 0.0170\n",
      "Epoch 642/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0508\n",
      "Epoch 642: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0063 - mae: 0.0508 - val_loss: 5.4251e-04 - val_mae: 0.0169\n",
      "Epoch 643/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0510\n",
      "Epoch 643: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0063 - mae: 0.0510 - val_loss: 5.3752e-04 - val_mae: 0.0168\n",
      "Epoch 644/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0520\n",
      "Epoch 644: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0063 - mae: 0.0520 - val_loss: 5.3903e-04 - val_mae: 0.0168\n",
      "Epoch 645/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0513\n",
      "Epoch 645: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0513 - val_loss: 5.4572e-04 - val_mae: 0.0169\n",
      "Epoch 646/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0064 - mae: 0.0508\n",
      "Epoch 646: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0064 - mae: 0.0508 - val_loss: 5.3810e-04 - val_mae: 0.0168\n",
      "Epoch 647/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0063 - mae: 0.0517\n",
      "Epoch 647: val_loss improved from 0.00054 to 0.00054, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0063 - mae: 0.0517 - val_loss: 5.3582e-04 - val_mae: 0.0167\n",
      "Epoch 648/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0519\n",
      "Epoch 648: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 5.4176e-04 - val_mae: 0.0168\n",
      "Epoch 649/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0506\n",
      "Epoch 649: val_loss did not improve from 0.00054\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0062 - mae: 0.0506 - val_loss: 5.4236e-04 - val_mae: 0.0168\n",
      "Epoch 650/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0509\n",
      "Epoch 650: val_loss improved from 0.00054 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0063 - mae: 0.0509 - val_loss: 5.3263e-04 - val_mae: 0.0167\n",
      "Epoch 651/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0526\n",
      "Epoch 651: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0063 - mae: 0.0526 - val_loss: 5.3145e-04 - val_mae: 0.0167\n",
      "Epoch 652/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0521\n",
      "Epoch 652: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 5.4691e-04 - val_mae: 0.0169\n",
      "Epoch 653/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0504\n",
      "Epoch 653: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0504 - val_loss: 5.3445e-04 - val_mae: 0.0167\n",
      "Epoch 654/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0064 - mae: 0.0514\n",
      "Epoch 654: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 5.3344e-04 - val_mae: 0.0167\n",
      "Epoch 655/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0530\n",
      "Epoch 655: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0530 - val_loss: 5.3405e-04 - val_mae: 0.0167\n",
      "Epoch 656/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0515\n",
      "Epoch 656: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0063 - mae: 0.0515 - val_loss: 5.5020e-04 - val_mae: 0.0170\n",
      "Epoch 657/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0498\n",
      "Epoch 657: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0062 - mae: 0.0498 - val_loss: 5.3552e-04 - val_mae: 0.0167\n",
      "Epoch 658/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0510\n",
      "Epoch 658: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0062 - mae: 0.0510 - val_loss: 5.2789e-04 - val_mae: 0.0166\n",
      "Epoch 659/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0526\n",
      "Epoch 659: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0062 - mae: 0.0526 - val_loss: 5.2709e-04 - val_mae: 0.0166\n",
      "Epoch 660/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0514\n",
      "Epoch 660: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0063 - mae: 0.0514 - val_loss: 5.3904e-04 - val_mae: 0.0168\n",
      "Epoch 661/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0062 - mae: 0.0501\n",
      "Epoch 661: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0062 - mae: 0.0501 - val_loss: 5.2855e-04 - val_mae: 0.0166\n",
      "Epoch 662/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0062 - mae: 0.0509\n",
      "Epoch 662: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0062 - mae: 0.0509 - val_loss: 5.2702e-04 - val_mae: 0.0166\n",
      "Epoch 663/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0063 - mae: 0.0524\n",
      "Epoch 663: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0063 - mae: 0.0524 - val_loss: 5.2855e-04 - val_mae: 0.0166\n",
      "Epoch 664/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0515\n",
      "Epoch 664: val_loss did not improve from 0.00053\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0062 - mae: 0.0515 - val_loss: 5.4111e-04 - val_mae: 0.0168\n",
      "Epoch 665/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0063 - mae: 0.0503\n",
      "Epoch 665: val_loss improved from 0.00053 to 0.00053, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0063 - mae: 0.0503 - val_loss: 5.2565e-04 - val_mae: 0.0166\n",
      "Epoch 666/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0514\n",
      "Epoch 666: val_loss improved from 0.00053 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0063 - mae: 0.0514 - val_loss: 5.2252e-04 - val_mae: 0.0165\n",
      "Epoch 667/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0517\n",
      "Epoch 667: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 5.3015e-04 - val_mae: 0.0166\n",
      "Epoch 668/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0506\n",
      "Epoch 668: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0063 - mae: 0.0506 - val_loss: 5.2544e-04 - val_mae: 0.0166\n",
      "Epoch 669/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0062 - mae: 0.0508\n",
      "Epoch 669: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0062 - mae: 0.0508 - val_loss: 5.2117e-04 - val_mae: 0.0165\n",
      "Epoch 670/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0521\n",
      "Epoch 670: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 5.2289e-04 - val_mae: 0.0165\n",
      "Epoch 671/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0515\n",
      "Epoch 671: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 5.3083e-04 - val_mae: 0.0166\n",
      "Epoch 672/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0503\n",
      "Epoch 672: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0061 - mae: 0.0503 - val_loss: 5.3220e-04 - val_mae: 0.0167\n",
      "Epoch 673/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0506\n",
      "Epoch 673: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0063 - mae: 0.0506 - val_loss: 5.1806e-04 - val_mae: 0.0164\n",
      "Epoch 674/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0525\n",
      "Epoch 674: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0063 - mae: 0.0525 - val_loss: 5.1693e-04 - val_mae: 0.0165\n",
      "Epoch 675/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0062 - mae: 0.0526\n",
      "Epoch 675: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0062 - mae: 0.0526 - val_loss: 5.2803e-04 - val_mae: 0.0166\n",
      "Epoch 676/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0506\n",
      "Epoch 676: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0063 - mae: 0.0506 - val_loss: 5.2272e-04 - val_mae: 0.0165\n",
      "Epoch 677/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0504\n",
      "Epoch 677: val_loss improved from 0.00052 to 0.00052, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0061 - mae: 0.0504 - val_loss: 5.1563e-04 - val_mae: 0.0164\n",
      "Epoch 678/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0523\n",
      "Epoch 678: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0061 - mae: 0.0523 - val_loss: 5.1665e-04 - val_mae: 0.0164\n",
      "Epoch 679/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0515\n",
      "Epoch 679: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0515 - val_loss: 5.2959e-04 - val_mae: 0.0166\n",
      "Epoch 680/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0500\n",
      "Epoch 680: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0061 - mae: 0.0500 - val_loss: 5.2239e-04 - val_mae: 0.0165\n",
      "Epoch 681/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0063 - mae: 0.0509\n",
      "Epoch 681: val_loss did not improve from 0.00052\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0063 - mae: 0.0509 - val_loss: 5.1579e-04 - val_mae: 0.0164\n",
      "Epoch 682/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0528\n",
      "Epoch 682: val_loss improved from 0.00052 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0063 - mae: 0.0528 - val_loss: 5.1322e-04 - val_mae: 0.0164\n",
      "Epoch 683/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0518\n",
      "Epoch 683: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0061 - mae: 0.0518 - val_loss: 5.3565e-04 - val_mae: 0.0168\n",
      "Epoch 684/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0063 - mae: 0.0500\n",
      "Epoch 684: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0063 - mae: 0.0500 - val_loss: 5.1660e-04 - val_mae: 0.0164\n",
      "Epoch 685/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0507\n",
      "Epoch 685: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0061 - mae: 0.0507 - val_loss: 5.1403e-04 - val_mae: 0.0164\n",
      "Epoch 686/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0524\n",
      "Epoch 686: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0062 - mae: 0.0524 - val_loss: 5.1259e-04 - val_mae: 0.0163\n",
      "Epoch 687/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0513\n",
      "Epoch 687: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 5.2606e-04 - val_mae: 0.0166\n",
      "Epoch 688/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0061 - mae: 0.0498\n",
      "Epoch 688: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0061 - mae: 0.0498 - val_loss: 5.1270e-04 - val_mae: 0.0163\n",
      "Epoch 689/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0509\n",
      "Epoch 689: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - loss: 0.0062 - mae: 0.0509 - val_loss: 5.0822e-04 - val_mae: 0.0163\n",
      "Epoch 690/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0528\n",
      "Epoch 690: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0062 - mae: 0.0528 - val_loss: 5.0713e-04 - val_mae: 0.0162\n",
      "Epoch 691/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0063 - mae: 0.0520\n",
      "Epoch 691: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0063 - mae: 0.0520 - val_loss: 5.1549e-04 - val_mae: 0.0164\n",
      "Epoch 692/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0506\n",
      "Epoch 692: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0506 - val_loss: 5.1023e-04 - val_mae: 0.0163\n",
      "Epoch 693/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mae: 0.0509\n",
      "Epoch 693: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0061 - mae: 0.0509 - val_loss: 5.0547e-04 - val_mae: 0.0162\n",
      "Epoch 694/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0519\n",
      "Epoch 694: val_loss improved from 0.00051 to 0.00051, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 5.0525e-04 - val_mae: 0.0162\n",
      "Epoch 695/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0515\n",
      "Epoch 695: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0062 - mae: 0.0515 - val_loss: 5.1099e-04 - val_mae: 0.0163\n",
      "Epoch 696/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0499\n",
      "Epoch 696: val_loss did not improve from 0.00051\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0060 - mae: 0.0499 - val_loss: 5.1256e-04 - val_mae: 0.0163\n",
      "Epoch 697/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0062 - mae: 0.0505\n",
      "Epoch 697: val_loss improved from 0.00051 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0062 - mae: 0.0505 - val_loss: 5.0286e-04 - val_mae: 0.0162\n",
      "Epoch 698/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0517\n",
      "Epoch 698: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 5.0368e-04 - val_mae: 0.0162\n",
      "Epoch 699/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0523\n",
      "Epoch 699: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0062 - mae: 0.0523 - val_loss: 5.0970e-04 - val_mae: 0.0163\n",
      "Epoch 700/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0508\n",
      "Epoch 700: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0061 - mae: 0.0508 - val_loss: 5.1783e-04 - val_mae: 0.0164\n",
      "Epoch 701/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0504\n",
      "Epoch 701: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0062 - mae: 0.0504 - val_loss: 5.0711e-04 - val_mae: 0.0162\n",
      "Epoch 702/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0509\n",
      "Epoch 702: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0060 - mae: 0.0509 - val_loss: 5.0180e-04 - val_mae: 0.0161\n",
      "Epoch 703/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0520\n",
      "Epoch 703: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0062 - mae: 0.0520 - val_loss: 4.9961e-04 - val_mae: 0.0161\n",
      "Epoch 704/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0511\n",
      "Epoch 704: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 5.0497e-04 - val_mae: 0.0162\n",
      "Epoch 705/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0503\n",
      "Epoch 705: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0060 - mae: 0.0503 - val_loss: 5.0296e-04 - val_mae: 0.0161\n",
      "Epoch 706/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0505\n",
      "Epoch 706: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0061 - mae: 0.0505 - val_loss: 4.9825e-04 - val_mae: 0.0161\n",
      "Epoch 707/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0514\n",
      "Epoch 707: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 5.0000e-04 - val_mae: 0.0161\n",
      "Epoch 708/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0060 - mae: 0.0512\n",
      "Epoch 708: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 5.0814e-04 - val_mae: 0.0162\n",
      "Epoch 709/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0509\n",
      "Epoch 709: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0062 - mae: 0.0509 - val_loss: 5.0139e-04 - val_mae: 0.0161\n",
      "Epoch 710/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0513\n",
      "Epoch 710: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0062 - mae: 0.0513 - val_loss: 4.9701e-04 - val_mae: 0.0160\n",
      "Epoch 711/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mae: 0.0515\n",
      "Epoch 711: val_loss improved from 0.00050 to 0.00050, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 4.9697e-04 - val_mae: 0.0160\n",
      "Epoch 712/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0510\n",
      "Epoch 712: val_loss did not improve from 0.00050\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0061 - mae: 0.0510 - val_loss: 4.9921e-04 - val_mae: 0.0161\n",
      "Epoch 713/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0062 - mae: 0.0509\n",
      "Epoch 713: val_loss improved from 0.00050 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0062 - mae: 0.0509 - val_loss: 4.9470e-04 - val_mae: 0.0160\n",
      "Epoch 714/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0514\n",
      "Epoch 714: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0061 - mae: 0.0514 - val_loss: 4.9558e-04 - val_mae: 0.0160\n",
      "Epoch 715/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0517\n",
      "Epoch 715: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0061 - mae: 0.0517 - val_loss: 4.9867e-04 - val_mae: 0.0161\n",
      "Epoch 716/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0508\n",
      "Epoch 716: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 5.0428e-04 - val_mae: 0.0162\n",
      "Epoch 717/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0503\n",
      "Epoch 717: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0061 - mae: 0.0503 - val_loss: 4.9464e-04 - val_mae: 0.0160\n",
      "Epoch 718/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0061 - mae: 0.0512\n",
      "Epoch 718: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0061 - mae: 0.0512 - val_loss: 4.9140e-04 - val_mae: 0.0160\n",
      "Epoch 719/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0515\n",
      "Epoch 719: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 4.9546e-04 - val_mae: 0.0160\n",
      "Epoch 720/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0503\n",
      "Epoch 720: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0060 - mae: 0.0503 - val_loss: 4.9749e-04 - val_mae: 0.0160\n",
      "Epoch 721/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0505\n",
      "Epoch 721: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0062 - mae: 0.0505 - val_loss: 4.9025e-04 - val_mae: 0.0159\n",
      "Epoch 722/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0512\n",
      "Epoch 722: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 4.9331e-04 - val_mae: 0.0160\n",
      "Epoch 723/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0061 - mae: 0.0509\n",
      "Epoch 723: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0061 - mae: 0.0509 - val_loss: 4.9857e-04 - val_mae: 0.0161\n",
      "Epoch 724/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0505\n",
      "Epoch 724: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - loss: 0.0061 - mae: 0.0505 - val_loss: 4.9163e-04 - val_mae: 0.0159\n",
      "Epoch 725/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0062 - mae: 0.0520\n",
      "Epoch 725: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0062 - mae: 0.0520 - val_loss: 4.9083e-04 - val_mae: 0.0159\n",
      "Epoch 726/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0062 - mae: 0.0524\n",
      "Epoch 726: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0062 - mae: 0.0524 - val_loss: 4.9437e-04 - val_mae: 0.0160\n",
      "Epoch 727/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0061 - mae: 0.0506\n",
      "Epoch 727: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0061 - mae: 0.0506 - val_loss: 4.9674e-04 - val_mae: 0.0160\n",
      "Epoch 728/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0060 - mae: 0.0500\n",
      "Epoch 728: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0060 - mae: 0.0500 - val_loss: 4.8630e-04 - val_mae: 0.0159\n",
      "Epoch 729/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0061 - mae: 0.0515\n",
      "Epoch 729: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 4.8601e-04 - val_mae: 0.0159\n",
      "Epoch 730/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0062 - mae: 0.0524\n",
      "Epoch 730: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0062 - mae: 0.0524 - val_loss: 4.8728e-04 - val_mae: 0.0159\n",
      "Epoch 731/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0512\n",
      "Epoch 731: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0061 - mae: 0.0512 - val_loss: 4.9354e-04 - val_mae: 0.0160\n",
      "Epoch 732/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0503\n",
      "Epoch 732: val_loss did not improve from 0.00049\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0060 - mae: 0.0503 - val_loss: 4.8887e-04 - val_mae: 0.0159\n",
      "Epoch 733/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 733: val_loss improved from 0.00049 to 0.00049, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.8568e-04 - val_mae: 0.0158\n",
      "Epoch 734/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0060 - mae: 0.0515\n",
      "Epoch 734: val_loss improved from 0.00049 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 4.8488e-04 - val_mae: 0.0158\n",
      "Epoch 735/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0515\n",
      "Epoch 735: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 4.8412e-04 - val_mae: 0.0158\n",
      "Epoch 736/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - mae: 0.0505\n",
      "Epoch 736: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0059 - mae: 0.0505 - val_loss: 4.9105e-04 - val_mae: 0.0159\n",
      "Epoch 737/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0502\n",
      "Epoch 737: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0061 - mae: 0.0502 - val_loss: 4.8636e-04 - val_mae: 0.0158\n",
      "Epoch 738/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0060 - mae: 0.0506\n",
      "Epoch 738: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0060 - mae: 0.0506 - val_loss: 4.8245e-04 - val_mae: 0.0158\n",
      "Epoch 739/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0061 - mae: 0.0518\n",
      "Epoch 739: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0061 - mae: 0.0518 - val_loss: 4.8349e-04 - val_mae: 0.0158\n",
      "Epoch 740/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0061 - mae: 0.0512\n",
      "Epoch 740: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0061 - mae: 0.0512 - val_loss: 4.8753e-04 - val_mae: 0.0159\n",
      "Epoch 741/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0505\n",
      "Epoch 741: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0060 - mae: 0.0505 - val_loss: 4.8197e-04 - val_mae: 0.0158\n",
      "Epoch 742/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 742: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.8317e-04 - val_mae: 0.0158\n",
      "Epoch 743/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 743: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.8264e-04 - val_mae: 0.0158\n",
      "Epoch 744/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 744: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.8217e-04 - val_mae: 0.0158\n",
      "Epoch 745/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0508\n",
      "Epoch 745: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 4.8221e-04 - val_mae: 0.0158\n",
      "Epoch 746/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0510\n",
      "Epoch 746: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0061 - mae: 0.0510 - val_loss: 4.8279e-04 - val_mae: 0.0158\n",
      "Epoch 747/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0061 - mae: 0.0513\n",
      "Epoch 747: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 4.8057e-04 - val_mae: 0.0157\n",
      "Epoch 748/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0513\n",
      "Epoch 748: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 4.8034e-04 - val_mae: 0.0157\n",
      "Epoch 749/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0508\n",
      "Epoch 749: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 4.8193e-04 - val_mae: 0.0158\n",
      "Epoch 750/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 750: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.7847e-04 - val_mae: 0.0157\n",
      "Epoch 751/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0510\n",
      "Epoch 751: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - loss: 0.0060 - mae: 0.0510 - val_loss: 4.7828e-04 - val_mae: 0.0157\n",
      "Epoch 752/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 752: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.7997e-04 - val_mae: 0.0157\n",
      "Epoch 753/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0060 - mae: 0.0508\n",
      "Epoch 753: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 4.7736e-04 - val_mae: 0.0157\n",
      "Epoch 754/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0060 - mae: 0.0513\n",
      "Epoch 754: val_loss improved from 0.00048 to 0.00048, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 4.7693e-04 - val_mae: 0.0157\n",
      "Epoch 755/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0061 - mae: 0.0513\n",
      "Epoch 755: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0061 - mae: 0.0513 - val_loss: 4.7874e-04 - val_mae: 0.0157\n",
      "Epoch 756/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0510\n",
      "Epoch 756: val_loss did not improve from 0.00048\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0061 - mae: 0.0510 - val_loss: 4.7846e-04 - val_mae: 0.0157\n",
      "Epoch 757/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 757: val_loss improved from 0.00048 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.7483e-04 - val_mae: 0.0156\n",
      "Epoch 758/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 758: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.7950e-04 - val_mae: 0.0157\n",
      "Epoch 759/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0500\n",
      "Epoch 759: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0059 - mae: 0.0500 - val_loss: 4.7902e-04 - val_mae: 0.0157\n",
      "Epoch 760/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - mae: 0.0502\n",
      "Epoch 760: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0059 - mae: 0.0502 - val_loss: 4.7308e-04 - val_mae: 0.0156\n",
      "Epoch 761/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0510\n",
      "Epoch 761: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 4.7140e-04 - val_mae: 0.0156\n",
      "Epoch 762/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0515\n",
      "Epoch 762: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0060 - mae: 0.0515 - val_loss: 4.7436e-04 - val_mae: 0.0156\n",
      "Epoch 763/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 763: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.7777e-04 - val_mae: 0.0157\n",
      "Epoch 764/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - mae: 0.0501\n",
      "Epoch 764: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0059 - mae: 0.0501 - val_loss: 4.7573e-04 - val_mae: 0.0156\n",
      "Epoch 765/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0506\n",
      "Epoch 765: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0060 - mae: 0.0506 - val_loss: 4.7467e-04 - val_mae: 0.0156\n",
      "Epoch 766/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0511\n",
      "Epoch 766: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 4.7162e-04 - val_mae: 0.0156\n",
      "Epoch 767/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0510\n",
      "Epoch 767: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 4.7395e-04 - val_mae: 0.0156\n",
      "Epoch 768/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0059 - mae: 0.0503\n",
      "Epoch 768: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0059 - mae: 0.0503 - val_loss: 4.7084e-04 - val_mae: 0.0156\n",
      "Epoch 769/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0503\n",
      "Epoch 769: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0059 - mae: 0.0503 - val_loss: 4.6961e-04 - val_mae: 0.0155\n",
      "Epoch 770/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0059 - mae: 0.0507\n",
      "Epoch 770: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 4.7091e-04 - val_mae: 0.0156\n",
      "Epoch 771/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0061 - mae: 0.0509\n",
      "Epoch 771: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0061 - mae: 0.0509 - val_loss: 4.6835e-04 - val_mae: 0.0155\n",
      "Epoch 772/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0513\n",
      "Epoch 772: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0060 - mae: 0.0513 - val_loss: 4.7001e-04 - val_mae: 0.0155\n",
      "Epoch 773/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0511\n",
      "Epoch 773: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0060 - mae: 0.0511 - val_loss: 4.7151e-04 - val_mae: 0.0156\n",
      "Epoch 774/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0506\n",
      "Epoch 774: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0060 - mae: 0.0506 - val_loss: 4.7079e-04 - val_mae: 0.0156\n",
      "Epoch 775/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0060 - mae: 0.0508\n",
      "Epoch 775: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0060 - mae: 0.0508 - val_loss: 4.6603e-04 - val_mae: 0.0155\n",
      "Epoch 776/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0513\n",
      "Epoch 776: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 4.6828e-04 - val_mae: 0.0155\n",
      "Epoch 777/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0060 - mae: 0.0512\n",
      "Epoch 777: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0060 - mae: 0.0512 - val_loss: 4.6769e-04 - val_mae: 0.0155\n",
      "Epoch 778/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 778: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.6946e-04 - val_mae: 0.0155\n",
      "Epoch 779/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0502\n",
      "Epoch 779: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0059 - mae: 0.0502 - val_loss: 4.6883e-04 - val_mae: 0.0155\n",
      "Epoch 780/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0059 - mae: 0.0504\n",
      "Epoch 780: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0059 - mae: 0.0504 - val_loss: 4.6534e-04 - val_mae: 0.0155\n",
      "Epoch 781/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - mae: 0.0507\n",
      "Epoch 781: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 4.6569e-04 - val_mae: 0.0155\n",
      "Epoch 782/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0507\n",
      "Epoch 782: val_loss did not improve from 0.00047\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 4.6668e-04 - val_mae: 0.0155\n",
      "Epoch 783/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0505\n",
      "Epoch 783: val_loss improved from 0.00047 to 0.00047, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0059 - mae: 0.0505 - val_loss: 4.6515e-04 - val_mae: 0.0155\n",
      "Epoch 784/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 784: val_loss improved from 0.00047 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.6436e-04 - val_mae: 0.0154\n",
      "Epoch 785/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 785: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.6413e-04 - val_mae: 0.0154\n",
      "Epoch 786/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 786: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.6506e-04 - val_mae: 0.0155\n",
      "Epoch 787/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0059 - mae: 0.0504\n",
      "Epoch 787: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0059 - mae: 0.0504 - val_loss: 4.6446e-04 - val_mae: 0.0154\n",
      "Epoch 788/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0504\n",
      "Epoch 788: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0058 - mae: 0.0504 - val_loss: 4.6424e-04 - val_mae: 0.0154\n",
      "Epoch 789/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0060 - mae: 0.0510\n",
      "Epoch 789: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 99ms/step - loss: 0.0060 - mae: 0.0510 - val_loss: 4.6095e-04 - val_mae: 0.0154\n",
      "Epoch 790/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 790: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.6473e-04 - val_mae: 0.0155\n",
      "Epoch 791/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0058 - mae: 0.0500\n",
      "Epoch 791: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0058 - mae: 0.0500 - val_loss: 4.6467e-04 - val_mae: 0.0155\n",
      "Epoch 792/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0501\n",
      "Epoch 792: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0059 - mae: 0.0501 - val_loss: 4.6008e-04 - val_mae: 0.0154\n",
      "Epoch 793/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0507\n",
      "Epoch 793: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0058 - mae: 0.0507 - val_loss: 4.6279e-04 - val_mae: 0.0154\n",
      "Epoch 794/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 794: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.6129e-04 - val_mae: 0.0154\n",
      "Epoch 795/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0505\n",
      "Epoch 795: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0059 - mae: 0.0505 - val_loss: 4.5963e-04 - val_mae: 0.0154\n",
      "Epoch 796/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 796: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.5738e-04 - val_mae: 0.0153\n",
      "Epoch 797/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0510\n",
      "Epoch 797: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 4.5776e-04 - val_mae: 0.0153\n",
      "Epoch 798/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 798: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.5947e-04 - val_mae: 0.0154\n",
      "Epoch 799/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0060 - mae: 0.0507\n",
      "Epoch 799: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0060 - mae: 0.0507 - val_loss: 4.5717e-04 - val_mae: 0.0153\n",
      "Epoch 800/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0509\n",
      "Epoch 800: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0059 - mae: 0.0509 - val_loss: 4.6099e-04 - val_mae: 0.0154\n",
      "Epoch 801/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0500\n",
      "Epoch 801: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0500 - val_loss: 4.6390e-04 - val_mae: 0.0154\n",
      "Epoch 802/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0501\n",
      "Epoch 802: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0059 - mae: 0.0501 - val_loss: 4.5583e-04 - val_mae: 0.0153\n",
      "Epoch 803/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0512\n",
      "Epoch 803: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0059 - mae: 0.0512 - val_loss: 4.5590e-04 - val_mae: 0.0153\n",
      "Epoch 804/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0510\n",
      "Epoch 804: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 4.5652e-04 - val_mae: 0.0153\n",
      "Epoch 805/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0508\n",
      "Epoch 805: val_loss improved from 0.00046 to 0.00046, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0059 - mae: 0.0508 - val_loss: 4.5507e-04 - val_mae: 0.0153\n",
      "Epoch 806/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0506\n",
      "Epoch 806: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0506 - val_loss: 4.5793e-04 - val_mae: 0.0153\n",
      "Epoch 807/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0499\n",
      "Epoch 807: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0058 - mae: 0.0499 - val_loss: 4.6092e-04 - val_mae: 0.0154\n",
      "Epoch 808/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0494\n",
      "Epoch 808: val_loss did not improve from 0.00046\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0057 - mae: 0.0494 - val_loss: 4.5720e-04 - val_mae: 0.0153\n",
      "Epoch 809/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0502\n",
      "Epoch 809: val_loss improved from 0.00046 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0059 - mae: 0.0502 - val_loss: 4.5077e-04 - val_mae: 0.0152\n",
      "Epoch 810/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0512\n",
      "Epoch 810: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0058 - mae: 0.0512 - val_loss: 4.5412e-04 - val_mae: 0.0153\n",
      "Epoch 811/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0504\n",
      "Epoch 811: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0058 - mae: 0.0504 - val_loss: 4.6064e-04 - val_mae: 0.0154\n",
      "Epoch 812/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0496\n",
      "Epoch 812: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0058 - mae: 0.0496 - val_loss: 4.5236e-04 - val_mae: 0.0152\n",
      "Epoch 813/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0509\n",
      "Epoch 813: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0059 - mae: 0.0509 - val_loss: 4.5206e-04 - val_mae: 0.0152\n",
      "Epoch 814/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0516\n",
      "Epoch 814: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0516 - val_loss: 4.5528e-04 - val_mae: 0.0153\n",
      "Epoch 815/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - mae: 0.0502\n",
      "Epoch 815: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0058 - mae: 0.0502 - val_loss: 4.6319e-04 - val_mae: 0.0154\n",
      "Epoch 816/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0498\n",
      "Epoch 816: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0059 - mae: 0.0498 - val_loss: 4.4965e-04 - val_mae: 0.0152\n",
      "Epoch 817/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 817: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.5338e-04 - val_mae: 0.0153\n",
      "Epoch 818/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0499\n",
      "Epoch 818: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0058 - mae: 0.0499 - val_loss: 4.5818e-04 - val_mae: 0.0154\n",
      "Epoch 819/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0497\n",
      "Epoch 819: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0059 - mae: 0.0497 - val_loss: 4.4924e-04 - val_mae: 0.0152\n",
      "Epoch 820/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0511\n",
      "Epoch 820: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0059 - mae: 0.0511 - val_loss: 4.5240e-04 - val_mae: 0.0152\n",
      "Epoch 821/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0512\n",
      "Epoch 821: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0512 - val_loss: 4.5772e-04 - val_mae: 0.0153\n",
      "Epoch 822/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0058 - mae: 0.0500\n",
      "Epoch 822: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0058 - mae: 0.0500 - val_loss: 4.5854e-04 - val_mae: 0.0154\n",
      "Epoch 823/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0059 - mae: 0.0502\n",
      "Epoch 823: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0059 - mae: 0.0502 - val_loss: 4.4698e-04 - val_mae: 0.0151\n",
      "Epoch 824/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0512\n",
      "Epoch 824: val_loss improved from 0.00045 to 0.00045, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0058 - mae: 0.0512 - val_loss: 4.4512e-04 - val_mae: 0.0151\n",
      "Epoch 825/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 825: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.6173e-04 - val_mae: 0.0154\n",
      "Epoch 826/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0059 - mae: 0.0492\n",
      "Epoch 826: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0059 - mae: 0.0492 - val_loss: 4.4934e-04 - val_mae: 0.0152\n",
      "Epoch 827/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0501\n",
      "Epoch 827: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0058 - mae: 0.0501 - val_loss: 4.4805e-04 - val_mae: 0.0152\n",
      "Epoch 828/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0060 - mae: 0.0521\n",
      "Epoch 828: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0060 - mae: 0.0521 - val_loss: 4.5260e-04 - val_mae: 0.0152\n",
      "Epoch 829/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0513\n",
      "Epoch 829: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0059 - mae: 0.0513 - val_loss: 4.6339e-04 - val_mae: 0.0155\n",
      "Epoch 830/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0058 - mae: 0.0495\n",
      "Epoch 830: val_loss did not improve from 0.00045\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0058 - mae: 0.0495 - val_loss: 4.5585e-04 - val_mae: 0.0153\n",
      "Epoch 831/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0498\n",
      "Epoch 831: val_loss improved from 0.00045 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - loss: 0.0058 - mae: 0.0498 - val_loss: 4.4245e-04 - val_mae: 0.0151\n",
      "Epoch 832/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0517\n",
      "Epoch 832: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0058 - mae: 0.0517 - val_loss: 4.4146e-04 - val_mae: 0.0151\n",
      "Epoch 833/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0516\n",
      "Epoch 833: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0059 - mae: 0.0516 - val_loss: 4.5396e-04 - val_mae: 0.0153\n",
      "Epoch 834/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0498\n",
      "Epoch 834: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0059 - mae: 0.0498 - val_loss: 4.4660e-04 - val_mae: 0.0151\n",
      "Epoch 835/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0498\n",
      "Epoch 835: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0056 - mae: 0.0498 - val_loss: 4.4570e-04 - val_mae: 0.0151\n",
      "Epoch 836/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0510\n",
      "Epoch 836: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0058 - mae: 0.0510 - val_loss: 4.4941e-04 - val_mae: 0.0152\n",
      "Epoch 837/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0059 - mae: 0.0506\n",
      "Epoch 837: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0059 - mae: 0.0506 - val_loss: 4.4834e-04 - val_mae: 0.0152\n",
      "Epoch 838/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0501\n",
      "Epoch 838: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0058 - mae: 0.0501 - val_loss: 4.4452e-04 - val_mae: 0.0151\n",
      "Epoch 839/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0504\n",
      "Epoch 839: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0058 - mae: 0.0504 - val_loss: 4.4187e-04 - val_mae: 0.0150\n",
      "Epoch 840/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0057 - mae: 0.0504\n",
      "Epoch 840: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0057 - mae: 0.0504 - val_loss: 4.4569e-04 - val_mae: 0.0151\n",
      "Epoch 841/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0059 - mae: 0.0502\n",
      "Epoch 841: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0059 - mae: 0.0502 - val_loss: 4.4157e-04 - val_mae: 0.0150\n",
      "Epoch 842/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0508\n",
      "Epoch 842: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0058 - mae: 0.0508 - val_loss: 4.4408e-04 - val_mae: 0.0151\n",
      "Epoch 843/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0510\n",
      "Epoch 843: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0059 - mae: 0.0510 - val_loss: 4.4686e-04 - val_mae: 0.0151\n",
      "Epoch 844/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0499\n",
      "Epoch 844: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0057 - mae: 0.0499 - val_loss: 4.5337e-04 - val_mae: 0.0153\n",
      "Epoch 845/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 0.0058 - mae: 0.0496\n",
      "Epoch 845: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - loss: 0.0058 - mae: 0.0496 - val_loss: 4.4012e-04 - val_mae: 0.0150\n",
      "Epoch 846/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 846: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.3984e-04 - val_mae: 0.0150\n",
      "Epoch 847/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0058 - mae: 0.0507\n",
      "Epoch 847: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0058 - mae: 0.0507 - val_loss: 4.4613e-04 - val_mae: 0.0151\n",
      "Epoch 848/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0495\n",
      "Epoch 848: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0057 - mae: 0.0495 - val_loss: 4.4592e-04 - val_mae: 0.0151\n",
      "Epoch 849/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0058 - mae: 0.0500\n",
      "Epoch 849: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - loss: 0.0058 - mae: 0.0500 - val_loss: 4.3977e-04 - val_mae: 0.0150\n",
      "Epoch 850/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 850: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.4295e-04 - val_mae: 0.0151\n",
      "Epoch 851/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0502\n",
      "Epoch 851: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0058 - mae: 0.0502 - val_loss: 4.4306e-04 - val_mae: 0.0151\n",
      "Epoch 852/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0503\n",
      "Epoch 852: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0503 - val_loss: 4.4054e-04 - val_mae: 0.0150\n",
      "Epoch 853/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0506\n",
      "Epoch 853: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - loss: 0.0058 - mae: 0.0506 - val_loss: 4.3838e-04 - val_mae: 0.0150\n",
      "Epoch 854/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0508\n",
      "Epoch 854: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0058 - mae: 0.0508 - val_loss: 4.4108e-04 - val_mae: 0.0150\n",
      "Epoch 855/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0504\n",
      "Epoch 855: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0058 - mae: 0.0504 - val_loss: 4.3988e-04 - val_mae: 0.0150\n",
      "Epoch 856/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - mae: 0.0503\n",
      "Epoch 856: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0058 - mae: 0.0503 - val_loss: 4.3841e-04 - val_mae: 0.0150\n",
      "Epoch 857/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mae: 0.0502\n",
      "Epoch 857: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0057 - mae: 0.0502 - val_loss: 4.4265e-04 - val_mae: 0.0151\n",
      "Epoch 858/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0499\n",
      "Epoch 858: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0057 - mae: 0.0499 - val_loss: 4.3758e-04 - val_mae: 0.0150\n",
      "Epoch 859/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0505\n",
      "Epoch 859: val_loss improved from 0.00044 to 0.00044, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0058 - mae: 0.0505 - val_loss: 4.3542e-04 - val_mae: 0.0149\n",
      "Epoch 860/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0058 - mae: 0.0509\n",
      "Epoch 860: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0058 - mae: 0.0509 - val_loss: 4.3700e-04 - val_mae: 0.0150\n",
      "Epoch 861/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0502\n",
      "Epoch 861: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0057 - mae: 0.0502 - val_loss: 4.4632e-04 - val_mae: 0.0151\n",
      "Epoch 862/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0496\n",
      "Epoch 862: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0057 - mae: 0.0496 - val_loss: 4.4013e-04 - val_mae: 0.0150\n",
      "Epoch 863/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0505\n",
      "Epoch 863: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0505 - val_loss: 4.3582e-04 - val_mae: 0.0149\n",
      "Epoch 864/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0058 - mae: 0.0511\n",
      "Epoch 864: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0058 - mae: 0.0511 - val_loss: 4.3673e-04 - val_mae: 0.0150\n",
      "Epoch 865/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0507\n",
      "Epoch 865: val_loss did not improve from 0.00044\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0058 - mae: 0.0507 - val_loss: 4.3760e-04 - val_mae: 0.0150\n",
      "Epoch 866/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0501\n",
      "Epoch 866: val_loss improved from 0.00044 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0058 - mae: 0.0501 - val_loss: 4.3446e-04 - val_mae: 0.0149\n",
      "Epoch 867/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0504\n",
      "Epoch 867: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0057 - mae: 0.0504 - val_loss: 4.3493e-04 - val_mae: 0.0149\n",
      "Epoch 868/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0505\n",
      "Epoch 868: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0058 - mae: 0.0505 - val_loss: 4.4048e-04 - val_mae: 0.0150\n",
      "Epoch 869/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0497\n",
      "Epoch 869: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0497 - val_loss: 4.3701e-04 - val_mae: 0.0150\n",
      "Epoch 870/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0502\n",
      "Epoch 870: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0057 - mae: 0.0502 - val_loss: 4.3437e-04 - val_mae: 0.0149\n",
      "Epoch 871/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0506\n",
      "Epoch 871: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0058 - mae: 0.0506 - val_loss: 4.3396e-04 - val_mae: 0.0149\n",
      "Epoch 872/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0504\n",
      "Epoch 872: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0504 - val_loss: 4.3580e-04 - val_mae: 0.0149\n",
      "Epoch 873/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0500\n",
      "Epoch 873: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 111ms/step - loss: 0.0057 - mae: 0.0500 - val_loss: 4.3160e-04 - val_mae: 0.0149\n",
      "Epoch 874/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0058 - mae: 0.0506\n",
      "Epoch 874: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0058 - mae: 0.0506 - val_loss: 4.3286e-04 - val_mae: 0.0149\n",
      "Epoch 875/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0506\n",
      "Epoch 875: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0058 - mae: 0.0506 - val_loss: 4.3486e-04 - val_mae: 0.0149\n",
      "Epoch 876/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0506\n",
      "Epoch 876: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0057 - mae: 0.0506 - val_loss: 4.3942e-04 - val_mae: 0.0150\n",
      "Epoch 877/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0059 - mae: 0.0507\n",
      "Epoch 877: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0059 - mae: 0.0507 - val_loss: 4.3050e-04 - val_mae: 0.0149\n",
      "Epoch 878/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0058 - mae: 0.0513\n",
      "Epoch 878: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0058 - mae: 0.0513 - val_loss: 4.2931e-04 - val_mae: 0.0148\n",
      "Epoch 879/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 879: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.3497e-04 - val_mae: 0.0149\n",
      "Epoch 880/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0498\n",
      "Epoch 880: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0058 - mae: 0.0498 - val_loss: 4.3256e-04 - val_mae: 0.0149\n",
      "Epoch 881/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0501\n",
      "Epoch 881: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0057 - mae: 0.0501 - val_loss: 4.2915e-04 - val_mae: 0.0148\n",
      "Epoch 882/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0507\n",
      "Epoch 882: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0057 - mae: 0.0507 - val_loss: 4.3560e-04 - val_mae: 0.0149\n",
      "Epoch 883/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0502\n",
      "Epoch 883: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0058 - mae: 0.0502 - val_loss: 4.3355e-04 - val_mae: 0.0149\n",
      "Epoch 884/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0503\n",
      "Epoch 884: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 4.3107e-04 - val_mae: 0.0149\n",
      "Epoch 885/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0057 - mae: 0.0508\n",
      "Epoch 885: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0057 - mae: 0.0508 - val_loss: 4.3296e-04 - val_mae: 0.0149\n",
      "Epoch 886/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0500\n",
      "Epoch 886: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0057 - mae: 0.0500 - val_loss: 4.3413e-04 - val_mae: 0.0149\n",
      "Epoch 887/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0492\n",
      "Epoch 887: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 4.3061e-04 - val_mae: 0.0148\n",
      "Epoch 888/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0496\n",
      "Epoch 888: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0056 - mae: 0.0496 - val_loss: 4.2837e-04 - val_mae: 0.0148\n",
      "Epoch 889/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - mae: 0.0500\n",
      "Epoch 889: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0500 - val_loss: 4.2973e-04 - val_mae: 0.0148\n",
      "Epoch 890/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0503\n",
      "Epoch 890: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 4.2984e-04 - val_mae: 0.0148\n",
      "Epoch 891/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0500\n",
      "Epoch 891: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - loss: 0.0056 - mae: 0.0500 - val_loss: 4.3162e-04 - val_mae: 0.0149\n",
      "Epoch 892/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 892: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.3421e-04 - val_mae: 0.0149\n",
      "Epoch 893/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0058 - mae: 0.0499\n",
      "Epoch 893: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0058 - mae: 0.0499 - val_loss: 4.2628e-04 - val_mae: 0.0148\n",
      "Epoch 894/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0057 - mae: 0.0510\n",
      "Epoch 894: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0057 - mae: 0.0510 - val_loss: 4.2652e-04 - val_mae: 0.0148\n",
      "Epoch 895/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0506\n",
      "Epoch 895: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0056 - mae: 0.0506 - val_loss: 4.3506e-04 - val_mae: 0.0149\n",
      "Epoch 896/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0491\n",
      "Epoch 896: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0491 - val_loss: 4.3632e-04 - val_mae: 0.0150\n",
      "Epoch 897/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0492\n",
      "Epoch 897: val_loss improved from 0.00043 to 0.00043, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 4.2518e-04 - val_mae: 0.0148\n",
      "Epoch 898/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 0.0056 - mae: 0.0510\n",
      "Epoch 898: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - loss: 0.0056 - mae: 0.0510 - val_loss: 4.2542e-04 - val_mae: 0.0148\n",
      "Epoch 899/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0503\n",
      "Epoch 899: val_loss did not improve from 0.00043\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0503 - val_loss: 4.3896e-04 - val_mae: 0.0150\n",
      "Epoch 900/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0057 - mae: 0.0489\n",
      "Epoch 900: val_loss improved from 0.00043 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 118ms/step - loss: 0.0057 - mae: 0.0489 - val_loss: 4.2442e-04 - val_mae: 0.0147\n",
      "Epoch 901/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0502\n",
      "Epoch 901: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0055 - mae: 0.0502 - val_loss: 4.2810e-04 - val_mae: 0.0148\n",
      "Epoch 902/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0500\n",
      "Epoch 902: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0057 - mae: 0.0500 - val_loss: 4.2981e-04 - val_mae: 0.0148\n",
      "Epoch 903/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0498\n",
      "Epoch 903: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0057 - mae: 0.0498 - val_loss: 4.2549e-04 - val_mae: 0.0148\n",
      "Epoch 904/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - mae: 0.0506\n",
      "Epoch 904: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0506 - val_loss: 4.2490e-04 - val_mae: 0.0147\n",
      "Epoch 905/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0502\n",
      "Epoch 905: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0056 - mae: 0.0502 - val_loss: 4.3163e-04 - val_mae: 0.0149\n",
      "Epoch 906/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0496\n",
      "Epoch 906: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0057 - mae: 0.0496 - val_loss: 4.2173e-04 - val_mae: 0.0147\n",
      "Epoch 907/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0506\n",
      "Epoch 907: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0057 - mae: 0.0506 - val_loss: 4.2081e-04 - val_mae: 0.0147\n",
      "Epoch 908/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0510\n",
      "Epoch 908: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0057 - mae: 0.0510 - val_loss: 4.2793e-04 - val_mae: 0.0148\n",
      "Epoch 909/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0057 - mae: 0.0501\n",
      "Epoch 909: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0057 - mae: 0.0501 - val_loss: 4.2593e-04 - val_mae: 0.0148\n",
      "Epoch 910/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0502\n",
      "Epoch 910: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0057 - mae: 0.0502 - val_loss: 4.2444e-04 - val_mae: 0.0147\n",
      "Epoch 911/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0498\n",
      "Epoch 911: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 4.2648e-04 - val_mae: 0.0148\n",
      "Epoch 912/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0058 - mae: 0.0501\n",
      "Epoch 912: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0058 - mae: 0.0501 - val_loss: 4.1960e-04 - val_mae: 0.0147\n",
      "Epoch 913/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0509\n",
      "Epoch 913: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0509 - val_loss: 4.2092e-04 - val_mae: 0.0147\n",
      "Epoch 914/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0503\n",
      "Epoch 914: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 4.2554e-04 - val_mae: 0.0148\n",
      "Epoch 915/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0498\n",
      "Epoch 915: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0498 - val_loss: 4.2050e-04 - val_mae: 0.0147\n",
      "Epoch 916/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0502\n",
      "Epoch 916: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0056 - mae: 0.0502 - val_loss: 4.2370e-04 - val_mae: 0.0147\n",
      "Epoch 917/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0501\n",
      "Epoch 917: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0056 - mae: 0.0501 - val_loss: 4.3051e-04 - val_mae: 0.0149\n",
      "Epoch 918/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0057 - mae: 0.0497\n",
      "Epoch 918: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0057 - mae: 0.0497 - val_loss: 4.2338e-04 - val_mae: 0.0147\n",
      "Epoch 919/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0505\n",
      "Epoch 919: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0056 - mae: 0.0505 - val_loss: 4.2017e-04 - val_mae: 0.0147\n",
      "Epoch 920/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0508\n",
      "Epoch 920: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0057 - mae: 0.0508 - val_loss: 4.2219e-04 - val_mae: 0.0147\n",
      "Epoch 921/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 921: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.2444e-04 - val_mae: 0.0147\n",
      "Epoch 922/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0498\n",
      "Epoch 922: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0057 - mae: 0.0498 - val_loss: 4.1657e-04 - val_mae: 0.0146\n",
      "Epoch 923/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0505\n",
      "Epoch 923: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0055 - mae: 0.0505 - val_loss: 4.2554e-04 - val_mae: 0.0148\n",
      "Epoch 924/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0495\n",
      "Epoch 924: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - loss: 0.0057 - mae: 0.0495 - val_loss: 4.2187e-04 - val_mae: 0.0147\n",
      "Epoch 925/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 925: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.1782e-04 - val_mae: 0.0146\n",
      "Epoch 926/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0503\n",
      "Epoch 926: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0503 - val_loss: 4.2661e-04 - val_mae: 0.0148\n",
      "Epoch 927/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0489\n",
      "Epoch 927: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0055 - mae: 0.0489 - val_loss: 4.2658e-04 - val_mae: 0.0148\n",
      "Epoch 928/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - mae: 0.0495\n",
      "Epoch 928: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - loss: 0.0056 - mae: 0.0495 - val_loss: 4.1651e-04 - val_mae: 0.0146\n",
      "Epoch 929/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0511\n",
      "Epoch 929: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0511 - val_loss: 4.1798e-04 - val_mae: 0.0146\n",
      "Epoch 930/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0503\n",
      "Epoch 930: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 4.2974e-04 - val_mae: 0.0149\n",
      "Epoch 931/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 0.0056 - mae: 0.0490\n",
      "Epoch 931: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0056 - mae: 0.0490 - val_loss: 4.1715e-04 - val_mae: 0.0146\n",
      "Epoch 932/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 932: val_loss improved from 0.00042 to 0.00042, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.1571e-04 - val_mae: 0.0146\n",
      "Epoch 933/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0505\n",
      "Epoch 933: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0056 - mae: 0.0505 - val_loss: 4.2008e-04 - val_mae: 0.0147\n",
      "Epoch 934/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0496\n",
      "Epoch 934: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0056 - mae: 0.0496 - val_loss: 4.1729e-04 - val_mae: 0.0146\n",
      "Epoch 935/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0495\n",
      "Epoch 935: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0055 - mae: 0.0495 - val_loss: 4.1608e-04 - val_mae: 0.0146\n",
      "Epoch 936/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0498\n",
      "Epoch 936: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 4.1791e-04 - val_mae: 0.0146\n",
      "Epoch 937/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 937: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.1857e-04 - val_mae: 0.0146\n",
      "Epoch 938/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0496\n",
      "Epoch 938: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0055 - mae: 0.0496 - val_loss: 4.1987e-04 - val_mae: 0.0147\n",
      "Epoch 939/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0497\n",
      "Epoch 939: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - loss: 0.0056 - mae: 0.0497 - val_loss: 4.1918e-04 - val_mae: 0.0146\n",
      "Epoch 940/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 0.0056 - mae: 0.0503\n",
      "Epoch 940: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0056 - mae: 0.0503 - val_loss: 4.1611e-04 - val_mae: 0.0146\n",
      "Epoch 941/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0511\n",
      "Epoch 941: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0057 - mae: 0.0511 - val_loss: 4.1721e-04 - val_mae: 0.0146\n",
      "Epoch 942/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0057 - mae: 0.0503\n",
      "Epoch 942: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 4.2004e-04 - val_mae: 0.0147\n",
      "Epoch 943/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0491\n",
      "Epoch 943: val_loss did not improve from 0.00042\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0056 - mae: 0.0491 - val_loss: 4.1751e-04 - val_mae: 0.0146\n",
      "Epoch 944/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0494\n",
      "Epoch 944: val_loss improved from 0.00042 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - loss: 0.0055 - mae: 0.0494 - val_loss: 4.1363e-04 - val_mae: 0.0145\n",
      "Epoch 945/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0501\n",
      "Epoch 945: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0056 - mae: 0.0501 - val_loss: 4.1312e-04 - val_mae: 0.0145\n",
      "Epoch 946/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0504\n",
      "Epoch 946: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0055 - mae: 0.0504 - val_loss: 4.2132e-04 - val_mae: 0.0147\n",
      "Epoch 947/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - mae: 0.0492\n",
      "Epoch 947: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 4.2019e-04 - val_mae: 0.0147\n",
      "Epoch 948/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0492\n",
      "Epoch 948: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - loss: 0.0055 - mae: 0.0492 - val_loss: 4.1265e-04 - val_mae: 0.0145\n",
      "Epoch 949/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0057 - mae: 0.0508\n",
      "Epoch 949: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - loss: 0.0057 - mae: 0.0508 - val_loss: 4.1031e-04 - val_mae: 0.0145\n",
      "Epoch 950/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0056 - mae: 0.0507\n",
      "Epoch 950: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0056 - mae: 0.0507 - val_loss: 4.1883e-04 - val_mae: 0.0146\n",
      "Epoch 951/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0492\n",
      "Epoch 951: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 4.1882e-04 - val_mae: 0.0146\n",
      "Epoch 952/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0492\n",
      "Epoch 952: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0055 - mae: 0.0492 - val_loss: 4.1061e-04 - val_mae: 0.0145\n",
      "Epoch 953/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0507\n",
      "Epoch 953: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0055 - mae: 0.0507 - val_loss: 4.1862e-04 - val_mae: 0.0146\n",
      "Epoch 954/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0055 - mae: 0.0495\n",
      "Epoch 954: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0055 - mae: 0.0495 - val_loss: 4.2913e-04 - val_mae: 0.0149\n",
      "Epoch 955/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0489\n",
      "Epoch 955: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0056 - mae: 0.0489 - val_loss: 4.1321e-04 - val_mae: 0.0145\n",
      "Epoch 956/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0505\n",
      "Epoch 956: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0055 - mae: 0.0505 - val_loss: 4.1064e-04 - val_mae: 0.0145\n",
      "Epoch 957/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0506\n",
      "Epoch 957: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0506 - val_loss: 4.1956e-04 - val_mae: 0.0147\n",
      "Epoch 958/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0492\n",
      "Epoch 958: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0055 - mae: 0.0492 - val_loss: 4.1348e-04 - val_mae: 0.0145\n",
      "Epoch 959/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0499\n",
      "Epoch 959: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0056 - mae: 0.0499 - val_loss: 4.1204e-04 - val_mae: 0.0145\n",
      "Epoch 960/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0509\n",
      "Epoch 960: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0055 - mae: 0.0509 - val_loss: 4.2076e-04 - val_mae: 0.0147\n",
      "Epoch 961/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - mae: 0.0493\n",
      "Epoch 961: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - loss: 0.0056 - mae: 0.0493 - val_loss: 4.2268e-04 - val_mae: 0.0147\n",
      "Epoch 962/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0488\n",
      "Epoch 962: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 89ms/step - loss: 0.0055 - mae: 0.0488 - val_loss: 4.0843e-04 - val_mae: 0.0145\n",
      "Epoch 963/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 0.0056 - mae: 0.0508\n",
      "Epoch 963: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0056 - mae: 0.0508 - val_loss: 4.0716e-04 - val_mae: 0.0144\n",
      "Epoch 964/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0056 - mae: 0.0510\n",
      "Epoch 964: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0510 - val_loss: 4.1406e-04 - val_mae: 0.0146\n",
      "Epoch 965/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0495\n",
      "Epoch 965: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0056 - mae: 0.0495 - val_loss: 4.1180e-04 - val_mae: 0.0145\n",
      "Epoch 966/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0497\n",
      "Epoch 966: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0056 - mae: 0.0497 - val_loss: 4.0712e-04 - val_mae: 0.0144\n",
      "Epoch 967/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0507\n",
      "Epoch 967: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0055 - mae: 0.0507 - val_loss: 4.1451e-04 - val_mae: 0.0146\n",
      "Epoch 968/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0495\n",
      "Epoch 968: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0055 - mae: 0.0495 - val_loss: 4.1747e-04 - val_mae: 0.0146\n",
      "Epoch 969/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0054 - mae: 0.0487\n",
      "Epoch 969: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0054 - mae: 0.0487 - val_loss: 4.1077e-04 - val_mae: 0.0145\n",
      "Epoch 970/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 0.0055 - mae: 0.0498\n",
      "Epoch 970: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 4.0862e-04 - val_mae: 0.0145\n",
      "Epoch 971/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0505\n",
      "Epoch 971: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0056 - mae: 0.0505 - val_loss: 4.1317e-04 - val_mae: 0.0145\n",
      "Epoch 972/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - loss: 0.0055 - mae: 0.0498\n",
      "Epoch 972: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 4.1712e-04 - val_mae: 0.0146\n",
      "Epoch 973/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0057 - mae: 0.0496\n",
      "Epoch 973: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - loss: 0.0057 - mae: 0.0496 - val_loss: 4.0688e-04 - val_mae: 0.0144\n",
      "Epoch 974/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0055 - mae: 0.0505\n",
      "Epoch 974: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - loss: 0.0055 - mae: 0.0505 - val_loss: 4.0638e-04 - val_mae: 0.0144\n",
      "Epoch 975/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 0.0055 - mae: 0.0501\n",
      "Epoch 975: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - loss: 0.0055 - mae: 0.0501 - val_loss: 4.2124e-04 - val_mae: 0.0147\n",
      "Epoch 976/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0054 - mae: 0.0484\n",
      "Epoch 976: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - loss: 0.0054 - mae: 0.0484 - val_loss: 4.0836e-04 - val_mae: 0.0145\n",
      "Epoch 977/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0056 - mae: 0.0498\n",
      "Epoch 977: val_loss improved from 0.00041 to 0.00041, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - loss: 0.0056 - mae: 0.0498 - val_loss: 4.0502e-04 - val_mae: 0.0144\n",
      "Epoch 978/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0508\n",
      "Epoch 978: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - loss: 0.0055 - mae: 0.0508 - val_loss: 4.1389e-04 - val_mae: 0.0146\n",
      "Epoch 979/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0056 - mae: 0.0498\n",
      "Epoch 979: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0056 - mae: 0.0498 - val_loss: 4.1780e-04 - val_mae: 0.0147\n",
      "Epoch 980/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0493\n",
      "Epoch 980: val_loss did not improve from 0.00041\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - loss: 0.0055 - mae: 0.0493 - val_loss: 4.0520e-04 - val_mae: 0.0144\n",
      "Epoch 981/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0508\n",
      "Epoch 981: val_loss improved from 0.00041 to 0.00040, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - loss: 0.0056 - mae: 0.0508 - val_loss: 4.0348e-04 - val_mae: 0.0144\n",
      "Epoch 982/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 0.0056 - mae: 0.0508\n",
      "Epoch 982: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - loss: 0.0056 - mae: 0.0508 - val_loss: 4.1106e-04 - val_mae: 0.0145\n",
      "Epoch 983/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0491\n",
      "Epoch 983: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0055 - mae: 0.0491 - val_loss: 4.1247e-04 - val_mae: 0.0145\n",
      "Epoch 984/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0492\n",
      "Epoch 984: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - loss: 0.0056 - mae: 0.0492 - val_loss: 4.0400e-04 - val_mae: 0.0144\n",
      "Epoch 985/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0055 - mae: 0.0509\n",
      "Epoch 985: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0055 - mae: 0.0509 - val_loss: 4.0642e-04 - val_mae: 0.0144\n",
      "Epoch 986/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 0.0054 - mae: 0.0498\n",
      "Epoch 986: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - loss: 0.0054 - mae: 0.0498 - val_loss: 4.2308e-04 - val_mae: 0.0148\n",
      "Epoch 987/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0484\n",
      "Epoch 987: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0055 - mae: 0.0484 - val_loss: 4.0761e-04 - val_mae: 0.0144\n",
      "Epoch 988/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0498\n",
      "Epoch 988: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0055 - mae: 0.0498 - val_loss: 4.0402e-04 - val_mae: 0.0144\n",
      "Epoch 989/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0513\n",
      "Epoch 989: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0513 - val_loss: 4.1053e-04 - val_mae: 0.0145\n",
      "Epoch 990/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0492\n",
      "Epoch 990: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - loss: 0.0055 - mae: 0.0492 - val_loss: 4.2358e-04 - val_mae: 0.0148\n",
      "Epoch 991/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0490\n",
      "Epoch 991: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - loss: 0.0056 - mae: 0.0490 - val_loss: 4.0401e-04 - val_mae: 0.0144\n",
      "Epoch 992/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0056 - mae: 0.0513\n",
      "Epoch 992: val_loss improved from 0.00040 to 0.00040, saving model to nev_test.keras\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - loss: 0.0056 - mae: 0.0513 - val_loss: 4.0246e-04 - val_mae: 0.0144\n",
      "Epoch 993/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 0.0055 - mae: 0.0507\n",
      "Epoch 993: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - loss: 0.0055 - mae: 0.0507 - val_loss: 4.2682e-04 - val_mae: 0.0149\n",
      "Epoch 994/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0054 - mae: 0.0479\n",
      "Epoch 994: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0054 - mae: 0.0479 - val_loss: 4.0822e-04 - val_mae: 0.0145\n",
      "Epoch 995/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0494\n",
      "Epoch 995: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - loss: 0.0055 - mae: 0.0494 - val_loss: 4.0406e-04 - val_mae: 0.0145\n",
      "Epoch 996/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - loss: 0.0055 - mae: 0.0517\n",
      "Epoch 996: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0055 - mae: 0.0517 - val_loss: 4.0560e-04 - val_mae: 0.0144\n",
      "Epoch 997/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0497\n",
      "Epoch 997: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - loss: 0.0055 - mae: 0.0497 - val_loss: 4.3097e-04 - val_mae: 0.0150\n",
      "Epoch 998/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - loss: 0.0055 - mae: 0.0478\n",
      "Epoch 998: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - loss: 0.0055 - mae: 0.0478 - val_loss: 4.0293e-04 - val_mae: 0.0144\n",
      "Epoch 999/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - loss: 0.0056 - mae: 0.0504\n",
      "Epoch 999: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - loss: 0.0056 - mae: 0.0504 - val_loss: 4.0450e-04 - val_mae: 0.0145\n",
      "Epoch 1000/1000\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 0.0055 - mae: 0.0519\n",
      "Epoch 1000: val_loss did not improve from 0.00040\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - loss: 0.0055 - mae: 0.0519 - val_loss: 4.1372e-04 - val_mae: 0.0146\n",
      "Restoring model weights from the end of the best epoch: 992.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_8\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_8\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,360</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">21</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_19 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │         \u001b[38;5;34m1,360\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m21\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,145</span> (16.20 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,145\u001b[0m (16.20 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,381</span> (5.39 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,381\u001b[0m (5.39 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,764</span> (10.80 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,764\u001b[0m (10.80 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 1000\n",
    "\n",
    "batch_size = len(X_train)\n",
    "val_batch_size = len(X_valid)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, verbose=1)\n",
    "\n",
    "file_name = 'nev_test.keras'\n",
    "checkpoint = ModelCheckpoint(file_name, monitor='val_loss', save_best_only=True, verbose=1)\n",
    "callbacks = [early_stopping, checkpoint]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    validation_batch_size=val_batch_size,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e6272de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Loss:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 0.0015 - mae: 0.0306\n",
      "Loss: [0.0015111059183254838, 0.030567094683647156]\n",
      "\n",
      "Generating output predictions with model:\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "\n",
      "Central Frequency Percentage 15cm: 99.68689656677176\n",
      "\n",
      "Central Frequency Percentage 5cm: 78.69805701318961\n",
      "\n",
      "Central Frequency Percentage 1cm: 23.69876613246348\n",
      "Mean Squared Error: 0.0015111058814669305\n",
      "Root Mean Squared Error: 0.038872945366500475\n",
      "Mean Absolute Error: 0.03056709516355744\n",
      "Median Absolute Error: 0.02629817485809327\n",
      "R-squared: 0.9456712055158418\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e6e9414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predictions = model.predict(X_test, batch_size=len(X_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "0e893fb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(indices_test[:3000], y_test[:3000], label='Test Observed', color='blue')\n",
    "plt.plot(indices_test[:3000], predictions[:3000], label='Test Predicted', color='orange')\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Water Level (m)')\n",
    "plt.title('Observed vs Predicted Water Levels (First 5000 Samples)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
